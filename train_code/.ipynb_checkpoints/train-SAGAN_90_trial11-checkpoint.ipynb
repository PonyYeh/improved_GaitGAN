{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T06:30:06.594963Z",
     "start_time": "2019-06-18T06:30:06.022203Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from onlineTripletloss import *\n",
    "from selector import *\n",
    "# from model_copy import NetG, NetD, NetA, NetP\n",
    "# from model_SAGAN2 import NetG, NetD, NetA\n",
    "# from model_WGANGP import NetG, NetD, NetA\n",
    "# from model_WGAN import NetG, NetD, NetA\n",
    "from model_siGAN import NetG, NetD, NetA\n",
    "# from data_set import CASIABDataset\n",
    "from dataset2Loader_triplet import CASIABDataset\n",
    "import torch.optim as optim\n",
    "import visdom\n",
    "from torchvision.utils import make_grid\n",
    "# Data_Dir = '../GaitRecognition/DatasetB_GEI_64x64_allseq/'\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "Model_Name = 'Model_64x64_TripletGAN_90_trial16'\n",
    "Model_dir = './Transform_Model/'+ Model_Name\n",
    "if not os.path.isdir(Model_dir):\n",
    "    os.mkdir(Model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T11:51:23.878764Z",
     "start_time": "2019-05-17T11:51:22.490886Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "import os\n",
    "\n",
    "for r, d, files in os.walk(Data_Dir):\n",
    "    print(r)\n",
    "    print(len(d))\n",
    "    print(len(files))\n",
    "    \n",
    "# cpt = sum([len(files) for r, d, files in os.walk(Data_Dir)])\n",
    "# cpt = sum([len(d) for r, d, files in os.walk(Data_Dir)])\n",
    "# print(cpt)\n",
    "# list = os.listdir(Data_Dir) # dir is your directory path\n",
    "# number_files = len(list)\n",
    "# print(number_files)\n",
    "\n",
    "# import fnmatch\n",
    "# print(len(fnmatch.filter(os.listdir(Data_Dir), '*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T06:02:12.747164Z",
     "start_time": "2019-05-27T06:02:12.676816Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "ass_label, noass_label, img = dataset.getbatch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T08:08:38.785029Z",
     "start_time": "2019-06-16T08:08:38.768214Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-d2306f43491b>, line 129)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d2306f43491b>\"\u001b[0;36m, line \u001b[0;32m129\u001b[0m\n\u001b[0;31m    fake = netg(img) 25\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(tensor, gain=1.)\n",
    "#         init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 128\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print('Training starts')\n",
    "while iteration < 30000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    # update D\n",
    "    lossD = 0\n",
    "    optimD.zero_grad()\n",
    "    output = netd(ass_label)\n",
    "    label.fill_(real_label)\n",
    "    lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "    lossD += lossD_real1.item()\n",
    "    lossD_real1.backward()\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output1 = netd(noass_label)\n",
    "    lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "    lossD += lossD_real2.item()\n",
    "    lossD_real2.backward()\n",
    "\n",
    "    fake = netg(img).detach()\n",
    "    label.fill_(fake_label)\n",
    "    output2 = netd(fake)\n",
    "    lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "    lossD += lossD_fake.item()\n",
    "    lossD_fake.backward()\n",
    "\n",
    "    optimD.step()\n",
    "    \n",
    "    # update A\n",
    "    lossA = 0\n",
    "    optimA.zero_grad()\n",
    "    assd = th.cat((img, ass_label), 1)\n",
    "    noassd = th.cat((img, noass_label), 1)\n",
    "    fake = netg(img).detach()\n",
    "    faked = th.cat((img, fake), 1)\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output1 = neta(assd)\n",
    "    lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "    lossA += lossA_real1.item()\n",
    "    lossA_real1.backward()\n",
    "\n",
    "    label.fill_(fake_label)\n",
    "    output = neta(noassd)\n",
    "    lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "    lossA += lossA_real2.item()\n",
    "    lossA_real2.backward()\n",
    "\n",
    "    label.fill_(fake_label)\n",
    "    output = neta(faked)\n",
    "    lossA_fake = F.binary_cross_entropy(output, label)\n",
    "    lossA += lossA_fake.item()\n",
    "    lossA_fake.backward()\n",
    "    \n",
    "    optimA.step()\n",
    "    \n",
    "    # update G\n",
    "    lossG = 0\n",
    "    optimG.zero_grad()\n",
    "    fake = netg(img)\n",
    "    output = netd(fake)\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    lossGD = F.binary_cross_entropy(output, label)\n",
    "    lossG += lossGD.item()\n",
    "    lossGD.backward(retain_graph=True)\n",
    "\n",
    "    faked = th.cat((img, fake), 1)\n",
    "    output = neta(faked)\n",
    "    label.fill_(real_label)\n",
    "    lossGA = F.binary_cross_entropy(output, label)\n",
    "    lossG += lossGA.item()\n",
    "    lossGA.backward()\n",
    "    \n",
    "    optimG.step()\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration % 20 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            fake = netg(img) 25\n",
    "            netg.train() #切換回去\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 20).cpu().numpy()\n",
    "        if win1 is None:\n",
    "            win1 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train'))\n",
    "        else:\n",
    "            vis.image(display, win=win1)\n",
    "    if iteration % 1000 == 0 or iteration==500:\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)\n",
    "\n",
    "    if iteration % 100==0 or iteration==10 :\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration, iteration,\n",
    "                                        iteration]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration,\n",
    "                                  iteration]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "            \n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            iteration, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('iter = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            iteration, lossG/2, lossA/3, lossD/3\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T05:25:59.661560Z",
     "start_time": "2019-05-27T05:25:59.620596Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=False)\n",
    "train_loader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T08:46:23.327475Z",
     "start_time": "2019-06-16T08:23:19.736325Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 3.3411221504211426, ErrA = 0.44111086055636406, ErrD = 0.036158584679166474\n",
      "Epoch = 4, ErrG = 3.361356258392334, ErrA = 0.3775310466686885, ErrD = 0.036184978360931076\n",
      "Epoch = 6, ErrG = 4.272621393203735, ErrA = 0.3271034111579259, ErrD = 0.003417431997756163\n",
      "Epoch = 8, ErrG = 4.160229206085205, ErrA = 0.2504531896362702, ErrD = 0.05292314477264881\n",
      "Epoch = 10, ErrG = 3.3400180339813232, ErrA = 0.2544544863825043, ErrD = 0.3592479278643926\n",
      "Epoch = 12, ErrG = 2.230285406112671, ErrA = 0.0737597147623698, ErrD = 0.4638359546661377\n",
      "Epoch = 14, ErrG = 3.333204686641693, ErrA = 0.15362303347016373, ErrD = 0.3380258431037267\n",
      "Epoch = 16, ErrG = 3.0305097103118896, ErrA = 0.12443562845389049, ErrD = 0.18306180338064829\n",
      "Epoch = 18, ErrG = 3.0286770462989807, ErrA = 0.11020504403859377, ErrD = 0.4389033814271291\n",
      "Epoch = 20, ErrG = 2.9920820891857147, ErrA = 0.020810067964096863, ErrD = 0.3843097488085429\n",
      "Epoch = 22, ErrG = 4.305165886878967, ErrA = 0.16786196703712145, ErrD = 0.0031868963657567897\n",
      "Epoch = 24, ErrG = 3.436143398284912, ErrA = 0.03987422197436293, ErrD = 0.28397955000400543\n",
      "Epoch = 26, ErrG = 4.2425437271595, ErrA = 0.14466423322543656, ErrD = 0.6363368233044943\n",
      "Epoch = 28, ErrG = 3.3681275248527527, ErrA = 0.019689220935106277, ErrD = 0.2069978415966034\n",
      "Epoch = 30, ErrG = 3.4143062233924866, ErrA = 0.008049463387578726, ErrD = 0.23474102218945822\n",
      "Epoch = 32, ErrG = 3.9184280931949615, ErrA = 0.010949958891918262, ErrD = 0.3675355613231659\n",
      "Epoch = 34, ErrG = 5.158403217792511, ErrA = 0.038214251379637666, ErrD = 0.3390839646259944\n",
      "Epoch = 36, ErrG = 4.315913289785385, ErrA = 0.0745812911967126, ErrD = 0.3710207554201285\n",
      "Epoch = 38, ErrG = 3.7672959566116333, ErrA = 0.007803739747032523, ErrD = 0.056341241424282394\n",
      "Epoch = 40, ErrG = 4.914057075977325, ErrA = 0.010097662666036436, ErrD = 0.13354581346114477\n",
      "Epoch = 42, ErrG = 3.6656675338745117, ErrA = 0.015820540953427553, ErrD = 0.058811395739515625\n",
      "Epoch = 44, ErrG = 4.084235429763794, ErrA = 0.005469997646287084, ErrD = 0.12889852188527584\n",
      "Epoch = 46, ErrG = 5.848504543304443, ErrA = 0.02259795391970935, ErrD = 0.19498497247695923\n",
      "Epoch = 48, ErrG = 4.21962571144104, ErrA = 0.005453272877881925, ErrD = 0.09756845235824585\n",
      "Epoch = 50, ErrG = 4.8004186153411865, ErrA = 0.003945991940175493, ErrD = 0.09890650771558285\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b76814e822cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mlossD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0moptimD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mass_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mlossD_real1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_ting_cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/deep3072/Data/tingen/GaitGAN-paper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_ting_cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_ting_cv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_ting_cv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_ting_cv/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, target = {} \\n'.format(\n",
    "            epoches, lr, batchSize, target))\n",
    "\n",
    "print('Training starts')\n",
    "low_loss = 10\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, ass_img, img, noass_img) in enumerate(train_loader): \n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "        label.fill_(real_label)\n",
    "        lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "        lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "        label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "        lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "\n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_img), 1)\n",
    "        noassd = th.cat((img, noass_img), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "\n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:  \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "    \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update k times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:08:32.658055Z",
     "start_time": "2019-06-15T08:18:03.792818Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 1.5588033199310303, ErrA = 0.4954340805610021, ErrD = 0.19129109879334769\n",
      "Epoch = 4, ErrG = 1.8620306849479675, ErrA = 0.38821983337402344, ErrD = 0.15181769927342734\n",
      "Epoch = 6, ErrG = 2.9678717851638794, ErrA = 0.39058470105131465, ErrD = 0.07360446825623512\n",
      "Epoch = 8, ErrG = 3.080983877182007, ErrA = 0.37689451904346544, ErrD = 0.10360063364108403\n",
      "Epoch = 10, ErrG = 2.6229763627052307, ErrA = 0.35657545427481335, ErrD = 0.4389157295227051\n",
      "Epoch = 12, ErrG = 2.3641445338726044, ErrA = 0.3480776399374008, ErrD = 0.4964556197325389\n",
      "Epoch = 14, ErrG = 2.986826181411743, ErrA = 0.19838610012084246, ErrD = 0.6122767329216003\n",
      "Epoch = 16, ErrG = 3.181006968021393, ErrA = 0.6149165614818534, ErrD = 0.5359568235774835\n",
      "Epoch = 18, ErrG = 3.4160876870155334, ErrA = 0.629215250412623, ErrD = 0.030627019703388214\n",
      "Epoch = 20, ErrG = 3.121281534433365, ErrA = 0.3222902840934694, ErrD = 0.9301179846127828\n",
      "Epoch = 22, ErrG = 2.28449809551239, ErrA = 0.21419317151109377, ErrD = 0.3259084274371465\n",
      "Epoch = 24, ErrG = 2.9733357429504395, ErrA = 0.1649842051168283, ErrD = 0.29348162313302356\n",
      "Epoch = 26, ErrG = 3.4261946082115173, ErrA = 0.25009777847056586, ErrD = 0.6736394862333933\n",
      "Epoch = 28, ErrG = 3.397323250770569, ErrA = 0.33757159610589343, ErrD = 0.27974534034729004\n",
      "Epoch = 30, ErrG = 3.18826824426651, ErrA = 0.135877073276788, ErrD = 0.3101800133784612\n",
      "Epoch = 32, ErrG = 3.633284568786621, ErrA = 0.3423358845369269, ErrD = 0.3545445154110591\n",
      "Epoch = 34, ErrG = 2.698749303817749, ErrA = 0.11969206109642982, ErrD = 0.3611515164375305\n",
      "Epoch = 36, ErrG = 2.991978943347931, ErrA = 0.11822708315836887, ErrD = 0.4500857988993327\n",
      "Epoch = 38, ErrG = 3.298756957054138, ErrA = 0.1301939506083727, ErrD = 0.3077438995242119\n",
      "Epoch = 40, ErrG = 2.8489978909492493, ErrA = 0.05860048113390803, ErrD = 0.3497689714034398\n",
      "Epoch = 42, ErrG = 2.776526391506195, ErrA = 0.0906776135476927, ErrD = 0.7756190101305643\n",
      "Epoch = 44, ErrG = 3.670587182044983, ErrA = 0.055683113324145474, ErrD = 0.5306005130211512\n",
      "Epoch = 46, ErrG = 4.71131506562233, ErrA = 0.13803809182718396, ErrD = 0.5159317751725515\n",
      "Epoch = 48, ErrG = 3.6526378393173218, ErrA = 0.13724781153723598, ErrD = 0.6927185853322347\n",
      "Epoch = 50, ErrG = 2.6258330941200256, ErrA = 0.07754352316260338, ErrD = 0.15986429899930954\n",
      "Epoch = 52, ErrG = 3.559292256832123, ErrA = 0.03535760574353238, ErrD = 0.5831121404965719\n",
      "Epoch = 54, ErrG = 2.3367812037467957, ErrA = 0.22698639829953512, ErrD = 0.029589945450425148\n",
      "Epoch = 56, ErrG = 2.804350733757019, ErrA = 0.23070155953367552, ErrD = 0.187148615407447\n",
      "Epoch = 58, ErrG = 2.866926074028015, ErrA = 0.02565515150005619, ErrD = 0.24704709649085999\n",
      "Epoch = 60, ErrG = 2.727347254753113, ErrA = 0.085756439405183, ErrD = 0.252025028069814\n",
      "Epoch = 62, ErrG = 4.069447636604309, ErrA = 0.07270532349745433, ErrD = 0.45503856738408405\n",
      "Epoch = 64, ErrG = 4.191762566566467, ErrA = 0.03650464552144209, ErrD = 0.38238540291786194\n",
      "Epoch = 66, ErrG = 3.840497612953186, ErrA = 0.05697118521978458, ErrD = 0.20294466614723206\n",
      "Epoch = 68, ErrG = 4.9836984276771545, ErrA = 0.00798716931603849, ErrD = 0.1681501790881157\n",
      "Epoch = 70, ErrG = 3.7176315784454346, ErrA = 0.020531809888780117, ErrD = 0.14785755798220634\n",
      "Epoch = 72, ErrG = 4.62688872218132, ErrA = 0.17360395895472416, ErrD = 0.3373541633288066\n",
      "Epoch = 74, ErrG = 4.193493723869324, ErrA = 0.0403475332132075, ErrD = 0.315212885538737\n",
      "Epoch = 76, ErrG = 4.158313155174255, ErrA = 0.06194042422187825, ErrD = 0.3918408552805583\n",
      "Epoch = 78, ErrG = 5.0868576765060425, ErrA = 0.013790501669670144, ErrD = 0.274206538995107\n",
      "Epoch = 80, ErrG = 3.591189920902252, ErrA = 0.07359922085500632, ErrD = 0.20607542991638184\n",
      "Epoch = 82, ErrG = 3.4691641330718994, ErrA = 0.00499380628267924, ErrD = 0.1390734763505558\n",
      "Epoch = 84, ErrG = 3.7030913829803467, ErrA = 0.04153516717875997, ErrD = 0.16807174775749445\n",
      "Epoch = 86, ErrG = 3.3358211517333984, ErrA = 0.03263693233020604, ErrD = 0.18732218692700067\n",
      "Epoch = 88, ErrG = 3.8986722230911255, ErrA = 0.006404221290722489, ErrD = 0.10818305735786755\n",
      "Epoch = 90, ErrG = 3.6141512393951416, ErrA = 0.013319596298970282, ErrD = 0.45008673270543414\n",
      "Epoch = 92, ErrG = 2.610228180885315, ErrA = 0.04723501888414224, ErrD = 0.09554800701638062\n",
      "Epoch = 94, ErrG = 4.706256926059723, ErrA = 0.11557108324874814, ErrD = 0.2302416910727819\n",
      "Epoch = 96, ErrG = 3.4500227868556976, ErrA = 0.04811304450655977, ErrD = 0.20551622907320657\n",
      "Epoch = 98, ErrG = 4.60446298122406, ErrA = 0.0018510486697778106, ErrD = 0.18066896498203278\n",
      "Epoch = 100, ErrG = 3.602692127227783, ErrA = 0.001770637434674427, ErrD = 0.2631114323933919\n",
      "Epoch = 102, ErrG = 5.405020177364349, ErrA = 0.004279925565545757, ErrD = 0.10114792982737224\n",
      "Epoch = 104, ErrG = 3.808947205543518, ErrA = 0.006375523361687859, ErrD = 0.17983405540386835\n",
      "Epoch = 106, ErrG = 4.458278298377991, ErrA = 0.03238633798900992, ErrD = 0.20078942428032556\n",
      "Epoch = 108, ErrG = 3.710123062133789, ErrA = 0.46635866453774116, ErrD = 0.13001205399632454\n",
      "Epoch = 110, ErrG = 4.051281273365021, ErrA = 0.002266013742579768, ErrD = 0.19983931196232638\n",
      "Epoch = 112, ErrG = 5.009787142276764, ErrA = 0.035272719030520726, ErrD = 0.2590262119968732\n",
      "Epoch = 114, ErrG = 4.790991723537445, ErrA = 0.00727162099792622, ErrD = 0.28982652227083844\n",
      "Epoch = 116, ErrG = 5.674633622169495, ErrA = 0.002018615535538023, ErrD = 0.18528592959046364\n",
      "Epoch = 118, ErrG = 6.465242430567741, ErrA = 0.0011648771906038746, ErrD = 0.4207439621289571\n",
      "Epoch = 120, ErrG = 3.8466684818267822, ErrA = 0.01541209923743736, ErrD = 0.23357491319378218\n",
      "Epoch = 122, ErrG = 5.003231346607208, ErrA = 0.004704455253280078, ErrD = 0.26887044807275134\n",
      "Epoch = 124, ErrG = 4.243467330932617, ErrA = 0.002077804849250242, ErrD = 0.4137547016143799\n",
      "Epoch = 126, ErrG = 4.646921992301941, ErrA = 0.0018333271242833387, ErrD = 0.495672086874644\n",
      "Epoch = 128, ErrG = 5.094305843114853, ErrA = 0.017821177607402205, ErrD = 0.3325531631708145\n",
      "Epoch = 130, ErrG = 4.86880761384964, ErrA = 0.023964493807094794, ErrD = 0.12723323330283165\n",
      "Epoch = 132, ErrG = 4.0622758865356445, ErrA = 0.0036391185130923986, ErrD = 0.1346303503960371\n",
      "Epoch = 134, ErrG = 4.492927074432373, ErrA = 0.012679067528551968, ErrD = 0.28742700318495434\n",
      "Epoch = 136, ErrG = 5.048724293708801, ErrA = 0.003076397693803301, ErrD = 0.2538134629527728\n",
      "Epoch = 138, ErrG = 5.416046142578125, ErrA = 0.01575214017915035, ErrD = 0.5281518151362737\n",
      "Epoch = 140, ErrG = 6.425680756568909, ErrA = 0.0008045709497916201, ErrD = 0.1119247352083524\n",
      "Epoch = 142, ErrG = 4.964323580265045, ErrA = 0.0034545894062224156, ErrD = 0.19469960778951645\n",
      "Epoch = 144, ErrG = 5.8038575649261475, ErrA = 0.002214774739210649, ErrD = 0.24574905633926392\n",
      "Epoch = 146, ErrG = 3.708596706390381, ErrA = 0.04747824747270594, ErrD = 0.24693100154399872\n",
      "Epoch = 148, ErrG = 5.9444779753685, ErrA = 0.004918117682488325, ErrD = 0.17709413977960745\n",
      "Epoch = 150, ErrG = 6.73222279548645, ErrA = 0.002691744335303762, ErrD = 0.3282362222671509\n",
      "Epoch = 152, ErrG = 5.827183723449707, ErrA = 0.0010638129000047531, ErrD = 0.23016130179166794\n",
      "Epoch = 154, ErrG = 4.765697658061981, ErrA = 0.023262015922227874, ErrD = 0.441539245347182\n",
      "Epoch = 156, ErrG = 5.019473731517792, ErrA = 0.0068014634113448364, ErrD = 0.3956485490004222\n",
      "Epoch = 158, ErrG = 5.55163186788559, ErrA = 0.00026495338988752337, ErrD = 0.45786771178245544\n",
      "Epoch = 160, ErrG = 5.977031707763672, ErrA = 0.0010094802561676868, ErrD = 0.6845433513323466\n",
      "Epoch = 162, ErrG = 4.621211290359497, ErrA = 0.007468368427604825, ErrD = 0.2575662185748418\n",
      "Epoch = 164, ErrG = 6.107385039329529, ErrA = 0.0005333589603348324, ErrD = 0.19930965080857277\n",
      "Epoch = 166, ErrG = 5.322146773338318, ErrA = 0.0023402485627836236, ErrD = 0.14791055396199226\n",
      "Epoch = 168, ErrG = 5.145471155643463, ErrA = 0.0013082905716146342, ErrD = 0.17766952017943063\n",
      "Epoch = 170, ErrG = 6.3679563999176025, ErrA = 0.0008687467933820395, ErrD = 0.4064093952377637\n",
      "Epoch = 172, ErrG = 5.88571560382843, ErrA = 0.0009969979582820088, ErrD = 0.2897718238333861\n",
      "Epoch = 174, ErrG = 7.100221216678619, ErrA = 0.16677593936909338, ErrD = 0.24325362344582876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 176, ErrG = 6.831139832735062, ErrA = 0.004716723418823676, ErrD = 0.3077218135197957\n",
      "Epoch = 178, ErrG = 5.7401123046875, ErrA = 0.0005244686411363849, ErrD = 0.19037060687939325\n",
      "Epoch = 180, ErrG = 5.42939567565918, ErrA = 0.0009260319119069512, ErrD = 0.32404774862031144\n",
      "Epoch = 182, ErrG = 4.795043647289276, ErrA = 0.0009413289275149358, ErrD = 0.5196272283792496\n",
      "Epoch = 184, ErrG = 5.475306749343872, ErrA = 0.00041795648091162246, ErrD = 0.2979186934729417\n",
      "Epoch = 186, ErrG = 6.479019582271576, ErrA = 0.0007185266852805702, ErrD = 0.17575795451800028\n",
      "Epoch = 188, ErrG = 6.157017111778259, ErrA = 0.00047458595751474303, ErrD = 0.1468967745701472\n",
      "Epoch = 190, ErrG = 5.370856821537018, ErrA = 0.025097796693444252, ErrD = 0.20363212128480276\n",
      "Epoch = 192, ErrG = 5.994137287139893, ErrA = 0.0019459321180571958, ErrD = 0.1704980581998825\n",
      "Epoch = 194, ErrG = 6.887574553489685, ErrA = 0.0005688234808379397, ErrD = 0.2908540566762288\n",
      "Epoch = 196, ErrG = 5.431972861289978, ErrA = 0.005557092898849684, ErrD = 0.44168355067571\n",
      "Epoch = 198, ErrG = 5.0483092069625854, ErrA = 0.001439545595682527, ErrD = 0.14551782608032227\n",
      "Epoch = 200, ErrG = 7.38976263999939, ErrA = 0.00017823962116381153, ErrD = 0.3695467511812846\n",
      "Epoch = 202, ErrG = 5.729413479566574, ErrA = 0.0006885371404905527, ErrD = 0.23476689184705415\n",
      "Epoch = 204, ErrG = 7.367161571979523, ErrA = 0.00014610938039065027, ErrD = 0.21752366920312247\n",
      "Epoch = 206, ErrG = 5.297608375549316, ErrA = 0.0003532910389670481, ErrD = 0.15207653741041818\n",
      "Epoch = 208, ErrG = 6.089477837085724, ErrA = 0.0635629389641205, ErrD = 0.10857359444101651\n",
      "Epoch = 210, ErrG = 7.400358498096466, ErrA = 0.002857226220839948, ErrD = 0.19750338792800903\n",
      "Epoch = 212, ErrG = 7.444262325763702, ErrA = 0.00023914965883401843, ErrD = 0.3605700396001339\n",
      "Epoch = 214, ErrG = 6.966509997844696, ErrA = 2.6926679007980663e-05, ErrD = 0.26209162424008053\n",
      "Epoch = 216, ErrG = 6.555902034044266, ErrA = 0.002139318335442416, ErrD = 0.2282706027229627\n",
      "Epoch = 218, ErrG = 6.449874639511108, ErrA = 0.0005210292403792968, ErrD = 0.24263704816500345\n",
      "Epoch = 220, ErrG = 6.979858815670013, ErrA = 0.0004989970366295893, ErrD = 0.15609226003289223\n",
      "Epoch = 222, ErrG = 5.1147231459617615, ErrA = 7.461278679935883e-05, ErrD = 0.173709770043691\n",
      "Epoch = 224, ErrG = 5.104885041713715, ErrA = 0.0003221937816609473, ErrD = 0.11707368617256482\n",
      "Epoch = 226, ErrG = 6.567285895347595, ErrA = 0.001155375662468335, ErrD = 0.7688252627849579\n",
      "Epoch = 228, ErrG = 5.203463077545166, ErrA = 0.0007905913516879082, ErrD = 0.3828948785861333\n",
      "Epoch = 230, ErrG = 5.11482572555542, ErrA = 0.004533862710862498, ErrD = 0.11224545569469531\n",
      "Epoch = 232, ErrG = 5.525125563144684, ErrA = 0.2749209191642876, ErrD = 0.38314466675122577\n",
      "Epoch = 234, ErrG = 7.50531804561615, ErrA = 0.00042314562309305376, ErrD = 0.24904416998227438\n",
      "Epoch = 236, ErrG = 6.938226342201233, ErrA = 0.00024715819154152996, ErrD = 0.1935039721429348\n",
      "Epoch = 238, ErrG = 5.354463577270508, ErrA = 1.8232856897763366e-05, ErrD = 0.24710898846387863\n",
      "Epoch = 240, ErrG = 6.240508198738098, ErrA = 6.659833167077522e-05, ErrD = 0.26549385115504265\n",
      "Epoch = 242, ErrG = 6.882387697696686, ErrA = 2.9598467032580327e-05, ErrD = 0.2862563182910283\n",
      "Epoch = 244, ErrG = 7.053284049034119, ErrA = 4.071596595167648e-05, ErrD = 0.21798868601520857\n",
      "Epoch = 246, ErrG = 6.35299015045166, ErrA = 0.0010740276501716532, ErrD = 0.29603444039821625\n",
      "Epoch = 248, ErrG = 3.7253294587135315, ErrA = 0.03862029031248918, ErrD = 0.13885532567898431\n",
      "Epoch = 250, ErrG = 6.24965238571167, ErrA = 4.4369126650659986e-05, ErrD = 0.29290055483579636\n",
      "Epoch = 252, ErrG = 7.735347151756287, ErrA = 0.0009570358921943504, ErrD = 0.2593594752252102\n",
      "Epoch = 254, ErrG = 5.74282443523407, ErrA = 8.620761582278647e-05, ErrD = 0.17458771914243698\n",
      "Epoch = 256, ErrG = 5.585742950439453, ErrA = 0.0006447401732051125, ErrD = 0.0893516627450784\n",
      "Epoch = 258, ErrG = 6.395928472280502, ErrA = 0.0006197605641062864, ErrD = 0.4263743857542674\n",
      "Epoch = 260, ErrG = 6.782248258590698, ErrA = 0.0019642428184549012, ErrD = 0.0453448590512077\n",
      "Epoch = 262, ErrG = 7.922906756401062, ErrA = 0.03356092601704338, ErrD = 0.2832721124092738\n",
      "Epoch = 264, ErrG = 7.992738842964172, ErrA = 0.0012896823949499019, ErrD = 0.37893571456273395\n",
      "Epoch = 266, ErrG = 6.634877324104309, ErrA = 3.228919672437769e-05, ErrD = 0.2194931668539842\n",
      "Epoch = 268, ErrG = 6.627044498920441, ErrA = 0.0007191298451895515, ErrD = 0.15083417358497778\n",
      "Epoch = 270, ErrG = 5.001044720411301, ErrA = 0.00032604494723879424, ErrD = 0.30038900673389435\n",
      "Epoch = 272, ErrG = 5.1754679679870605, ErrA = 0.002732490735676644, ErrD = 0.13377833118041357\n",
      "Epoch = 274, ErrG = 9.167929649353027, ErrA = 0.052073632623432786, ErrD = 0.14502675334612528\n",
      "Epoch = 276, ErrG = 6.626073598861694, ErrA = 0.00023287122075998923, ErrD = 0.17212997873624167\n",
      "Epoch = 278, ErrG = 6.998581886291504, ErrA = 0.0005497340684996743, ErrD = 0.306266816953818\n",
      "Epoch = 280, ErrG = 7.123667597770691, ErrA = 7.599636804419181e-05, ErrD = 0.3078617254892985\n",
      "Epoch = 282, ErrG = 8.299008250236511, ErrA = 0.00029209451925756486, ErrD = 0.2205242415269216\n",
      "Epoch = 284, ErrG = 6.149958550930023, ErrA = 0.0019207508497250576, ErrD = 0.18949141105016074\n",
      "Epoch = 286, ErrG = 5.785970687866211, ErrA = 0.001220208944384164, ErrD = 0.1634517883261045\n",
      "Epoch = 288, ErrG = 7.05096572637558, ErrA = 6.605624548683409e-05, ErrD = 0.26953189571698505\n",
      "Epoch = 290, ErrG = 6.708661079406738, ErrA = 5.0509529046394164e-05, ErrD = 0.34169697761535645\n",
      "Epoch = 292, ErrG = 6.546813130378723, ErrA = 6.45953195241115e-05, ErrD = 0.45006996144851047\n",
      "Epoch = 294, ErrG = 7.892622232437134, ErrA = 8.34807631993802e-05, ErrD = 0.25236372649669647\n",
      "Epoch = 296, ErrG = 6.9886181354522705, ErrA = 0.0008497060074053783, ErrD = 0.14262020122259855\n",
      "Epoch = 298, ErrG = 5.51101279258728, ErrA = 0.00027247043666041765, ErrD = 0.14272746505836645\n",
      "Epoch = 300, ErrG = 6.197799563407898, ErrA = 0.0021547998811305056, ErrD = 0.18899884323279062\n",
      "Epoch = 302, ErrG = 8.231956243515015, ErrA = 0.00010304615238965198, ErrD = 0.2172520856062571\n",
      "Epoch = 304, ErrG = 6.510575830936432, ErrA = 0.001171175115814549, ErrD = 0.3382675629109144\n",
      "Epoch = 306, ErrG = 5.556938529014587, ErrA = 0.0005722109854104929, ErrD = 0.12081217269102733\n",
      "Epoch = 308, ErrG = 7.206969499588013, ErrA = 1.4733254981062297e-05, ErrD = 0.12151665861407916\n",
      "Epoch = 310, ErrG = 6.237656474113464, ErrA = 0.00012052393534152846, ErrD = 0.23871944472193718\n",
      "Epoch = 312, ErrG = 7.90355110168457, ErrA = 0.00017700731268632808, ErrD = 0.16845056662956873\n",
      "Epoch = 314, ErrG = 8.270580112934113, ErrA = 0.0005889087885861954, ErrD = 0.1026686429977417\n",
      "Epoch = 316, ErrG = 5.023577928543091, ErrA = 9.157958993455395e-05, ErrD = 0.13671253621578217\n",
      "Epoch = 318, ErrG = 7.68807452917099, ErrA = 5.141106400211962e-05, ErrD = 0.11100120718280475\n",
      "Epoch = 320, ErrG = 6.463660359382629, ErrA = 6.491665726571227e-05, ErrD = 0.13692359377940497\n",
      "Epoch = 322, ErrG = 5.601341009140015, ErrA = 0.03234826092617974, ErrD = 0.0420701038868477\n",
      "Epoch = 324, ErrG = 8.115128338336945, ErrA = 0.00020147437574754198, ErrD = 0.3201041507224242\n",
      "Epoch = 326, ErrG = 8.235265612602234, ErrA = 6.283144709584576e-05, ErrD = 0.37839556485414505\n",
      "Epoch = 328, ErrG = 7.046606183052063, ErrA = 0.0023562224447838767, ErrD = 0.224446768561999\n",
      "Epoch = 330, ErrG = 6.835421025753021, ErrA = 0.04833840786053164, ErrD = 0.1124089981118838\n",
      "Epoch = 332, ErrG = 7.435894250869751, ErrA = 0.0019489001203207106, ErrD = 0.19366333012779555\n",
      "Epoch = 334, ErrG = 7.010713696479797, ErrA = 0.0002084466006332756, ErrD = 0.07209351969261964\n",
      "Epoch = 336, ErrG = 7.874320566654205, ErrA = 5.273975330529387e-05, ErrD = 0.9130461737513542\n",
      "Epoch = 338, ErrG = 8.73935580253601, ErrA = 0.0006809804034067687, ErrD = 0.15381966531276703\n",
      "Epoch = 340, ErrG = 5.57174289226532, ErrA = 0.00013669179740342466, ErrD = 0.08288533178468545\n",
      "Epoch = 342, ErrG = 6.473416328430176, ErrA = 0.0004996436303675486, ErrD = 0.13546955212950706\n",
      "Epoch = 344, ErrG = 8.017865061759949, ErrA = 0.00012353895582843202, ErrD = 0.2762211908896764\n",
      "Epoch = 346, ErrG = 6.944281280040741, ErrA = 4.941720787125329e-05, ErrD = 0.1565172697106997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 348, ErrG = 6.1596128940582275, ErrA = 0.00013765553497554114, ErrD = 0.11682136698315541\n",
      "Epoch = 350, ErrG = 9.763295352458954, ErrA = 3.4831571914158608e-06, ErrD = 0.161186791335543\n",
      "Epoch = 352, ErrG = 8.154533386230469, ErrA = 0.00024326466035518024, ErrD = 0.2682118167479833\n",
      "Epoch = 354, ErrG = 7.361542344093323, ErrA = 0.0002493309823421441, ErrD = 0.1081374188264211\n",
      "Epoch = 356, ErrG = 5.796618342399597, ErrA = 0.000159685312610236, ErrD = 0.21990248436729112\n",
      "Epoch = 358, ErrG = 7.202744960784912, ErrA = 2.3819473578138666e-05, ErrD = 0.1321813693890969\n",
      "Epoch = 360, ErrG = 6.564028263092041, ErrA = 9.72373321322569e-05, ErrD = 0.11159980359176795\n",
      "Epoch = 362, ErrG = 6.711366355419159, ErrA = 0.0002984184033039128, ErrD = 0.11192851513624191\n",
      "Epoch = 364, ErrG = 7.656510949134827, ErrA = 3.456297205654361e-05, ErrD = 0.11052152638634045\n",
      "Epoch = 366, ErrG = 8.382885754108429, ErrA = 0.00014327441052349363, ErrD = 0.11537620301047961\n",
      "Epoch = 368, ErrG = 7.920348703861237, ErrA = 9.115156293167577e-05, ErrD = 0.20176392793655396\n",
      "Epoch = 370, ErrG = 8.30558443069458, ErrA = 0.0009089362229133258, ErrD = 0.2146745224793752\n",
      "Epoch = 372, ErrG = 6.107416987419128, ErrA = 1.4010466079146985e-05, ErrD = 0.25939931844671565\n",
      "Epoch = 374, ErrG = 7.195173263549805, ErrA = 0.0002852756282057574, ErrD = 0.13608399530251822\n",
      "Epoch = 376, ErrG = 6.732599496841431, ErrA = 0.0001534302233873556, ErrD = 0.1965890439848105\n",
      "Epoch = 378, ErrG = 6.164279222488403, ErrA = 0.00011367505188294065, ErrD = 0.09121411293745041\n",
      "Epoch = 380, ErrG = 7.225293397903442, ErrA = 0.00027491100703021704, ErrD = 0.134306317816178\n",
      "Epoch = 382, ErrG = 8.860225796699524, ErrA = 0.00101269519533768, ErrD = 0.20207725216945013\n",
      "Epoch = 384, ErrG = 9.445181965827942, ErrA = 6.588871996389874e-05, ErrD = 0.1261193330089251\n",
      "Epoch = 386, ErrG = 8.686066925525665, ErrA = 1.4135896435618633e-05, ErrD = 0.12735682477553686\n",
      "Epoch = 388, ErrG = 5.301001071929932, ErrA = 0.002094893429481696, ErrD = 0.38451369603474933\n",
      "Epoch = 390, ErrG = 8.222852110862732, ErrA = 5.854990718034969e-06, ErrD = 0.18154898285865784\n",
      "Epoch = 392, ErrG = 7.920598268508911, ErrA = 4.127034723448257e-06, ErrD = 0.1787008469303449\n",
      "Epoch = 394, ErrG = 7.992295563220978, ErrA = 0.0003917974294154192, ErrD = 0.29023391753435135\n",
      "Epoch = 396, ErrG = 4.845570921897888, ErrA = 0.00015167962859171288, ErrD = 0.3040969471136729\n",
      "Epoch = 398, ErrG = 6.846996068954468, ErrA = 0.003157743413642796, ErrD = 0.2274566392103831\n",
      "Epoch = 400, ErrG = 8.565379202365875, ErrA = 0.0002066432100491511, ErrD = 0.21091868604222933\n",
      "Epoch = 402, ErrG = 7.268010139465332, ErrA = 0.016837613273916457, ErrD = 0.18920874502509832\n",
      "Epoch = 404, ErrG = 6.793139398097992, ErrA = 0.0012901408774155243, ErrD = 0.3716268328328927\n",
      "Epoch = 406, ErrG = 8.886203527450562, ErrA = 4.525995063886512e-05, ErrD = 0.15767265111207962\n",
      "Epoch = 408, ErrG = 7.049662709236145, ErrA = 1.6195477665329843e-05, ErrD = 0.1990168293317159\n",
      "Epoch = 410, ErrG = 8.298017680644989, ErrA = 0.00021403501159511507, ErrD = 0.1095349242289861\n",
      "Epoch = 412, ErrG = 8.309452056884766, ErrA = 0.0018385482254643648, ErrD = 0.23258425295352936\n",
      "Epoch = 414, ErrG = 7.557214856147766, ErrA = 0.00012103372137062252, ErrD = 0.04826689697802067\n",
      "Epoch = 416, ErrG = 7.812017917633057, ErrA = 9.429465522240814e-05, ErrD = 0.23885023593902588\n",
      "Epoch = 418, ErrG = 7.216081738471985, ErrA = 2.4182202878364478e-05, ErrD = 0.16027861336867014\n",
      "Epoch = 420, ErrG = 7.4938459396362305, ErrA = 3.177585699631891e-05, ErrD = 0.16007442648212114\n",
      "Epoch = 422, ErrG = 7.290327250957489, ErrA = 2.3202393701164206e-06, ErrD = 0.15053643037875494\n",
      "Epoch = 424, ErrG = 7.9649301171302795, ErrA = 0.0005516685779033045, ErrD = 0.1256496198475361\n",
      "Epoch = 426, ErrG = 6.798933684825897, ErrA = 3.192444061520897e-05, ErrD = 0.14553070751329264\n",
      "Epoch = 428, ErrG = 6.669091999530792, ErrA = 0.0009092294455210018, ErrD = 0.1504125107700626\n",
      "Epoch = 430, ErrG = 7.520036697387695, ErrA = 0.0016858955411104641, ErrD = 0.06946055342753728\n",
      "Epoch = 432, ErrG = 8.910473227500916, ErrA = 6.83746087304371e-05, ErrD = 0.14744910535713038\n",
      "Epoch = 434, ErrG = 7.270264625549316, ErrA = 0.0009933880517110083, ErrD = 0.08246264606714249\n",
      "Epoch = 436, ErrG = 8.182695627212524, ErrA = 6.243982791905485e-05, ErrD = 0.12236436953147252\n",
      "Epoch = 438, ErrG = 8.766005218029022, ErrA = 0.00026686179686900385, ErrD = 0.25861137732863426\n",
      "Epoch = 440, ErrG = 4.2686454355716705, ErrA = 0.004083148601542537, ErrD = 0.05109654118617376\n",
      "Epoch = 442, ErrG = 7.083795368671417, ErrA = 6.330603173410054e-05, ErrD = 0.2091597467660904\n",
      "Epoch = 444, ErrG = 5.9171130657196045, ErrA = 0.0003499965147473934, ErrD = 0.29813988010088605\n",
      "Epoch = 446, ErrG = 8.974856317043304, ErrA = 2.7077483565562943e-05, ErrD = 0.30218418935934704\n",
      "Epoch = 448, ErrG = 6.628250360488892, ErrA = 0.00022436548533733003, ErrD = 0.06857622663180034\n",
      "Epoch = 450, ErrG = 8.854316353797913, ErrA = 0.0007956268506556322, ErrD = 0.10499923179546992\n",
      "Epoch = 452, ErrG = 7.277132749557495, ErrA = 7.117864432378458e-06, ErrD = 0.17342626551787058\n",
      "Epoch = 454, ErrG = 7.853134512901306, ErrA = 5.4571299822706955e-05, ErrD = 0.287885179122289\n",
      "Epoch = 456, ErrG = 7.08243453502655, ErrA = 7.671169987588655e-05, ErrD = 0.07229274387160937\n",
      "Epoch = 458, ErrG = 7.244198143482208, ErrA = 1.3823659931707274e-05, ErrD = 0.10448324059446652\n",
      "Epoch = 460, ErrG = 7.739663064479828, ErrA = 0.00010230777188742952, ErrD = 0.12816218535105386\n",
      "Epoch = 462, ErrG = 8.14523196220398, ErrA = 0.0002622183336029593, ErrD = 0.09232307597994804\n",
      "Epoch = 464, ErrG = 7.839648962020874, ErrA = 7.876643826421059e-05, ErrD = 0.134440449376901\n",
      "Epoch = 466, ErrG = 7.684873819351196, ErrA = 0.00019808499958647494, ErrD = 0.11845782275001208\n",
      "Epoch = 468, ErrG = 7.683362007141113, ErrA = 2.789335667330306e-05, ErrD = 0.30088597039381665\n",
      "Epoch = 470, ErrG = 5.9401891231536865, ErrA = 0.011173930141012534, ErrD = 0.14400705446799597\n",
      "Epoch = 472, ErrG = 8.546567678451538, ErrA = 1.657541027573946e-05, ErrD = 0.1330943355957667\n",
      "Epoch = 474, ErrG = 8.610412418842316, ErrA = 0.0006225583941699142, ErrD = 0.1590449052552382\n",
      "Epoch = 476, ErrG = 6.496849358081818, ErrA = 0.0006920063776002886, ErrD = 0.16205880139023066\n",
      "Epoch = 478, ErrG = 7.466957092285156, ErrA = 5.363570441356084e-05, ErrD = 0.188167671362559\n",
      "Epoch = 480, ErrG = 7.644089460372925, ErrA = 0.00020436007010478838, ErrD = 0.09874989837408066\n",
      "Epoch = 482, ErrG = 9.758812606334686, ErrA = 0.021521221244862925, ErrD = 0.22299657265345255\n",
      "Epoch = 484, ErrG = 7.640935182571411, ErrA = 8.694908077207704e-05, ErrD = 0.2265971377491951\n",
      "Epoch = 486, ErrG = 8.461099088191986, ErrA = 0.00011806975237504957, ErrD = 0.14431063334147134\n",
      "Epoch = 488, ErrG = 5.7275848388671875, ErrA = 0.0001545027274308571, ErrD = 0.06485557431976001\n",
      "Epoch = 490, ErrG = 6.6198225021362305, ErrA = 2.617415278412712e-05, ErrD = 0.10388640686869621\n",
      "Epoch = 492, ErrG = 8.02717936038971, ErrA = 0.00023049987673099773, ErrD = 0.17269739570717016\n",
      "Epoch = 494, ErrG = 8.021451115608215, ErrA = 6.11895166002796e-05, ErrD = 0.2558613369862239\n",
      "Epoch = 496, ErrG = 8.358241319656372, ErrA = 5.62708631453764e-06, ErrD = 0.18325561781724295\n",
      "Epoch = 498, ErrG = 9.080953001976013, ErrA = 9.47900155855071e-05, ErrD = 0.14924298723538718\n",
      "Epoch = 500, ErrG = 8.141193151473999, ErrA = 1.248066034046739e-05, ErrD = 0.13236268113056818\n",
      "Epoch = 502, ErrG = 8.628712832927704, ErrA = 1.8992685681951116e-05, ErrD = 0.3140288932869832\n",
      "Epoch = 504, ErrG = 9.064330458641052, ErrA = 0.0009125937261463454, ErrD = 0.26214373608430225\n",
      "Epoch = 506, ErrG = 6.319857716560364, ErrA = 2.525212994441972e-05, ErrD = 0.089253980666399\n",
      "Epoch = 508, ErrG = 6.524296045303345, ErrA = 0.0002714486589259953, ErrD = 0.09344168255726497\n",
      "Epoch = 510, ErrG = 5.987512528896332, ErrA = 7.963448418498349e-05, ErrD = 0.134970985352993\n",
      "Epoch = 512, ErrG = 7.183448910713196, ErrA = 5.922665119821128e-06, ErrD = 0.2978568524122238\n",
      "Epoch = 514, ErrG = 7.870605826377869, ErrA = 2.148891125367906e-05, ErrD = 0.13315236568450928\n",
      "Epoch = 516, ErrG = 8.126086056232452, ErrA = 0.00037839109972992446, ErrD = 0.09563634792963664\n",
      "Epoch = 518, ErrG = 8.402491331100464, ErrA = 2.2221437158502035e-06, ErrD = 0.1394545597334703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 520, ErrG = 7.254403591156006, ErrA = 0.00013418334615285707, ErrD = 0.08429891072834532\n",
      "Epoch = 522, ErrG = 7.825333952903748, ErrA = 7.228213871712796e-05, ErrD = 0.21718123431007066\n",
      "Epoch = 524, ErrG = 8.774211645126343, ErrA = 3.339733822826929e-06, ErrD = 0.13289840271075568\n",
      "Epoch = 526, ErrG = 7.989862322807312, ErrA = 5.2516104346977954e-05, ErrD = 0.16965349266926447\n",
      "Epoch = 528, ErrG = 7.672500789165497, ErrA = 0.00016228325699785273, ErrD = 0.11582544383903344\n",
      "Epoch = 530, ErrG = 7.485991954803467, ErrA = 0.0005245358292995661, ErrD = 0.22601295510927835\n",
      "Epoch = 532, ErrG = 8.76667594909668, ErrA = 2.5884011696083082e-05, ErrD = 0.20086409151554108\n",
      "Epoch = 534, ErrG = 6.727994441986084, ErrA = 1.877761421080019e-05, ErrD = 0.3139570926626523\n",
      "Epoch = 536, ErrG = 8.76380729675293, ErrA = 4.5561538475643225e-05, ErrD = 0.08143636522193749\n",
      "Epoch = 538, ErrG = 7.52375340461731, ErrA = 0.00285392347724193, ErrD = 0.1418602019548416\n",
      "Epoch = 540, ErrG = 8.153590440750122, ErrA = 1.4243871201339667e-05, ErrD = 0.19844234238068262\n",
      "Epoch = 542, ErrG = 8.930625200271606, ErrA = 0.0001229353159336218, ErrD = 0.17959005385637283\n",
      "Epoch = 544, ErrG = 8.323318719863892, ErrA = 5.72119837822053e-05, ErrD = 0.1745521817356348\n",
      "Epoch = 546, ErrG = 9.594643115997314, ErrA = 7.978171684423312e-05, ErrD = 0.16352502008279166\n",
      "Epoch = 548, ErrG = 8.502127170562744, ErrA = 1.5814472741719026e-05, ErrD = 0.15157724420229593\n",
      "Epoch = 550, ErrG = 7.81527841091156, ErrA = 0.0016476351162661256, ErrD = 0.21917485694090524\n",
      "Epoch = 552, ErrG = 7.39591908454895, ErrA = 2.2475979240728825e-06, ErrD = 0.2805467036863168\n",
      "Epoch = 554, ErrG = 9.25400698184967, ErrA = 8.371501285372082e-06, ErrD = 0.15113495041926703\n",
      "Epoch = 556, ErrG = 8.517302989959717, ErrA = 0.00021198795487483343, ErrD = 0.13132056624939045\n",
      "Epoch = 558, ErrG = 7.451868414878845, ErrA = 3.6359009148630625e-06, ErrD = 0.14297558863957724\n",
      "Epoch = 560, ErrG = 8.28059697151184, ErrA = 4.151879693381488e-06, ErrD = 0.06753425175944965\n",
      "Epoch = 562, ErrG = 7.26969301700592, ErrA = 5.371086524519342e-05, ErrD = 0.07288118700186412\n",
      "Epoch = 564, ErrG = 8.411961913108826, ErrA = 2.429041236003589e-05, ErrD = 0.36783400426308316\n",
      "Epoch = 566, ErrG = 7.5068970918655396, ErrA = 0.00014453068676327044, ErrD = 0.14059174805879593\n",
      "Epoch = 568, ErrG = 9.858803272247314, ErrA = 0.0012184619105658119, ErrD = 0.047667204712828\n",
      "Epoch = 570, ErrG = 7.975262641906738, ErrA = 1.5577817862322263e-05, ErrD = 0.10329252978165944\n",
      "Epoch = 572, ErrG = 8.619436740875244, ErrA = 2.8442685788832023e-06, ErrD = 0.1741525245209535\n",
      "Epoch = 574, ErrG = 9.67534875869751, ErrA = 2.1296401882864302e-05, ErrD = 0.42721075455968577\n",
      "Epoch = 576, ErrG = 8.778101563453674, ErrA = 0.00010306519296439849, ErrD = 0.22740743542090058\n",
      "Epoch = 578, ErrG = 7.5032572746276855, ErrA = 1.5135850920463175e-05, ErrD = 0.09770342955986659\n",
      "Epoch = 580, ErrG = 7.566616356372833, ErrA = 5.85165792775418e-05, ErrD = 0.10689750127494335\n",
      "Epoch = 582, ErrG = 8.98610532283783, ErrA = 9.114606746152276e-05, ErrD = 0.1719080607096354\n",
      "Epoch = 584, ErrG = 8.725075602531433, ErrA = 4.2130855338958405e-05, ErrD = 0.19258830696344376\n",
      "Epoch = 586, ErrG = 8.72410523891449, ErrA = 7.223848024295876e-05, ErrD = 0.0607844814658165\n",
      "Epoch = 588, ErrG = 8.858016312122345, ErrA = 7.460070022110206e-05, ErrD = 0.2165254553159078\n",
      "Epoch = 590, ErrG = 8.393404006958008, ErrA = 3.496246790746227e-06, ErrD = 0.11397227893273036\n",
      "Epoch = 592, ErrG = 8.905136346817017, ErrA = 4.113391203948898e-06, ErrD = 0.09530332187811534\n",
      "Epoch = 594, ErrG = 8.689864486455917, ErrA = 6.073518610113145e-06, ErrD = 0.1602832352121671\n",
      "Epoch = 596, ErrG = 8.67639970779419, ErrA = 3.707886132057562e-05, ErrD = 0.08355188742280006\n",
      "Epoch = 598, ErrG = 8.806016206741333, ErrA = 3.633602832072332e-05, ErrD = 0.14505354190866152\n",
      "Epoch = 600, ErrG = 10.1268190741539, ErrA = 4.999392785975942e-06, ErrD = 0.09886589149634044\n",
      "Epoch = 602, ErrG = 9.552758932113647, ErrA = 6.193274030389755e-05, ErrD = 0.10224977259834607\n",
      "Epoch = 604, ErrG = 9.618197560310364, ErrA = 5.668703503639942e-06, ErrD = 0.11437633198996384\n",
      "Epoch = 606, ErrG = 8.747193217277527, ErrA = 2.6265013426988542e-05, ErrD = 0.13561260451873144\n",
      "Epoch = 608, ErrG = 9.444525003433228, ErrA = 2.191720255950713e-06, ErrD = 0.36709917709231377\n",
      "Epoch = 610, ErrG = 9.683231949806213, ErrA = 3.2091343517966685e-05, ErrD = 0.17863773802916208\n",
      "Epoch = 612, ErrG = 8.163599729537964, ErrA = 0.00021851046283435002, ErrD = 0.08540107309818268\n",
      "Epoch = 614, ErrG = 10.241403937339783, ErrA = 0.00042909636977128685, ErrD = 0.12999325866500536\n",
      "Epoch = 616, ErrG = 8.52282527089119, ErrA = 2.520119032093741e-05, ErrD = 0.070885236064593\n",
      "Epoch = 618, ErrG = 6.407023906707764, ErrA = 3.1002263161402276e-05, ErrD = 0.11555880308151245\n",
      "Epoch = 620, ErrG = 8.449639439582825, ErrA = 0.0008545649338884687, ErrD = 0.15127229504287243\n",
      "Epoch = 622, ErrG = 7.351888537406921, ErrA = 9.509079368778355e-05, ErrD = 0.4511095794538657\n",
      "Epoch = 624, ErrG = 7.690687775611877, ErrA = 1.4506066463582101e-05, ErrD = 0.10633548845847447\n",
      "Epoch = 626, ErrG = 8.985152035951614, ErrA = 1.5998763577348047e-05, ErrD = 0.33437424525618553\n",
      "Epoch = 628, ErrG = 9.336618781089783, ErrA = 6.2976895378596964e-06, ErrD = 0.24761668592691422\n",
      "Epoch = 630, ErrG = 9.658814013004303, ErrA = 3.9362065921958823e-05, ErrD = 0.17220317820707956\n",
      "Epoch = 632, ErrG = 9.284895181655884, ErrA = 3.220955143963996e-05, ErrD = 0.04430713100979725\n",
      "Epoch = 634, ErrG = 7.695754706859589, ErrA = 8.183368341481886e-06, ErrD = 0.11634977037707965\n",
      "Epoch = 636, ErrG = 8.502420425415039, ErrA = 0.00012239992915397124, ErrD = 0.07094757755597432\n",
      "Epoch = 638, ErrG = 9.065815448760986, ErrA = 8.889685472013298e-05, ErrD = 0.12083694338798523\n",
      "Epoch = 640, ErrG = 8.293090760707855, ErrA = 0.0001274892517386661, ErrD = 0.2006011406580607\n",
      "Epoch = 642, ErrG = 8.42715311050415, ErrA = 7.672939820698351e-06, ErrD = 0.12259165694316228\n",
      "Epoch = 644, ErrG = 9.42798638343811, ErrA = 1.6994147093403928e-05, ErrD = 0.13175655653079352\n",
      "Epoch = 646, ErrG = 7.8416900634765625, ErrA = 3.256290377606774e-05, ErrD = 0.1504946000253161\n",
      "Epoch = 648, ErrG = 7.7354061007499695, ErrA = 0.00011146199024854771, ErrD = 0.25496892382701236\n",
      "Epoch = 650, ErrG = 10.284389019012451, ErrA = 1.9629379328497027e-05, ErrD = 0.14728272457917532\n",
      "Epoch = 652, ErrG = 9.241703033447266, ErrA = 6.593809454595127e-06, ErrD = 0.1429191486289104\n",
      "Epoch = 654, ErrG = 6.254884839057922, ErrA = 3.1870522207100294e-05, ErrD = 0.09190291988973816\n",
      "Epoch = 656, ErrG = 10.176851391792297, ErrA = 0.0006052120204174116, ErrD = 0.08578899999459584\n",
      "Epoch = 658, ErrG = 7.338848829269409, ErrA = 0.00013797001596079403, ErrD = 0.09702940254161756\n",
      "Epoch = 660, ErrG = 8.910319328308105, ErrA = 1.2906818483315874e-05, ErrD = 0.19362086802721024\n",
      "Epoch = 662, ErrG = 7.326668739318848, ErrA = 1.135496612884405e-05, ErrD = 0.291844201584657\n",
      "Epoch = 664, ErrG = 8.55511200428009, ErrA = 0.00200119364793494, ErrD = 0.16354213717083135\n",
      "Epoch = 666, ErrG = 7.986203610897064, ErrA = 4.691969782773716e-05, ErrD = 0.09298765783508618\n",
      "Epoch = 668, ErrG = 7.4573187828063965, ErrA = 1.3125476859462044e-06, ErrD = 0.7506356225349009\n",
      "Epoch = 670, ErrG = 9.977631092071533, ErrA = 1.1207156309941032e-05, ErrD = 0.0813328226407369\n",
      "Epoch = 672, ErrG = 9.139099955558777, ErrA = 0.0015384623160722792, ErrD = 0.16042208640525737\n",
      "Epoch = 674, ErrG = 9.788705945014954, ErrA = 0.0001962406159539872, ErrD = 0.10421116401751836\n",
      "Epoch = 676, ErrG = 10.579941272735596, ErrA = 1.8618272406456526e-05, ErrD = 0.14518020922938982\n",
      "Epoch = 678, ErrG = 6.777587890625, ErrA = 1.1496531840293756e-05, ErrD = 0.09363265459736188\n",
      "Epoch = 680, ErrG = 8.09294605255127, ErrA = 1.9554823078730504e-05, ErrD = 0.15087255835533142\n",
      "Epoch = 682, ErrG = 7.937509596347809, ErrA = 1.8858439261748572e-05, ErrD = 0.1877947822213173\n",
      "Epoch = 684, ErrG = 8.738824307918549, ErrA = 0.00023074480084990986, ErrD = 0.0973768640930454\n",
      "Epoch = 686, ErrG = 8.578134536743164, ErrA = 0.0005841186578360672, ErrD = 0.08545436648031075\n",
      "Epoch = 688, ErrG = 8.83129072189331, ErrA = 0.00013708969663876283, ErrD = 0.06129241455346346\n",
      "Epoch = 690, ErrG = 9.672741651535034, ErrA = 4.861507344836961e-07, ErrD = 0.14086509495973587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 692, ErrG = 6.815811634063721, ErrA = 0.00046585347100365954, ErrD = 0.05685470253229141\n",
      "Epoch = 694, ErrG = 8.090083122253418, ErrA = 0.0001284888943284083, ErrD = 0.11047945295770963\n",
      "Epoch = 696, ErrG = 8.739537358283997, ErrA = 1.194665545275105e-05, ErrD = 0.18067911826074123\n",
      "Epoch = 698, ErrG = 7.190846085548401, ErrA = 6.725269486670034e-05, ErrD = 0.17465874056021372\n",
      "Epoch = 700, ErrG = 7.692009449005127, ErrA = 6.864315734371e-05, ErrD = 0.08567465655505657\n"
     ]
    }
   ],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "g_k = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, g_k = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, g_k, target))\n",
    "\n",
    "low_loss = 10\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % g_k ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_img), 1)\n",
    "            noassd = th.cat((img, noass_img), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "#         if i % k ==0: \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model changed +Dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T09:39:59.973452Z",
     "start_time": "2019-06-17T01:57:16.530081Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 3.11608849465847, ErrA = 0.3182279219230016, ErrD = 0.047072598710656166, ErrP = 0.635548980285724\n",
      "Epoch = 4, ErrG = 4.2982336431741714, ErrA = 0.2356738063196341, ErrD = 0.01883645790318648, ErrP = 0.9297461515913407\n",
      "Epoch = 6, ErrG = 1.0726338624954224, ErrA = 0.4498101423184077, ErrD = 0.5129949947198232, ErrP = 0.795226939022541\n",
      "Epoch = 8, ErrG = 1.4125598818063736, ErrA = 0.40818140904108685, ErrD = 0.35858893394470215, ErrP = 0.7477960462371508\n",
      "Epoch = 10, ErrG = 1.2971711158752441, ErrA = 0.3943396210670471, ErrD = 0.5168332060178121, ErrP = 0.7842573672533035\n",
      "Epoch = 12, ErrG = 1.287300482392311, ErrA = 0.3967048724492391, ErrD = 0.4421286384264628, ErrP = 0.8709859227140745\n",
      "Epoch = 14, ErrG = 1.0789260566234589, ErrA = 0.45353100697199505, ErrD = 0.5167980094750723, ErrP = 0.774136196821928\n",
      "Epoch = 16, ErrG = 0.8869864493608475, ErrA = 0.4371970593929291, ErrD = 0.6796552538871765, ErrP = 0.8102466631680727\n",
      "Epoch = 18, ErrG = 1.1040828377008438, ErrA = 0.43446064988772076, ErrD = 0.5856244961420695, ErrP = 0.6524621372421583\n",
      "Epoch = 20, ErrG = 1.5743365585803986, ErrA = 0.3639599035183589, ErrD = 0.43913888931274414, ErrP = 0.7159374095499516\n",
      "Epoch = 22, ErrG = 1.1741504073143005, ErrA = 0.4575922464330991, ErrD = 0.5125841200351715, ErrP = 0.8690813792248567\n",
      "Epoch = 24, ErrG = 0.9921679496765137, ErrA = 0.38480012367169064, ErrD = 0.5621174176534017, ErrP = 0.8217711100975672\n",
      "Epoch = 26, ErrG = 1.0363421738147736, ErrA = 0.46229687829812366, ErrD = 0.4241172870000203, ErrP = 0.8312163054943085\n",
      "Epoch = 28, ErrG = 1.1397062838077545, ErrA = 0.4011822044849396, ErrD = 0.45830264687538147, ErrP = 0.6681243690351645\n",
      "Epoch = 30, ErrG = 1.4071866422891617, ErrA = 0.38188037772973377, ErrD = 0.40995074808597565, ErrP = 0.6695581128199896\n",
      "Epoch = 32, ErrG = 1.1891025006771088, ErrA = 0.3362823377052943, ErrD = 0.3947891543308894, ErrP = 0.662409337858359\n",
      "Epoch = 34, ErrG = 1.0166188180446625, ErrA = 0.34419340019424755, ErrD = 0.4755404442548752, ErrP = 0.9904106805721918\n",
      "Epoch = 36, ErrG = 1.2283896505832672, ErrA = 0.4162171185016632, ErrD = 0.3638679285844167, ErrP = 0.7598948702216148\n",
      "Epoch = 38, ErrG = 0.9992239326238632, ErrA = 0.4068928596874078, ErrD = 0.4350965271393458, ErrP = 0.8096957964201769\n",
      "Epoch = 40, ErrG = 1.3824594020843506, ErrA = 0.36300525938471156, ErrD = 0.40877606471379596, ErrP = 0.8712100728104512\n",
      "Epoch = 42, ErrG = 1.2453293204307556, ErrA = 0.3799069399634997, ErrD = 0.3822377622127533, ErrP = 0.9201420607666174\n",
      "Epoch = 44, ErrG = 1.0621535927057266, ErrA = 0.4236299855013688, ErrD = 0.3321152826150258, ErrP = 0.9451936135689417\n",
      "Epoch = 46, ErrG = 1.3870772421360016, ErrA = 0.32196173071861267, ErrD = 0.2859438632925351, ErrP = 0.9029737922052542\n",
      "Epoch = 48, ErrG = 1.3711837381124496, ErrA = 0.34020196258400875, ErrD = 0.3778358995914459, ErrP = 1.0457964756836493\n",
      "Epoch = 50, ErrG = 1.6930319517850876, ErrA = 0.2867518092195193, ErrD = 0.30354244510332745, ErrP = 0.9429981044183174\n",
      "Epoch = 52, ErrG = 1.340091496706009, ErrA = 0.40055552621682483, ErrD = 0.2569858729839325, ErrP = 0.897439144551754\n",
      "Epoch = 54, ErrG = 2.058052808046341, ErrA = 0.24639898538589478, ErrD = 0.20573778947194418, ErrP = 0.9447217161456744\n",
      "Epoch = 56, ErrG = 1.7389176189899445, ErrA = 0.3112149362762769, ErrD = 0.25423603256543476, ErrP = 0.911015788714091\n",
      "Epoch = 58, ErrG = 1.6213901042938232, ErrA = 0.36423999567826587, ErrD = 0.20207995673020682, ErrP = 0.9583916570991278\n",
      "Epoch = 60, ErrG = 1.078776940703392, ErrA = 0.34266503822679323, ErrD = 0.274546946088473, ErrP = 1.048351609458526\n",
      "Epoch = 62, ErrG = 1.8277203142642975, ErrA = 0.29929571350415546, ErrD = 0.20714595913887024, ErrP = 0.8017522245645523\n",
      "Epoch = 64, ErrG = 1.6000527441501617, ErrA = 0.3581246609489123, ErrD = 0.20593478282292685, ErrP = 1.0539203435182571\n",
      "Epoch = 66, ErrG = 1.8447787165641785, ErrA = 0.30967529614766437, ErrD = 0.2026944955190023, ErrP = 0.9359981268644333\n",
      "Epoch = 68, ErrG = 1.5364091098308563, ErrA = 0.35088662678996724, ErrD = 0.2037775864203771, ErrP = 0.9380694385617971\n",
      "Epoch = 70, ErrG = 1.546522170305252, ErrA = 0.3085363283753395, ErrD = 0.19982134799162546, ErrP = 0.960868322600921\n",
      "Epoch = 72, ErrG = 1.7061747163534164, ErrA = 0.2706872920195262, ErrD = 0.21600095431009927, ErrP = 0.8281299298008283\n",
      "Epoch = 74, ErrG = 1.6434307247400284, ErrA = 0.2989124196271102, ErrD = 0.17440377175807953, ErrP = 1.0959073919802904\n",
      "Epoch = 76, ErrG = 1.7615034580230713, ErrA = 0.22936961924036345, ErrD = 0.15117799242337546, ErrP = 1.0091341696679592\n",
      "Epoch = 78, ErrG = 1.711217537522316, ErrA = 0.2958945942421754, ErrD = 0.1894975205262502, ErrP = 0.8267409577965736\n",
      "Epoch = 80, ErrG = 1.5260185897350311, ErrA = 0.37766653299331665, ErrD = 0.17560207843780518, ErrP = 0.8343812823295593\n",
      "Epoch = 82, ErrG = 1.6317908465862274, ErrA = 0.32009759661741555, ErrD = 0.14874037355184555, ErrP = 1.165618270014723\n",
      "Epoch = 84, ErrG = 1.590462937951088, ErrA = 0.44493881861368817, ErrD = 0.18747702737649283, ErrP = 0.9825273665289084\n",
      "Epoch = 86, ErrG = 1.6890516877174377, ErrA = 0.3127552891770999, ErrD = 0.20978639523188272, ErrP = 1.0405098299185436\n",
      "Epoch = 88, ErrG = 1.9675623178482056, ErrA = 0.22462191929419836, ErrD = 0.1368756244579951, ErrP = 1.0160717020432155\n",
      "Epoch = 90, ErrG = 1.595568522810936, ErrA = 0.3545604733905445, ErrD = 0.1870418886343638, ErrP = 1.1553749696662028\n",
      "Epoch = 92, ErrG = 1.8570469170808792, ErrA = 0.2782715323846787, ErrD = 0.17811551690101624, ErrP = 1.2023746464401484\n",
      "Epoch = 94, ErrG = 1.6213532388210297, ErrA = 0.28487928584218025, ErrD = 0.155513733625412, ErrP = 0.9423844503859679\n",
      "Epoch = 96, ErrG = 1.735004484653473, ErrA = 0.28449624481921393, ErrD = 0.15376649548610052, ErrP = 1.227018790319562\n",
      "Epoch = 98, ErrG = 2.5051871985197067, ErrA = 0.3178820366350313, ErrD = 0.1306139181057612, ErrP = 1.1417688438668847\n",
      "Epoch = 100, ErrG = 1.856007605791092, ErrA = 0.2402787503475944, ErrD = 0.17024623602628708, ErrP = 0.9845856701334318\n",
      "Epoch = 102, ErrG = 1.7000474482774734, ErrA = 0.3519788064683477, ErrD = 0.16254337380329767, ErrP = 1.0675638373941183\n",
      "Epoch = 104, ErrG = 2.1459480077028275, ErrA = 0.2101601546164602, ErrD = 0.1238310734430949, ErrP = 1.0068117454648018\n",
      "Epoch = 106, ErrG = 1.8335850983858109, ErrA = 0.21838813150922456, ErrD = 0.13242150470614433, ErrP = 1.0323144731422265\n",
      "Epoch = 108, ErrG = 2.049081653356552, ErrA = 0.20245380885899067, ErrD = 0.07871496304869652, ErrP = 0.8697576969861984\n",
      "Epoch = 110, ErrG = 1.9909667372703552, ErrA = 0.3418249761064847, ErrD = 0.11036064475774765, ErrP = 1.028628242512544\n",
      "Epoch = 112, ErrG = 2.1664824187755585, ErrA = 0.28422387363389134, ErrD = 0.12229007979234059, ErrP = 1.4016301225249965\n",
      "Epoch = 114, ErrG = 2.1570135951042175, ErrA = 0.21034306567162275, ErrD = 0.09735676646232605, ErrP = 1.2528899510701497\n",
      "Epoch = 116, ErrG = 2.1596155762672424, ErrA = 0.25523344178994495, ErrD = 0.1749302571018537, ErrP = 1.1239705582459767\n",
      "Epoch = 118, ErrG = 2.4714950621128082, ErrA = 0.2500295725961526, ErrD = 0.06554701303442319, ErrP = 1.2215980254113674\n",
      "Epoch = 120, ErrG = 2.3341469764709473, ErrA = 0.21781860998210809, ErrD = 0.08620736127098401, ErrP = 1.3351287792126338\n",
      "Epoch = 122, ErrG = 1.5549822300672531, ErrA = 0.29937512675921124, ErrD = 0.11149851481119792, ErrP = 1.4055022268245618\n",
      "Epoch = 124, ErrG = 2.352166533470154, ErrA = 0.17957778800822174, ErrD = 0.07335694382588069, ErrP = 1.2456576774517696\n",
      "Epoch = 126, ErrG = 2.3182138055562973, ErrA = 0.29744890580574673, ErrD = 0.07902596890926361, ErrP = 1.1103915845354397\n",
      "Epoch = 128, ErrG = 2.6765777319669724, ErrA = 0.14579435480603328, ErrD = 0.06595352788766225, ErrP = 1.3054708205163479\n",
      "Epoch = 130, ErrG = 2.2225099951028824, ErrA = 0.2659878882889946, ErrD = 0.11439034342765808, ErrP = 1.157643790046374\n",
      "Epoch = 132, ErrG = 2.4729270339012146, ErrA = 0.14898553925255933, ErrD = 0.10310464849074681, ErrP = 1.2215078305453062\n",
      "Epoch = 134, ErrG = 2.628823146224022, ErrA = 0.2566115646623075, ErrD = 0.05589531113704046, ErrP = 1.3291144414494436\n",
      "Epoch = 136, ErrG = 1.8798249810934067, ErrA = 0.31919167541976395, ErrD = 0.08498829851547877, ErrP = 1.5589505738268297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 138, ErrG = 1.8848372548818588, ErrA = 0.37690639923675917, ErrD = 0.126130573451519, ErrP = 1.3815680195887883\n",
      "Epoch = 140, ErrG = 2.459674745798111, ErrA = 0.13985291744271913, ErrD = 0.052301390717426934, ErrP = 1.046545887986819\n",
      "Epoch = 142, ErrG = 2.4358335584402084, ErrA = 0.34625486967464286, ErrD = 0.04889713848630587, ErrP = 1.2343868588407834\n",
      "Epoch = 144, ErrG = 3.460209161043167, ErrA = 0.17166305863065645, ErrD = 0.06769575364887714, ErrP = 1.2942327298223972\n",
      "Epoch = 146, ErrG = 2.29889839887619, ErrA = 0.24675471087296805, ErrD = 0.06533551961183548, ErrP = 1.054988423983256\n",
      "Epoch = 148, ErrG = 2.555293306708336, ErrA = 0.19735413370653987, ErrD = 0.06869085381428401, ErrP = 1.0796024451653163\n",
      "Epoch = 150, ErrG = 2.8094538152217865, ErrA = 0.0653710098316272, ErrD = 0.09579195268452168, ErrP = 1.0603360533714294\n",
      "Epoch = 152, ErrG = 2.5584416687488556, ErrA = 0.15072270280991992, ErrD = 0.05339148143927256, ErrP = 1.2721886957685153\n",
      "Epoch = 154, ErrG = 3.065234363079071, ErrA = 0.06648408994078636, ErrD = 0.0344769861549139, ErrP = 1.1586276988188426\n",
      "Epoch = 156, ErrG = 2.8422532230615616, ErrA = 0.2088050510113438, ErrD = 0.07656850914160411, ErrP = 1.0630983412265778\n",
      "Epoch = 158, ErrG = 2.230551764369011, ErrA = 0.1297539435327053, ErrD = 0.0584945964316527, ErrP = 1.0101263026396434\n",
      "Epoch = 160, ErrG = 2.931489884853363, ErrA = 0.1429597835134094, ErrD = 0.04087099122504393, ErrP = 1.3847608976066113\n",
      "Epoch = 162, ErrG = 2.1225748360157013, ErrA = 0.39143685402571765, ErrD = 0.11650790056834619, ErrP = 1.3537618673096101\n",
      "Epoch = 164, ErrG = 3.2213172763586044, ErrA = 0.30098662339150906, ErrD = 0.043054512391487755, ErrP = 1.1624621128042538\n",
      "Epoch = 166, ErrG = 2.3533526957035065, ErrA = 0.39031341408068937, ErrD = 0.03345187287777662, ErrP = 1.2471127808094025\n",
      "Epoch = 168, ErrG = 2.328254833817482, ErrA = 0.21054057932148376, ErrD = 0.06320078282927473, ErrP = 1.1444453050692875\n",
      "Epoch = 170, ErrG = 3.4510884881019592, ErrA = 0.05310613941401243, ErrD = 0.022786700787643593, ErrP = 1.223762107392152\n",
      "Epoch = 172, ErrG = 2.516604036092758, ErrA = 0.12247133813798428, ErrD = 0.039156525706251465, ErrP = 1.1624854306379955\n",
      "Epoch = 174, ErrG = 2.6017229557037354, ErrA = 0.18051222432404757, ErrD = 0.037953648095329605, ErrP = 1.3427273022631805\n",
      "Epoch = 176, ErrG = 2.481088802218437, ErrA = 0.20942124064701298, ErrD = 0.0436241392356654, ErrP = 1.3749583785732586\n",
      "Epoch = 178, ErrG = 3.196464419364929, ErrA = 0.1749273519963026, ErrD = 0.036465954035520554, ErrP = 0.9780107686916987\n",
      "Epoch = 180, ErrG = 2.895561546087265, ErrA = 0.07714925205800682, ErrD = 0.03772760555148125, ErrP = 1.2403959532578785\n",
      "Epoch = 182, ErrG = 2.936705768108368, ErrA = 0.3172469027340412, ErrD = 0.04625908161203066, ErrP = 1.1198862195014954\n",
      "Epoch = 184, ErrG = 3.1503107100725174, ErrA = 0.22906107548624277, ErrD = 0.03803443846603235, ErrP = 1.0289642537633579\n",
      "Epoch = 186, ErrG = 3.3278605192899704, ErrA = 0.12181054955969255, ErrD = 0.03104962594807148, ErrP = 1.04185385008653\n",
      "Epoch = 188, ErrG = 3.4531172662973404, ErrA = 0.0684744679601863, ErrD = 0.03351061325520277, ErrP = 1.2319741634031136\n",
      "Epoch = 190, ErrG = 2.968939960002899, ErrA = 0.2695740839311232, ErrD = 0.02192818621794383, ErrP = 1.0543847779432933\n",
      "Epoch = 192, ErrG = 2.5603036284446716, ErrA = 0.2708364551266034, ErrD = 0.016161473157505196, ErrP = 1.0970303813616435\n",
      "Epoch = 194, ErrG = 2.905971273779869, ErrA = 0.11217217799276114, ErrD = 0.02461014191309611, ErrP = 1.2584355734288692\n",
      "Epoch = 196, ErrG = 3.7232704162597656, ErrA = 0.04458324966253713, ErrD = 0.022821160964667797, ErrP = 1.453015950197975\n",
      "Epoch = 198, ErrG = 2.8272368162870407, ErrA = 0.18838812907536825, ErrD = 0.023925994833310444, ErrP = 1.0896718104680378\n",
      "Epoch = 200, ErrG = 2.649711474776268, ErrA = 0.2888988106084677, ErrD = 0.057336971163749695, ErrP = 1.2927805511280894\n",
      "Epoch = 202, ErrG = 3.269980788230896, ErrA = 0.05971637492378553, ErrD = 0.02181640189761917, ErrP = 1.202980640033881\n",
      "Epoch = 204, ErrG = 2.8617545068264008, ErrA = 0.2085188823742404, ErrD = 0.0321613239745299, ErrP = 1.474567358692487\n",
      "Epoch = 206, ErrG = 3.7804818153381348, ErrA = 0.02180879469960928, ErrD = 0.01475980419976016, ErrP = 1.2111697283883889\n",
      "Epoch = 208, ErrG = 3.4167623966932297, ErrA = 0.12909785648419833, ErrD = 0.020098617766052485, ErrP = 1.5097653418779373\n",
      "Epoch = 210, ErrG = 2.920867383480072, ErrA = 0.1783713692178329, ErrD = 0.02145395738383134, ErrP = 1.1611675173044205\n",
      "Epoch = 212, ErrG = 3.734957665205002, ErrA = 0.11109729997891311, ErrD = 0.028175362075368564, ErrP = 1.2501844267050426\n",
      "Epoch = 214, ErrG = 2.50219389796257, ErrA = 0.12498183137116332, ErrD = 0.03585967173178991, ErrP = 1.5299595060447853\n",
      "Epoch = 216, ErrG = 3.4294790029525757, ErrA = 0.12313739024102688, ErrD = 0.008800811599940062, ErrP = 1.0239322098592918\n",
      "Epoch = 218, ErrG = 3.7258348166942596, ErrA = 0.19806181903307638, ErrD = 0.012102639768272638, ErrP = 1.137364823371172\n",
      "Epoch = 220, ErrG = 3.2015236169099808, ErrA = 0.19258495775284246, ErrD = 0.029887298432489235, ErrP = 1.530611666540305\n",
      "Epoch = 222, ErrG = 2.1406304836273193, ErrA = 0.1687038017747303, ErrD = 0.5723414278278748, ErrP = 1.3339864996572335\n",
      "Epoch = 224, ErrG = 3.163671091198921, ErrA = 0.10539187739292781, ErrD = 0.02557208016514778, ErrP = 1.2099330679823954\n",
      "Epoch = 226, ErrG = 4.10093280673027, ErrA = 0.02922101248987019, ErrD = 0.02492922005088379, ErrP = 1.2808811559031408\n",
      "Epoch = 228, ErrG = 3.5501176714897156, ErrA = 0.02517118367056052, ErrD = 0.012760964843134085, ErrP = 1.113321219260494\n",
      "Epoch = 230, ErrG = 3.099506676197052, ErrA = 0.10793135998149712, ErrD = 0.027266037960847218, ErrP = 1.436635044713815\n",
      "Epoch = 232, ErrG = 3.925727128982544, ErrA = 0.027391228129999945, ErrD = 0.02403634615863363, ErrP = 1.4145725493629773\n",
      "Epoch = 234, ErrG = 3.8414984941482544, ErrA = 0.0840505467785988, ErrD = 0.024483393567303818, ErrP = 1.4566255422929923\n",
      "Epoch = 236, ErrG = 4.44661571085453, ErrA = 0.05097754136659205, ErrD = 0.014123769477009773, ErrP = 1.402547689775626\n",
      "Epoch = 238, ErrG = 2.678475707769394, ErrA = 0.12164344407453125, ErrD = 0.020006633984545868, ErrP = 1.4848592733033001\n",
      "Epoch = 240, ErrG = 2.7295568585395813, ErrA = 0.25543863443696563, ErrD = 0.02200482537349065, ErrP = 1.4622835852205753\n",
      "Epoch = 242, ErrG = 3.2883408218622208, ErrA = 0.29994689355953597, ErrD = 0.029808702568213146, ErrP = 1.6821196998159091\n",
      "Epoch = 244, ErrG = 4.437204107642174, ErrA = 0.012811722544332346, ErrD = 0.00878203105336676, ErrP = 1.4252342364440362\n",
      "Epoch = 246, ErrG = 3.331426292657852, ErrA = 0.07916085176596728, ErrD = 0.02350099167476098, ErrP = 1.5973076249162357\n",
      "Epoch = 248, ErrG = 2.8283147364854813, ErrA = 0.12651548782984415, ErrD = 0.023291727838416893, ErrP = 1.1090799470742543\n",
      "Epoch = 250, ErrG = 4.479939788579941, ErrA = 0.01299003727035597, ErrD = 0.008288601510381946, ErrP = 1.0953923258930445\n",
      "Epoch = 252, ErrG = 3.4693237394094467, ErrA = 0.07274680584669113, ErrD = 0.0333523570249478, ErrP = 1.458757841338714\n",
      "Epoch = 254, ErrG = 3.561822772026062, ErrA = 0.2830491222751637, ErrD = 0.017461520930131275, ErrP = 1.4358072268466155\n",
      "Epoch = 256, ErrG = 3.4908761382102966, ErrA = 0.07783772158048426, ErrD = 0.020861235447227955, ErrP = 1.2907238385329645\n",
      "Epoch = 258, ErrG = 3.554177299141884, ErrA = 0.10550959408283234, ErrD = 0.013621009148967763, ErrP = 1.2171633020043373\n",
      "Epoch = 260, ErrG = 4.447719678282738, ErrA = 0.025287426232049864, ErrD = 0.010300399037078023, ErrP = 1.5511016491800547\n",
      "Epoch = 262, ErrG = 2.738629937171936, ErrA = 0.1606954429638184, ErrD = 0.02771852972606818, ErrP = 1.6374024363855522\n",
      "Epoch = 264, ErrG = 4.6674317717552185, ErrA = 0.006678451341334342, ErrD = 0.011372930991152922, ErrP = 1.5779716290029075\n",
      "Epoch = 266, ErrG = 3.322315126657486, ErrA = 0.2108952296936574, ErrD = 0.016322442640860874, ErrP = 1.3669284308950107\n",
      "Epoch = 268, ErrG = 3.379184380173683, ErrA = 0.060350773545602955, ErrD = 0.02447049816449483, ErrP = 1.398348165365557\n",
      "Epoch = 270, ErrG = 2.630442589521408, ErrA = 0.22861512703821063, ErrD = 0.025343636982142925, ErrP = 1.4219584117333095\n",
      "Epoch = 272, ErrG = 3.148872047662735, ErrA = 0.15344067507976433, ErrD = 0.030855638440698385, ErrP = 1.5648510462294023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 274, ErrG = 4.246414482593536, ErrA = 0.07158860199463864, ErrD = 0.017607325144732993, ErrP = 1.0888368937497337\n",
      "Epoch = 276, ErrG = 5.505197733640671, ErrA = 0.01899628232543667, ErrD = 0.036937227783103786, ErrP = 1.6035501429190238\n",
      "Epoch = 278, ErrG = 5.23977318406105, ErrA = 0.007394160100375302, ErrD = 0.005038390149517606, ErrP = 1.736711440763126\n",
      "Epoch = 280, ErrG = 3.1377120912075043, ErrA = 0.08311231819849733, ErrD = 0.014951018461336693, ErrP = 1.611320825914542\n",
      "Epoch = 282, ErrG = 1.8737804591655731, ErrA = 0.10378054933001597, ErrD = 0.14773708581924438, ErrP = 1.1504630371928215\n",
      "Epoch = 284, ErrG = 4.510046571493149, ErrA = 0.01151328650303185, ErrD = 0.01227961697926124, ErrP = 1.310951016843319\n",
      "Epoch = 286, ErrG = 2.898777276277542, ErrA = 0.1016156747743177, ErrD = 0.021115196558336418, ErrP = 1.3343367502093315\n",
      "Epoch = 288, ErrG = 3.0274031162261963, ErrA = 0.08210172741140316, ErrD = 0.016999583691358566, ErrP = 1.3390904019276302\n",
      "Epoch = 290, ErrG = 3.3955919593572617, ErrA = 0.1402145978451396, ErrD = 0.021370313906421263, ErrP = 1.2738276186088722\n",
      "Epoch = 292, ErrG = 5.434290170669556, ErrA = 0.03534048417350277, ErrD = 0.02479444940884908, ErrP = 1.7936204017993684\n",
      "Epoch = 294, ErrG = 3.9578896164894104, ErrA = 0.10924327123211697, ErrD = 0.06803862750530243, ErrP = 1.5644575878977776\n",
      "Epoch = 296, ErrG = 4.1578347980976105, ErrA = 0.030529422064622242, ErrD = 0.020573371400435764, ErrP = 1.0257026217877865\n",
      "Epoch = 298, ErrG = 3.114032283425331, ErrA = 0.19896770210228473, ErrD = 0.04078506173876425, ErrP = 1.7203754832347233\n",
      "Epoch = 300, ErrG = 3.1856055855751038, ErrA = 0.09708927913258474, ErrD = 0.025184507151910413, ErrP = 1.3935399415592353\n",
      "Epoch = 302, ErrG = 5.564310640096664, ErrA = 0.010347934223924918, ErrD = 0.00793706082428495, ErrP = 1.4597067480596404\n",
      "Epoch = 304, ErrG = 3.211424171924591, ErrA = 0.26294020904848975, ErrD = 0.04064286624391874, ErrP = 1.0316454445322354\n",
      "Epoch = 306, ErrG = 3.8107632398605347, ErrA = 0.05327844371640822, ErrD = 0.032373559971650444, ErrP = 1.361421674489975\n",
      "Epoch = 308, ErrG = 4.030296832323074, ErrA = 0.102137302737295, ErrD = 0.012882241979241371, ErrP = 1.371653544716537\n",
      "Epoch = 310, ErrG = 4.102943047881126, ErrA = 0.009271901954586307, ErrD = 0.011309609826033315, ErrP = 1.366819358120362\n",
      "Epoch = 312, ErrG = 3.6406419575214386, ErrA = 0.04428577562794089, ErrD = 0.011037992973191043, ErrP = 1.3843326829373837\n",
      "Epoch = 314, ErrG = 2.948371648788452, ErrA = 0.0608523959951223, ErrD = 0.032258239264289536, ErrP = 1.8688666876405478\n",
      "Epoch = 316, ErrG = 5.223025664687157, ErrA = 0.04628375634395828, ErrD = 0.035251873234907784, ErrP = 1.5478730210258316\n",
      "Epoch = 318, ErrG = 3.6576716005802155, ErrA = 0.08060415989408891, ErrD = 0.012818537962933382, ErrP = 1.4132314051191013\n",
      "Epoch = 320, ErrG = 4.12355063855648, ErrA = 0.011979966511717066, ErrD = 0.019548316156336416, ErrP = 1.4865437783300877\n",
      "Epoch = 322, ErrG = 3.748492792248726, ErrA = 0.08924297976773232, ErrD = 0.018157059676013887, ErrP = 1.8556163019190233\n",
      "Epoch = 324, ErrG = 3.420336276292801, ErrA = 0.026832638259899493, ErrD = 0.022690851396570604, ErrP = 1.6724609307323892\n",
      "Epoch = 326, ErrG = 4.056762084364891, ErrA = 0.06140877272506865, ErrD = 0.010183074492185066, ErrP = 1.7368382525940735\n",
      "Epoch = 328, ErrG = 3.1723693907260895, ErrA = 0.11267875802392761, ErrD = 0.01954653513773034, ErrP = 1.154784943908453\n",
      "Epoch = 330, ErrG = 4.983267456293106, ErrA = 0.04139066549638907, ErrD = 0.02303469522545735, ErrP = 1.1441757366992533\n",
      "Epoch = 332, ErrG = 3.1621525436639786, ErrA = 0.2071882076561451, ErrD = 0.017719968629535288, ErrP = 1.3503728707631428\n",
      "Epoch = 334, ErrG = 3.2682865113019943, ErrA = 0.1610174579230564, ErrD = 0.020008438577254612, ErrP = 1.7333516261229913\n",
      "Epoch = 336, ErrG = 4.426431119441986, ErrA = 0.014516709023155272, ErrD = 0.023330647343148787, ErrP = 1.103268997122844\n",
      "Epoch = 338, ErrG = 3.6525750905275345, ErrA = 0.06532792196351996, ErrD = 0.011339972261339426, ErrP = 1.5833073283235233\n",
      "Epoch = 340, ErrG = 4.867937088012695, ErrA = 0.007113338681847381, ErrD = 0.012456767008795092, ErrP = 1.5449132472276688\n",
      "Epoch = 342, ErrG = 3.6432966589927673, ErrA = 0.01446156029123813, ErrD = 0.013715877081267536, ErrP = 1.3978921920061111\n",
      "Epoch = 344, ErrG = 4.505731821060181, ErrA = 0.009575027885148302, ErrD = 0.01653878643022229, ErrP = 1.3001678430785735\n",
      "Epoch = 346, ErrG = 4.3459049463272095, ErrA = 0.01295664372931545, ErrD = 0.0067568903614301234, ErrP = 1.5219742733364303\n",
      "Epoch = 348, ErrG = 3.429488569498062, ErrA = 0.05196146247908473, ErrD = 0.01709532303114732, ErrP = 1.1425070464611053\n",
      "Epoch = 350, ErrG = 5.214934810996056, ErrA = 0.004172558936261339, ErrD = 0.014777165721170604, ErrP = 1.7111040045274422\n",
      "Epoch = 352, ErrG = 3.623751997947693, ErrA = 0.08954081302848256, ErrD = 0.01370267104357481, ErrP = 1.6352973853548367\n",
      "Epoch = 354, ErrG = 4.624623417854309, ErrA = 0.07927535785385469, ErrD = 0.014153805250922838, ErrP = 1.7418605064352353\n",
      "Epoch = 356, ErrG = 4.446437299251556, ErrA = 0.023749889029810827, ErrD = 0.016059359613185126, ErrP = 1.3165066602329414\n",
      "Epoch = 358, ErrG = 3.7912749648094177, ErrA = 0.027102292275230866, ErrD = 0.01592697948217392, ErrP = 1.6726756676410635\n",
      "Epoch = 360, ErrG = 4.049764305353165, ErrA = 0.03513614435905765, ErrD = 0.007805502973496914, ErrP = 1.7500905332465966\n",
      "Epoch = 362, ErrG = 4.412889301776886, ErrA = 0.01322483674933513, ErrD = 0.011664936260785908, ErrP = 1.5789248812943697\n",
      "Epoch = 364, ErrG = 3.431992009282112, ErrA = 0.2529153076611692, ErrD = 0.027952478538888197, ErrP = 1.6372595727443695\n",
      "Epoch = 366, ErrG = 3.280508831143379, ErrA = 0.052585617115255445, ErrD = 0.01774588879197836, ErrP = 1.6149933164318402\n",
      "Epoch = 368, ErrG = 3.639445573091507, ErrA = 0.09438098222017288, ErrD = 0.014535864194234213, ErrP = 1.604287429402272\n",
      "Epoch = 370, ErrG = 4.249174475669861, ErrA = 0.011697840740453103, ErrD = 0.030902943573892117, ErrP = 1.554204976496597\n",
      "Epoch = 372, ErrG = 4.902543053030968, ErrA = 0.008120849747986844, ErrD = 0.003921489042113535, ErrP = 1.3315973033507664\n",
      "Epoch = 374, ErrG = 3.020394280552864, ErrA = 0.25137445435636135, ErrD = 0.029239605957021315, ErrP = 1.6257269455042358\n",
      "Epoch = 376, ErrG = 4.980644166469574, ErrA = 0.005229919236929466, ErrD = 0.010720991025057932, ErrP = 1.5305623390401404\n",
      "Epoch = 378, ErrG = 1.0610596984624863, ErrA = 0.18373900528058584, ErrD = 0.3597963899374008, ErrP = 1.7641923925063263\n",
      "Epoch = 380, ErrG = 3.347721666097641, ErrA = 0.07673312834231183, ErrD = 0.028255749338616926, ErrP = 1.4460664639870326\n",
      "Epoch = 382, ErrG = 4.050953716039658, ErrA = 0.14297279162080181, ErrD = 0.039383160726477705, ErrP = 1.7667545297493537\n",
      "Epoch = 384, ErrG = 4.082804784178734, ErrA = 0.0324281089597207, ErrD = 0.07908035566409428, ErrP = 1.6426065949102242\n",
      "Epoch = 386, ErrG = 3.2540557980537415, ErrA = 0.03479762375373715, ErrD = 0.021396068545679253, ErrP = 1.825590057298541\n",
      "Epoch = 388, ErrG = 4.005834758281708, ErrA = 0.06760810501873493, ErrD = 0.004764293689125528, ErrP = 1.3077252407868702\n",
      "Epoch = 390, ErrG = 3.6822333931922913, ErrA = 0.06785064873596032, ErrD = 0.01692408292243878, ErrP = 1.274198405444622\n",
      "Epoch = 392, ErrG = 4.1564686596393585, ErrA = 0.12213809666354791, ErrD = 0.04400784273942312, ErrP = 1.65232921645899\n",
      "Epoch = 394, ErrG = 4.658600553870201, ErrA = 0.005481032156846292, ErrD = 0.01703374336163203, ErrP = 1.7614417150616646\n",
      "Epoch = 396, ErrG = 5.3988684713840485, ErrA = 0.002203647658461705, ErrD = 0.012307109000782171, ErrP = 1.1744567800002794\n",
      "Epoch = 398, ErrG = 5.196159705519676, ErrA = 0.048039427667390555, ErrD = 0.00957931112498045, ErrP = 1.7418985196078818\n",
      "Epoch = 400, ErrG = 3.6536252200603485, ErrA = 0.021151902631875902, ErrD = 0.03644123392587062, ErrP = 1.7271915848056476\n",
      "Epoch = 402, ErrG = 3.552785560488701, ErrA = 0.047453176852172874, ErrD = 0.029786800655225914, ErrP = 1.6510584546873968\n",
      "Epoch = 404, ErrG = 2.944999858736992, ErrA = 0.12031694378068399, ErrD = 0.040338986941302814, ErrP = 1.8543395232409239\n",
      "Epoch = 406, ErrG = 3.676711082458496, ErrA = 0.028330687477136962, ErrD = 0.011534223856870085, ErrP = 1.6532569505895178\n",
      "Epoch = 408, ErrG = 5.099562108516693, ErrA = 0.011837740331732979, ErrD = 0.013121926846603552, ErrP = 1.5658965408802032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 410, ErrG = 3.533279463648796, ErrA = 0.18423704275240502, ErrD = 0.02176489882792036, ErrP = 1.0999428828557332\n",
      "Epoch = 412, ErrG = 4.836178123950958, ErrA = 0.025415120626954984, ErrD = 0.014120173950990042, ErrP = 1.5275077670812607\n",
      "Epoch = 414, ErrG = 4.70133513212204, ErrA = 0.02017675046226941, ErrD = 0.018193533644080162, ErrP = 1.4544565848385294\n",
      "Epoch = 416, ErrG = 3.393650382757187, ErrA = 0.09150503514668647, ErrD = 0.016030723229050636, ErrP = 1.7136773901681106\n",
      "Epoch = 418, ErrG = 5.0546484142541885, ErrA = 0.026691945117969833, ErrD = 0.0371281080879271, ErrP = 1.7391536757349968\n",
      "Epoch = 420, ErrG = 4.21792396903038, ErrA = 0.008521542561841974, ErrD = 0.0178439828256766, ErrP = 1.5578158454348643\n",
      "Epoch = 422, ErrG = 4.1009859293699265, ErrA = 0.037448210399209834, ErrD = 0.02382975568373998, ErrP = 1.2971549574285746\n",
      "Epoch = 424, ErrG = 5.2505334466695786, ErrA = 0.06564981438956845, ErrD = 0.020380170550197363, ErrP = 1.4769948869943619\n",
      "Epoch = 426, ErrG = 4.59053048491478, ErrA = 0.019089079537176683, ErrD = 0.007897404721006751, ErrP = 1.7497440502047539\n",
      "Epoch = 428, ErrG = 3.5910790860652924, ErrA = 0.04831132905868193, ErrD = 0.015880810096859932, ErrP = 1.4372405037283897\n",
      "Epoch = 430, ErrG = 4.235274910926819, ErrA = 0.04038103857343837, ErrD = 0.020560748564700287, ErrP = 1.8811497911810875\n",
      "Epoch = 432, ErrG = 4.779917448759079, ErrA = 0.01785208475333396, ErrD = 0.013957717766364416, ErrP = 1.7427192855005462\n",
      "Epoch = 434, ErrG = 2.636063441634178, ErrA = 0.1564102184396082, ErrD = 0.04326044643676141, ErrP = 1.6712252050638199\n",
      "Epoch = 436, ErrG = 4.121873766183853, ErrA = 0.046120647923089564, ErrD = 0.04079342897360524, ErrP = 1.2951195042890806\n",
      "Epoch = 438, ErrG = 4.634121745824814, ErrA = 0.02672590756264981, ErrD = 0.017099141143262386, ErrP = 1.7617307264978688\n",
      "Epoch = 440, ErrG = 6.443788677453995, ErrA = 0.004322896557672114, ErrD = 0.01214771019294858, ErrP = 1.7941905995054792\n",
      "Epoch = 442, ErrG = 4.028608828783035, ErrA = 0.20141757000237703, ErrD = 0.01613050326704979, ErrP = 1.4720251460870106\n",
      "Epoch = 444, ErrG = 6.064371883869171, ErrA = 0.0018662857110030018, ErrD = 0.015878518538859982, ErrP = 1.462886041321326\n",
      "Epoch = 446, ErrG = 2.000549465417862, ErrA = 0.10879240372711745, ErrD = 0.36869387080272037, ErrP = 1.7267586048692465\n",
      "Epoch = 448, ErrG = 3.755537122488022, ErrA = 0.04470895790533783, ErrD = 0.013426770456135273, ErrP = 1.3049680838982265\n",
      "Epoch = 450, ErrG = 3.2002732306718826, ErrA = 0.08354390647339945, ErrD = 0.013631435111165047, ErrP = 1.2846942618489265\n",
      "Epoch = 452, ErrG = 4.28850793838501, ErrA = 0.010313679405953735, ErrD = 0.012690173035177091, ErrP = 1.1712310587366421\n",
      "Epoch = 454, ErrG = 3.91151325404644, ErrA = 0.06978053622879088, ErrD = 0.017794248337546986, ErrP = 1.452213444126149\n",
      "Epoch = 456, ErrG = 5.315223008394241, ErrA = 0.0056082056738281, ErrD = 0.022968669538386166, ErrP = 1.4149065444556375\n",
      "Epoch = 458, ErrG = 3.9485403299331665, ErrA = 0.011196531408738034, ErrD = 0.06600944076975186, ErrP = 1.620012448169291\n",
      "Epoch = 460, ErrG = 3.868808552622795, ErrA = 0.03274757352968057, ErrD = 0.018838540961345036, ErrP = 1.2507401493688424\n",
      "Epoch = 462, ErrG = 4.845899328589439, ErrA = 0.008153642401642477, ErrD = 0.016545713568727177, ErrP = 1.7097073993645608\n",
      "Epoch = 464, ErrG = 3.8792702108621597, ErrA = 0.08934547302002709, ErrD = 0.013212218259771666, ErrP = 1.5172086600214243\n",
      "Epoch = 466, ErrG = 3.4991247355937958, ErrA = 0.06375106920798619, ErrD = 0.02717115047077338, ErrP = 1.1221931676069896\n",
      "Epoch = 468, ErrG = 5.132449969649315, ErrA = 0.052919020633756496, ErrD = 0.017721110333998997, ErrP = 1.7727805952696751\n",
      "Epoch = 470, ErrG = 4.952626138925552, ErrA = 0.019314312191757683, ErrD = 0.01631755040337642, ErrP = 1.5282613293578227\n",
      "Epoch = 472, ErrG = 4.881568625569344, ErrA = 0.022571394220335605, ErrD = 0.01381408330053091, ErrP = 1.927378254942596\n",
      "Epoch = 474, ErrG = 5.777593061327934, ErrA = 0.18198320389152892, ErrD = 0.01709125904987256, ErrP = 1.743409726380681\n",
      "Epoch = 476, ErrG = 3.8197363913059235, ErrA = 0.043813553655885094, ErrD = 0.017155480260650318, ErrP = 1.7320722341537476\n",
      "Epoch = 478, ErrG = 4.1285707503557205, ErrA = 0.05314412841107696, ErrD = 0.015606563227872053, ErrP = 1.4937356443454821\n",
      "Epoch = 480, ErrG = 3.8523504734039307, ErrA = 0.03991955053061247, ErrD = 0.01240155597527822, ErrP = 1.4477753999332588\n",
      "Epoch = 482, ErrG = 5.180457890033722, ErrA = 0.008391045664514726, ErrD = 0.013584122605000934, ErrP = 1.4284703457572807\n",
      "Epoch = 484, ErrG = 5.3257176131010056, ErrA = 0.005938933609286323, ErrD = 0.008030393781761328, ErrP = 1.3777602926517527\n",
      "Epoch = 486, ErrG = 5.24277999997139, ErrA = 0.007971072831423953, ErrD = 0.008583240521450838, ErrP = 1.349164729937911\n",
      "Epoch = 488, ErrG = 2.952293246984482, ErrA = 0.07736978734222551, ErrD = 0.0540912381062905, ErrP = 1.24656275458013\n",
      "Epoch = 490, ErrG = 4.757376939058304, ErrA = 0.0071932796878779, ErrD = 0.00897862894150118, ErrP = 2.015352905727923\n",
      "Epoch = 492, ErrG = 4.152436777949333, ErrA = 0.02817217112169601, ErrD = 0.015331467953122532, ErrP = 1.5250184065662324\n",
      "Epoch = 494, ErrG = 5.6243738532066345, ErrA = 0.040449776418427064, ErrD = 0.020378969764957826, ErrP = 1.7592233574638765\n",
      "Epoch = 496, ErrG = 3.2036648243665695, ErrA = 0.04549794681467271, ErrD = 0.16616532703240713, ErrP = 1.538736669967572\n",
      "Epoch = 498, ErrG = 5.316892206668854, ErrA = 0.05784270229461678, ErrD = 0.01806748037536939, ErrP = 2.025619210132087\n",
      "Epoch = 500, ErrG = 5.106313914060593, ErrA = 0.039899066347667635, ErrD = 0.011514590587466955, ErrP = 1.7106765545904636\n",
      "Epoch = 502, ErrG = 4.818808138370514, ErrA = 0.025646984266738098, ErrD = 0.013897571169460813, ErrP = 1.4782650900694232\n",
      "Epoch = 504, ErrG = 4.849469095468521, ErrA = 0.008382676479717096, ErrD = 0.0263714287430048, ErrP = 1.498638268870612\n",
      "Epoch = 506, ErrG = 4.015105724334717, ErrA = 0.04234835299818466, ErrD = 0.012710492863940695, ErrP = 1.8575666174292564\n",
      "Epoch = 508, ErrG = 4.459519937634468, ErrA = 0.010680730146759743, ErrD = 0.015829458289469283, ErrP = 1.8535449695773423\n",
      "Epoch = 510, ErrG = 5.788693994283676, ErrA = 0.019375289895833703, ErrD = 0.01250694195429484, ErrP = 1.6912994045220937\n",
      "Epoch = 512, ErrG = 3.8490554839372635, ErrA = 0.023584228724454686, ErrD = 0.01649355577925841, ErrP = 1.5023459169703226\n",
      "Epoch = 514, ErrG = 4.812599629163742, ErrA = 0.03178301909550404, ErrD = 0.006688111539309223, ErrP = 1.5821631227930386\n",
      "Epoch = 516, ErrG = 4.5076839327812195, ErrA = 0.004682914199444592, ErrD = 0.017947321602453787, ErrP = 1.9068797915242612\n",
      "Epoch = 518, ErrG = 4.517958343029022, ErrA = 0.003600760674279021, ErrD = 0.024730984432001907, ErrP = 1.6660699512188633\n",
      "Epoch = 520, ErrG = 2.919351488351822, ErrA = 0.011012181952537503, ErrD = 0.12432678726812203, ErrP = 1.7604738498727481\n",
      "Epoch = 522, ErrG = 5.104165762662888, ErrA = 0.044257562762747206, ErrD = 0.019639538290599983, ErrP = 1.46029007807374\n",
      "Epoch = 524, ErrG = 5.105029404163361, ErrA = 0.07104474880793532, ErrD = 0.019892089844991762, ErrP = 1.9278370338336874\n",
      "Epoch = 526, ErrG = 4.151278644800186, ErrA = 0.09177160821856016, ErrD = 0.015030538042386373, ErrP = 2.0866202376782894\n",
      "Epoch = 528, ErrG = 4.008408308029175, ErrA = 0.02885425566637423, ErrD = 0.03279315975184242, ErrP = 1.812276397831738\n",
      "Epoch = 530, ErrG = 5.956414803862572, ErrA = 0.004194071943250795, ErrD = 0.007969475021430602, ErrP = 1.413370788252602\n",
      "Epoch = 532, ErrG = 3.230537936091423, ErrA = 0.030045914791116957, ErrD = 0.02152506448328495, ErrP = 1.7999978358857334\n",
      "Epoch = 534, ErrG = 6.1876708418130875, ErrA = 0.0008565238717134586, ErrD = 0.005255846229071419, ErrP = 2.031667220774883\n",
      "Epoch = 536, ErrG = 2.575525239109993, ErrA = 0.12545513610060274, ErrD = 0.09796724716822307, ErrP = 1.972604184721907\n",
      "Epoch = 538, ErrG = 4.788540184497833, ErrA = 0.004397226177388802, ErrD = 0.008143910866541168, ErrP = 1.7772778455788891\n",
      "Epoch = 540, ErrG = 3.940616488456726, ErrA = 0.05850705820679044, ErrD = 0.016306688077747822, ErrP = 1.7281649460395176\n",
      "Epoch = 542, ErrG = 5.160715967416763, ErrA = 0.004844214500432524, ErrD = 0.006511490190556894, ErrP = 1.6860370746192832\n",
      "Epoch = 544, ErrG = 3.99858520925045, ErrA = 0.07660831744336367, ErrD = 0.04931680920223395, ErrP = 1.563105274612705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 546, ErrG = 5.477801129221916, ErrA = 0.002713428737782427, ErrD = 0.019839648467799027, ErrP = 2.1226077305230624\n",
      "Epoch = 548, ErrG = 4.065415054559708, ErrA = 0.02102125537445924, ErrD = 0.01617185352370143, ErrP = 1.604040424649914\n",
      "Epoch = 550, ErrG = 4.537599295377731, ErrA = 0.02919076700466879, ErrD = 0.018528030486777425, ErrP = 1.8433641091299553\n",
      "Epoch = 552, ErrG = 5.152814447879791, ErrA = 0.00454806725247181, ErrD = 0.006922723812749609, ErrP = 1.7361562778241932\n",
      "Epoch = 554, ErrG = 5.766420602798462, ErrA = 0.002164118593403449, ErrD = 0.003644603304564953, ErrP = 1.7609650113154203\n",
      "Epoch = 556, ErrG = 6.486919894814491, ErrA = 0.015705314464867115, ErrD = 0.015900192471841972, ErrP = 1.5003225519321859\n",
      "Epoch = 558, ErrG = 3.902671664953232, ErrA = 0.029854742927303352, ErrD = 0.009534214972518384, ErrP = 1.8170404036839802\n",
      "Epoch = 560, ErrG = 5.419224604964256, ErrA = 0.011814371981017757, ErrD = 0.007371207776789864, ErrP = 1.7574417429665725\n",
      "Epoch = 562, ErrG = 4.25486096739769, ErrA = 0.09930113827294917, ErrD = 0.013329934639235338, ErrP = 2.245753419575825\n",
      "Epoch = 564, ErrG = 4.485495433211327, ErrA = 0.14242165194203457, ErrD = 0.009109554967532555, ErrP = 1.6619871243213613\n",
      "Epoch = 566, ErrG = 5.453042834997177, ErrA = 0.003230851800860061, ErrD = 0.011691393796354532, ErrP = 2.0329767231984683\n",
      "Epoch = 568, ErrG = 5.716367721557617, ErrA = 0.07367974088265328, ErrD = 0.033570642893513046, ErrP = 1.9027188983357821\n",
      "Epoch = 570, ErrG = 3.6901838034391403, ErrA = 0.07623792849335587, ErrD = 0.06601175044973691, ErrP = 1.707496453076601\n",
      "Epoch = 572, ErrG = 5.509504020214081, ErrA = 0.005014595178863601, ErrD = 0.0054384922453512745, ErrP = 2.0507874616111317\n",
      "Epoch = 574, ErrG = 3.2298920452594757, ErrA = 0.08216157014248893, ErrD = 0.06972390164931615, ErrP = 1.9215647159144282\n",
      "Epoch = 576, ErrG = 4.938035234808922, ErrA = 0.08172036228521999, ErrD = 0.0313461326683561, ErrP = 1.6965156644582748\n",
      "Epoch = 578, ErrG = 3.867636054754257, ErrA = 0.03379365665023215, ErrD = 0.05350574323286613, ErrP = 1.52009500314792\n",
      "Epoch = 580, ErrG = 3.609742134809494, ErrA = 0.009329829524328185, ErrD = 0.03795099134246508, ErrP = 1.9319113135958712\n",
      "Epoch = 582, ErrG = 6.0319326519966125, ErrA = 0.004192071384750307, ErrD = 0.012597775552421808, ErrP = 2.5030891590965134\n",
      "Epoch = 584, ErrG = 4.739324793219566, ErrA = 0.012647992431690605, ErrD = 0.008541367948055267, ErrP = 1.7832085816189647\n",
      "Epoch = 586, ErrG = 4.703875854611397, ErrA = 0.0026779183535836637, ErrD = 0.028494248205485444, ErrP = 1.610566915536765\n",
      "Epoch = 588, ErrG = 3.5166450440883636, ErrA = 0.04669055568319891, ErrD = 0.012796550833930572, ErrP = 2.074266977918645\n",
      "Epoch = 590, ErrG = 4.5733079463243484, ErrA = 0.005157960905307846, ErrD = 0.031239092922381435, ErrP = 2.0766145427866527\n",
      "Epoch = 592, ErrG = 4.157914161682129, ErrA = 0.006748299502457182, ErrD = 0.04263108844558398, ErrP = 1.7011738354340196\n",
      "Epoch = 594, ErrG = 4.48410028219223, ErrA = 0.014082220315079516, ErrD = 0.011999949968109528, ErrP = 1.6850684626648824\n",
      "Epoch = 596, ErrG = 4.263223201036453, ErrA = 0.014561300797140575, ErrD = 0.014698139314229289, ErrP = 2.1795361690844097\n",
      "Epoch = 598, ErrG = 4.464149296283722, ErrA = 0.009830104498253908, ErrD = 0.021091028194253642, ErrP = 2.2296195415935167\n",
      "Epoch = 600, ErrG = 5.236704349517822, ErrA = 0.012548412196584499, ErrD = 0.011712287552654743, ErrP = 2.0971250716441623\n",
      "Epoch = 602, ErrG = 6.534312963485718, ErrA = 0.0013470861207072933, ErrD = 0.011166797329982122, ErrP = 1.7922766306437552\n",
      "Epoch = 604, ErrG = 3.9769757986068726, ErrA = 0.01554448221425749, ErrD = 0.028857339173555374, ErrP = 1.6354820585499208\n",
      "Epoch = 606, ErrG = 4.878310739994049, ErrA = 0.006078398180155394, ErrD = 0.010747734534864625, ErrP = 1.7707539098337293\n",
      "Epoch = 608, ErrG = 4.749947503209114, ErrA = 0.01864184779697098, ErrD = 0.010218711569905281, ErrP = 1.8637896753692378\n",
      "Epoch = 610, ErrG = 4.254722028970718, ErrA = 0.014248809280009786, ErrD = 0.02058687371512254, ErrP = 1.8870586277917027\n",
      "Epoch = 612, ErrG = 5.30147510766983, ErrA = 0.028134524667014677, ErrD = 0.014107659071063003, ErrP = 1.4506773960310966\n",
      "Epoch = 614, ErrG = 4.845551371574402, ErrA = 0.006443423459434901, ErrD = 0.00934758223593235, ErrP = 1.451788098551333\n",
      "Epoch = 616, ErrG = 3.336400032043457, ErrA = 0.040781630312267225, ErrD = 0.10238289460539818, ErrP = 1.7202747681488593\n",
      "Epoch = 618, ErrG = 5.0932615250349045, ErrA = 0.0810280275460779, ErrD = 0.022155221551656723, ErrP = 1.947997032587106\n",
      "Epoch = 620, ErrG = 5.280951231718063, ErrA = 0.0049371450950275175, ErrD = 0.005084937671199441, ErrP = 1.9250283556369443\n",
      "Epoch = 622, ErrG = 6.55303892493248, ErrA = 0.003567102807816506, ErrD = 0.020260609763984878, ErrP = 1.8554428396552491\n",
      "Epoch = 624, ErrG = 4.061861485242844, ErrA = 0.024341890559298918, ErrD = 0.01414103782735765, ErrP = 1.7881884103020032\n",
      "Epoch = 626, ErrG = 4.964130401611328, ErrA = 0.012439501478335538, ErrD = 0.01946133639042576, ErrP = 1.9640945177525282\n",
      "Epoch = 628, ErrG = 4.985389590263367, ErrA = 0.0387651277706027, ErrD = 0.009518504608422518, ErrP = 1.6050625254089634\n",
      "Epoch = 630, ErrG = 5.626995861530304, ErrA = 0.011581362128102532, ErrD = 0.009505057105949769, ErrP = 1.8687210067485769\n",
      "Epoch = 632, ErrG = 5.3463152050971985, ErrA = 0.03565042528014336, ErrD = 0.02329789234014849, ErrP = 2.492801580830322\n",
      "Epoch = 634, ErrG = 4.59013894200325, ErrA = 0.015744937234558165, ErrD = 0.012390673626214266, ErrP = 1.2988360573848088\n",
      "Epoch = 636, ErrG = 4.697734132409096, ErrA = 0.010024489034549333, ErrD = 0.01370203122496605, ErrP = 1.738422685302794\n",
      "Epoch = 638, ErrG = 5.56621441245079, ErrA = 0.0032475531988893636, ErrD = 0.02077815867960453, ErrP = 1.7112946392347415\n",
      "Epoch = 640, ErrG = 4.504685699939728, ErrA = 0.008532070554792881, ErrD = 0.02474193156619246, ErrP = 1.7036593857531745\n",
      "Epoch = 642, ErrG = 4.964475333690643, ErrA = 0.00896157361967198, ErrD = 0.01385677233338356, ErrP = 1.8531872667372227\n",
      "Epoch = 644, ErrG = 4.674285784363747, ErrA = 0.004546402982668951, ErrD = 0.03957279457245022, ErrP = 1.5445996895432472\n",
      "Epoch = 646, ErrG = 5.2631523460149765, ErrA = 0.0019324740865916585, ErrD = 0.014704374596476555, ErrP = 1.9310400501126423\n",
      "Epoch = 648, ErrG = 5.991700321435928, ErrA = 0.0036808209430697993, ErrD = 0.009711469989269972, ErrP = 2.1418213590416904\n",
      "Epoch = 650, ErrG = 4.832366198301315, ErrA = 0.021294952836721375, ErrD = 0.025162204634398222, ErrP = 2.2076596067442247\n",
      "Epoch = 652, ErrG = 5.0273624658584595, ErrA = 0.012968104322984194, ErrD = 0.007030575380971034, ErrP = 2.181274910690263\n",
      "Epoch = 654, ErrG = 4.350407138466835, ErrA = 0.034192169861256616, ErrD = 0.008121471696843704, ErrP = 2.094544311830153\n",
      "Epoch = 656, ErrG = 5.689451172947884, ErrA = 0.0018912265586550348, ErrD = 0.00826673434736828, ErrP = 1.7860694895498455\n",
      "Epoch = 658, ErrG = 4.637914597988129, ErrA = 0.05502671003364412, ErrD = 0.04380686208605766, ErrP = 1.9574060574620187\n",
      "Epoch = 660, ErrG = 5.634746819734573, ErrA = 0.004207988933255062, ErrD = 0.006988721628052493, ErrP = 1.8544608710023265\n",
      "Epoch = 662, ErrG = 4.045100197196007, ErrA = 0.10997462932330866, ErrD = 0.015552476902181903, ErrP = 1.7473479299806058\n",
      "Epoch = 664, ErrG = 5.450129985809326, ErrA = 0.03013757981091203, ErrD = 0.012644852666805187, ErrP = 2.223332422746656\n",
      "Epoch = 666, ErrG = 4.297820091247559, ErrA = 0.18363933679453717, ErrD = 0.020354771055281162, ErrP = 1.8582238170007865\n",
      "Epoch = 668, ErrG = 3.718529313802719, ErrA = 0.016981866210784347, ErrD = 0.022945072501897812, ErrP = 2.2047081477940083\n",
      "Epoch = 670, ErrG = 3.944596230983734, ErrA = 0.0761344295691136, ErrD = 0.006618531576047341, ErrP = 1.9796205746630828\n",
      "Epoch = 672, ErrG = 5.182962700724602, ErrA = 0.013014004255372432, ErrD = 0.1080765649676323, ErrP = 2.307185802104262\n",
      "Epoch = 674, ErrG = 3.309203863143921, ErrA = 0.10940685976917545, ErrD = 0.019276267538468044, ErrP = 1.637788721670707\n",
      "Epoch = 676, ErrG = 4.180152162909508, ErrA = 0.02083187736595467, ErrD = 0.014932677848264575, ErrP = 2.0610061472592256\n",
      "Epoch = 678, ErrG = 4.401981562376022, ErrA = 0.030245208782919992, ErrD = 0.009833813722555837, ErrP = 1.773600623011589\n",
      "Epoch = 680, ErrG = 5.631276488304138, ErrA = 0.002092037931409626, ErrD = 0.0227919848014911, ErrP = 1.9718201687404264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 682, ErrG = 4.614795744419098, ErrA = 0.003497906973128314, ErrD = 0.043314843981837235, ErrP = 2.3817883241960467\n",
      "Epoch = 684, ErrG = 6.708198115229607, ErrA = 0.0009738096089980294, ErrD = 0.02778815571218729, ErrP = 2.4185923703577523\n",
      "Epoch = 686, ErrG = 3.5164002031087875, ErrA = 0.07445311649159218, ErrD = 0.011461217266817888, ErrP = 1.6208183467388153\n",
      "Epoch = 688, ErrG = 6.071031093597412, ErrA = 0.0023168805685950624, ErrD = 0.016358414975305397, ErrP = 2.3647002772195265\n",
      "Epoch = 690, ErrG = 5.7160618007183075, ErrA = 0.004689266908068627, ErrD = 0.007368836629514893, ErrP = 2.111980510642752\n",
      "Epoch = 692, ErrG = 2.6602130830287933, ErrA = 0.13904298325845352, ErrD = 0.07406613665322463, ErrP = 1.7235653350750606\n",
      "Epoch = 694, ErrG = 4.651394456624985, ErrA = 0.006315744171691525, ErrD = 0.014701074299712976, ErrP = 2.127034991669158\n",
      "Epoch = 696, ErrG = 5.875986486673355, ErrA = 0.006327504727475268, ErrD = 0.006433010722200076, ErrP = 2.0806407686322927\n",
      "Epoch = 698, ErrG = 4.915483325719833, ErrA = 0.007524929631851289, ErrD = 0.011002648466577133, ErrP = 1.6809655136118333\n",
      "Epoch = 700, ErrG = 4.1822676956653595, ErrA = 0.022033503225126577, ErrD = 0.03818730513254801, ErrP = 1.9112732733289401\n"
     ]
    }
   ],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netp = NetP(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netp.children())[0].children(),\n",
    "    list(neta.children())[0].children(),\n",
    "    list(netd.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netp = netp.to(device)\n",
    "neta = neta.to(device)\n",
    "netd = netd.to(device)\n",
    "netg.train()\n",
    "netp.train()\n",
    "neta.train()\n",
    "netd.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimP = optim.Adam(netp.parameters(), lr=lr/3)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, target = {} \\n'.format(\n",
    "            epoches, lr, batchSize, target))\n",
    "\n",
    "print('Training starts')\n",
    "low_loss = 10\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, ass_img, img, noass_img) in enumerate(train_loader): \n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        \n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "        label.fill_(real_label)\n",
    "        lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "        lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "        label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "        lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "\n",
    "\n",
    "        # update P\n",
    "        lossP = 0\n",
    "        optimP.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_img), 1)\n",
    "        noassd = th.cat((img, noass_img), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossP_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossP += lossP_real1.item()/2\n",
    "        lossP_real1 = lossP_real1/2\n",
    "        lossP_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossP_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossP += lossP_real2.item()/2\n",
    "        lossP_real2 = lossP_real2/2\n",
    "        lossP_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossP_fake = F.binary_cross_entropy(output, label)\n",
    "        lossP += lossP_fake.item()/2\n",
    "        lossP_fake = lossP_fake/2\n",
    "        lossP_fake.backward()\n",
    "\n",
    "        optimP.step()\n",
    "    \n",
    "\n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "\n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        \n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward(retain_graph=True)\n",
    "        \n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = netp(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGP = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGP.item()/2\n",
    "        lossGP = lossGP/2\n",
    "        lossGP.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch, epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3, lossP/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD', 'lossP']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch, epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3, lossP/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:  \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict(),\n",
    "            'netP': netp.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "    \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict(),\n",
    "            'netP': netp.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {}  \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T03:05:11.264440Z",
     "start_time": "2019-05-10T03:05:11.221502Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from model_siGAN import NetG, NetD, NetA\n",
    "from data_set import *\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "ass_label, noass_label, img = dataset.getbatch(1)\n",
    "# ass_label, noass_label, img = dataset.getbatch(1)\n",
    "\n",
    "# dataset_test = CASIABDatasetForTest(data_dir=Data_Dir)\n",
    "# ass_label_test, noass_label_test, img_test = dataset_test.getbatch(1)\n",
    "# ass_label_test, noass_label_test, img_test = dataset_test.getbatch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T22:52:44.360471Z",
     "start_time": "2019-05-06T16:38:09.779397Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from model_siGAN import NetG, NetD, NetA\n",
    "from data_set import *\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import make_grid\n",
    "import visdom\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "Model_Name = 'Model_Triplet'\n",
    "if not os.path.isdir(Model_Name):\n",
    "    os.mkdir(Model_Name)\n",
    "    \n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "#     list(netd.children())[0].children(),\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netg.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "dataset_test = CASIABDatasetForTest(data_dir=Data_Dir)\n",
    "ass_label_test, noass_label_test, img_test = dataset_test.getbatch(300)\n",
    "ass_label_test = ass_label_test.to(device).to(th.float32)\n",
    "noass_label_test = noass_label_test.to(device).to(th.float32)\n",
    "img_test = img_test.to(device).to(th.float32)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.0001\n",
    "batchSize = 128\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr)\n",
    "# optimG = optim.Adam(netg.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "while iteration < 30000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    __, A = netg(img)\n",
    "    __, P = netg(ass_label)\n",
    "    __, N = netg(noass_label)\n",
    "    lossTriplet = F.triplet_margin_loss(A, P, N, margin=5)\n",
    "    lossGT = lossTriplet.item()\n",
    "    lossTriplet.backward()\n",
    "    optimG.step()\n",
    "    \n",
    "    iteration+=1\n",
    "    if iteration % 500 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            __, A_test = netg(img_test)\n",
    "            __, P_test = netg(ass_label_test)\n",
    "            __, N_test = netg(noass_label_test)\n",
    "            loss_test = F.triplet_margin_loss(A_test, P_test, N_test, margin=5)\n",
    "            loss_test = loss_test.item()\n",
    "            netg.train() #切換回去\n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrGT = {}, Test_ErrGT = {}\\n'.format(\n",
    "            iteration, lossGT, loss_test\n",
    "        ))\n",
    "        print('iter = {}, ErrGT = {}, Test_ErrGT = {}'.format(\n",
    "            iteration, lossGT, loss_test\n",
    "        ))\n",
    "\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration,iteration]]),\n",
    "                           Y=np.array([[lossGT, loss_test]]),\n",
    "                           opts=dict(\n",
    "                               title= Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossGT', 'lossGT_test']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration]]),\n",
    "                     Y=np.array([[lossGT, loss_test]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "            \n",
    "    if iteration % 2500 == 0:\n",
    "        state = {\n",
    "#             'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "#             'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Siamese and GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T21:13:30.999315Z",
     "start_time": "2019-05-29T14:16:28.502269Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "margin = 5\n",
    "target = '036'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, margin = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, margin, target))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "        label.fill_(real_label)\n",
    "        lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "        lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake, _ = netg(img)\n",
    "        label.fill_(fake_label)\n",
    "        output2 = netd(fake.detach())\n",
    "        lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "\n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        fake,_ = netg(img)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked.detach())\n",
    "        lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "        \n",
    "        \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake, A = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "        \n",
    "        # constrain on generator\n",
    "        fake_ass, P = netg(ass_label)\n",
    "        fake_noass, N = netg(noass_label)\n",
    "        lossTriplet = F.triplet_margin_loss(fake, fake_ass, fake_noass, margin = margin)\n",
    "        lossG += lossTriplet.item()\n",
    "        lossTriplet.backward()\n",
    "        \n",
    "        # constrain on encoder\n",
    "#         __, P = netg(ass_label)\n",
    "#         __, N = netg(noass_label)\n",
    "#         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "#         lossG += lossTriplet.item()\n",
    "#         lossTriplet.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Siamese and GAN k times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-18T06:30:56.030Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 6.079311847686768, ErrA = 0.45719657093286514, ErrD = 0.15815530717372894\n",
      "Epoch = 4, ErrG = 4.7586734890937805, ErrA = 0.42604386806488037, ErrD = 0.42887693643569946\n",
      "Epoch = 6, ErrG = 3.702850639820099, ErrA = 0.47924991448720294, ErrD = 0.494888573884964\n",
      "Epoch = 8, ErrG = 3.5415768027305603, ErrA = 0.5032813847064972, ErrD = 0.6257400711377462\n",
      "Epoch = 10, ErrG = 3.145357310771942, ErrA = 0.569260984659195, ErrD = 0.5315638681252798\n",
      "Epoch = 12, ErrG = 2.8632413148880005, ErrA = 0.5580846269925436, ErrD = 0.6164103746414185\n",
      "Epoch = 14, ErrG = 3.4398266077041626, ErrA = 0.5699803531169891, ErrD = 0.5714153349399567\n",
      "Epoch = 16, ErrG = 2.488332360982895, ErrA = 0.5693407853444418, ErrD = 0.5842624207337698\n",
      "Epoch = 18, ErrG = 2.8794360756874084, ErrA = 0.5267928838729858, ErrD = 0.6221688290437063\n",
      "Epoch = 20, ErrG = 2.9776294976472855, ErrA = 0.5936105102300644, ErrD = 0.6124396125475565\n",
      "Epoch = 22, ErrG = 2.8799997866153717, ErrA = 0.576061616341273, ErrD = 0.5389897127946218\n",
      "Epoch = 24, ErrG = 2.520514637231827, ErrA = 0.5795839230219523, ErrD = 0.6092757682005564\n",
      "Epoch = 26, ErrG = 2.8677753061056137, ErrA = 0.5393313964207967, ErrD = 0.6454990108807882\n",
      "Epoch = 28, ErrG = 2.7502206563949585, ErrA = 0.5399859547615051, ErrD = 0.5091856519381205\n",
      "Epoch = 30, ErrG = 2.051117092370987, ErrA = 0.5281719068686167, ErrD = 0.5790917674700419\n",
      "Epoch = 32, ErrG = 2.2015447318553925, ErrA = 0.5133478964368502, ErrD = 0.5634980400403341\n",
      "Epoch = 34, ErrG = 2.788050889968872, ErrA = 0.5292966589331627, ErrD = 0.511412779490153\n",
      "Epoch = 36, ErrG = 2.7306666523218155, ErrA = 0.5650033603111903, ErrD = 0.5881329874197642\n",
      "Epoch = 38, ErrG = 2.234039545059204, ErrA = 0.5342715978622437, ErrD = 0.5585849781831106\n",
      "Epoch = 40, ErrG = 2.3053693175315857, ErrA = 0.5674223651488622, ErrD = 0.5226818124453226\n",
      "Epoch = 42, ErrG = 2.7525658905506134, ErrA = 0.5153961131970087, ErrD = 0.599700003862381\n",
      "Epoch = 44, ErrG = 2.297931671142578, ErrA = 0.5105236023664474, ErrD = 0.5194060206413269\n",
      "Epoch = 46, ErrG = 2.1918378472328186, ErrA = 0.5249174758791924, ErrD = 0.5563233494758606\n",
      "Epoch = 48, ErrG = 1.9780471622943878, ErrA = 0.48232655723889667, ErrD = 0.5477278133233389\n",
      "Epoch = 50, ErrG = 2.1149319410324097, ErrA = 0.4889841079711914, ErrD = 0.4890411893526713\n",
      "Epoch = 52, ErrG = 2.3996572494506836, ErrA = 0.501628873248895, ErrD = 0.564287394285202\n",
      "Epoch = 54, ErrG = 1.967437595129013, ErrA = 0.4774104158083598, ErrD = 0.5322589576244354\n",
      "Epoch = 56, ErrG = 2.0730493515729904, ErrA = 0.5207800169785818, ErrD = 0.5628550251324972\n",
      "Epoch = 58, ErrG = 2.3037022948265076, ErrA = 0.4708947812517484, ErrD = 0.47786831855773926\n",
      "Epoch = 60, ErrG = 2.533527225255966, ErrA = 0.4691565930843353, ErrD = 0.5029882490634918\n",
      "Epoch = 62, ErrG = 2.162025660276413, ErrA = 0.4999394466479619, ErrD = 0.5226981937885284\n",
      "Epoch = 64, ErrG = 2.09339502453804, ErrA = 0.46017470955848694, ErrD = 0.46797581513722736\n",
      "Epoch = 66, ErrG = 2.2557446658611298, ErrA = 0.46934529890616733, ErrD = 0.4432901938756307\n",
      "Epoch = 68, ErrG = 2.065971225500107, ErrA = 0.4723052531480789, ErrD = 0.4509403308232625\n",
      "Epoch = 70, ErrG = 1.917769730091095, ErrA = 0.46486352880795795, ErrD = 0.43403234084447223\n",
      "Epoch = 72, ErrG = 2.449428528547287, ErrA = 0.5012105802694956, ErrD = 0.4361730714639028\n",
      "Epoch = 74, ErrG = 2.098850965499878, ErrA = 0.4783770740032196, ErrD = 0.40728970368703205\n",
      "Epoch = 76, ErrG = 2.377156764268875, ErrA = 0.49471987908085185, ErrD = 0.44166625042756397\n",
      "Epoch = 78, ErrG = 2.093427300453186, ErrA = 0.4670732766389847, ErrD = 0.4286852677663167\n",
      "Epoch = 80, ErrG = 2.1164764761924744, ErrA = 0.40975069254636765, ErrD = 0.3793058494726817\n",
      "Epoch = 82, ErrG = 2.526730000972748, ErrA = 0.41850366319219273, ErrD = 0.3653257389863332\n",
      "Epoch = 84, ErrG = 2.560358464717865, ErrA = 0.4403083279418449, ErrD = 0.4289083480834961\n",
      "Epoch = 86, ErrG = 2.3420329093933105, ErrA = 0.467853760967652, ErrD = 0.4246455828348796\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "margin = 10\n",
    "g_k = 2\n",
    "k = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/3)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, margin = {}, g_k ={}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, margin, g_k, target))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         com_img = th.cat((noass_img, img, ass_img), 0)\n",
    "#         com_label = th.cat(( label_neg, label_anc, label_pos), 0)\n",
    "#         com_img = com_img.to(device).to(th.float32)\n",
    "#         com_label = com_label.to(device).to(th.float32)\n",
    "        \n",
    "#         if(i ==0):\n",
    "#             print(label_neg,label_anc,label_pos)\n",
    "#             print(com_label)\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape,com_img.shape, com_label.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % g_k ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake, _ = netg(img)\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake.detach()) #需要 detach 因為不希望更新fake的參數\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake,_ = netg(img)\n",
    "            faked = th.cat((img, fake.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "#     if i % k ==0: \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake, A = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)  ##這裡需要retain graph 因為他之後有需要fake，因此需要retain\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "        \n",
    "        ## new tripletloss\n",
    "        _, P = netg(ass_img)\n",
    "        __, N = netg(noass_img)\n",
    "        lossf = TripletLoss(margin) #因為之前的A都沒被使用過所以不會遺失，如果是拿fake ，LossGA就需要再retain graph\n",
    "        lossTriplet =lossf(A, P, N)\n",
    "        lossG += lossTriplet.item()\n",
    "        lossTriplet.backward()\n",
    "        \n",
    "#         ## new onlinetripletloss\n",
    "#         __, com = netg(com_img)\n",
    "#         loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "#         lossTriplet,len_triplet = loss_fn(com, com_label)\n",
    "#         lossG += lossTriplet.item()\n",
    "#         lossTriplet.backward()\n",
    "# #         print(lossTriplet.item(),len_triplet)\n",
    "        \n",
    "#         ## triplet loss\n",
    "#         __, P = netg(ass_img)\n",
    "#         __, N = netg(noass_img)\n",
    "#         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin) #因為之前的A都沒被使用過所以不會遺失，如果是拿fake ，LossGA就需要再retain graph\n",
    "#         lossG += lossTriplet.item()\n",
    "#         lossTriplet.backward()\n",
    "# #         if i%10==0:\n",
    "# #             print(\"tripletloss \",lossTriplet.item())\n",
    "\n",
    "        ## tripletloss no negative\n",
    "#         N_plus = th.zeros((A.size()), requires_grad=False).to(device)\n",
    "#         lossTriplet_AP = F.triplet_margin_loss(A, P, N_plus, margin = margin)\n",
    "#         lossG += lossTriplet_AP.item()\n",
    "#         lossTriplet += lossTriplet_AP\n",
    "#         lossTriplet.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG  Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from PixelDT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:13:36.331308Z",
     "start_time": "2019-04-13T08:01:32.315792Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 128\n",
    "\n",
    "real_label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "fake_label = th.ones((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr)\n",
    "\n",
    "print('Training starts')\n",
    "while iteration < 40000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    # update D\n",
    "    lossD = 0\n",
    "    optimD.zero_grad()\n",
    "    output = netd(ass_label)\n",
    "#     label.fill_(real_label)\n",
    "    lossD_real1 = F.binary_cross_entropy(output, real_label)\n",
    "#     lossD += lossD_real1.item()\n",
    "#     lossD_real1.backward()\n",
    "\n",
    "#     label.fill_(real_label)\n",
    "    output1 = netd(noass_label)\n",
    "    lossD_real2 = F.binary_cross_entropy(output1, real_label)\n",
    "#     lossD += lossD_real2.item()\n",
    "#     lossD_real2.backward()\n",
    "\n",
    "    fake = netg(img).detach()\n",
    "#     label.fill_(fake_label)\n",
    "    output2 = netd(fake)\n",
    "    lossD_fake = F.binary_cross_entropy(output2, fake_label)\n",
    "#     lossD += lossD_fake.item()\n",
    "#     lossD_fake.backward()\n",
    "    lossD = (lossD_real1+ lossD_real2+ lossD_fake)/3\n",
    "    lossD.backward()\n",
    "\n",
    "    lossD_item = lossD.item()\n",
    "    optimD.step()\n",
    "    \n",
    "    # update A\n",
    "    lossA = 0\n",
    "    optimA.zero_grad()\n",
    "    assd = th.cat((img, ass_label), 1)\n",
    "    noassd = th.cat((img, noass_label), 1)\n",
    "    fake = netg(img).detach()\n",
    "    faked = th.cat((img, fake), 1)\n",
    "\n",
    "#     label.fill_(real_label)\n",
    "    output = neta(assd)\n",
    "    lossA_real1 = F.binary_cross_entropy(output, real_label)\n",
    "#     lossA += lossA_real1.item()\n",
    "#     lossA_real1.backward()\n",
    "\n",
    "#     label.fill_(fake_label)\n",
    "    output1 = neta(noassd)\n",
    "    lossA_real2 = F.binary_cross_entropy(output1, fake_label)\n",
    "#     lossA += lossA_real2.item()\n",
    "#     lossA_real2.backward()\n",
    "\n",
    "#     label.fill_(fake_label)\n",
    "    output2 = neta(faked)\n",
    "    lossA_fake = F.binary_cross_entropy(output2, fake_label)\n",
    "#     lossA += lossA_fake.item()\n",
    "#     lossA_fake.backward()\n",
    "    lossA = (lossA_real1+ lossA_real2 +lossA_fake)/3\n",
    "    lossA.backward()\n",
    "    \n",
    "    lossA_item = lossA.item()\n",
    "    optimA.step()\n",
    "    \n",
    "    # update G\n",
    "    lossG = 0\n",
    "    optimG.zero_grad()\n",
    "    fake = netg(img)\n",
    "    output = netd(fake)\n",
    "#     label.fill_(real_label)\n",
    "    lossGD = F.binary_cross_entropy(output, real_label)\n",
    "#     lossG += lossGD.item()\n",
    "#     lossGD.backward(retain_graph=True)\n",
    "\n",
    "    faked = th.cat((img, fake), 1)\n",
    "    output = neta(faked)\n",
    "#     label.fill_(real_label)\n",
    "    lossGA = F.binary_cross_entropy(output, real_label)\n",
    "#     lossG += lossGA.item()\n",
    "#     lossGA.backward()\n",
    "    lossG = (lossGD + lossGA)/2\n",
    "    lossG.backward()\n",
    "    \n",
    "    lossG_item = lossG.item()\n",
    "    optimG.step()\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration % 20 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            fake = netg(img) \n",
    "            netg.train() #切換回去\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 20).cpu().numpy()\n",
    "        if win1 is None:\n",
    "            win1 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train'))\n",
    "        else:\n",
    "            vis.image(display, win=win1)\n",
    "    if iteration % 5000 == 0 or iteration==500:\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)\n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            iteration, lossG_item, lossA_item, lossD_item\n",
    "        ))\n",
    "        print('iter = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            iteration, lossG_item, lossA_item, lossD_item\n",
    "        ))\n",
    "    if iteration % 5000==0 or iteration==10 or iteration==500:\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration, iteration,\n",
    "                                        iteration]]),\n",
    "                           Y=np.array([[lossG_item, lossA_item, lossD_item]]),\n",
    "                           opts=dict(\n",
    "                               title='GaitGAN',\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration,\n",
    "                                  iteration]]),\n",
    "                     Y=np.array([[lossG_item, lossA_item, lossD_item]]),\n",
    "                     win=win,\n",
    "                     update='append')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN from gaitgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T11:24:25.000385Z",
     "start_time": "2019-05-19T06:44:16.638708Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.RMSprop(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.RMSprop(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.RMSprop(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, n_critic = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, n_critic, target))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "#         label.fill_(real_label)\n",
    "#         lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD_real1 = -th.mean(output)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "#         label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "#         lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD_real2 = -th.mean(output1)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "#         label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "#         lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD_fake = th.mean(output2)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "        \n",
    "        for p in netd.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        fake = netg(img).detach()\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "#         label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "#         lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA_real1 = -th.mean(output1)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "#         label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "#         lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA_real2 = th.mean(output)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "#         label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "#         lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA_fake = th.mean(output)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "    \n",
    "        for p in neta.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "        if i % n_critic == 0:\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossGD = -th.mean(output)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "#             label.fill_(real_label)\n",
    "#             lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossGA = -th.mean(output)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T17:54:50.674179Z",
     "start_time": "2019-06-02T12:25:08.423036Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 5\n",
    "target = '090'\n",
    "lambda_gp = 10\n",
    "beta1 = 0\n",
    "beta2 = 0.999\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, lr, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        lossD_ = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "#         label.fill_(real_label)\n",
    "#         lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD_real1 = -th.mean(output)\n",
    "        lossD_ += lossD_real1\n",
    "        lossD += lossD_real1.item()\n",
    "#         lossD_real1.backward()\n",
    "\n",
    "#         label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "#         lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD_real2 = -th.mean(output1)\n",
    "        lossD_ += lossD_real2\n",
    "        lossD += lossD_real2.item()\n",
    "#         lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "#         label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "#         lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD_fake = th.mean(output2)\n",
    "        lossD_ += lossD_fake\n",
    "        lossD += lossD_fake.item()\n",
    "        gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "#         lossD_fake.backward()\n",
    "        lossD_ = lossD_/3 + lambda_gp * gradient_penalty\n",
    "        lossD_.backward()\n",
    "\n",
    "        optimD.step()\n",
    "        \n",
    "#         for p in netd.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        lossA_ = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        fake = netg(img).detach()\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "#         label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "#         lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA_real1 = -th.mean(output1)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_ += lossA_real1\n",
    "#         lossA_real1.backward()\n",
    "\n",
    "#         label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "#         lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA_real2 = th.mean(output)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_ += lossA_real2\n",
    "#         lossA_real2.backward()\n",
    "\n",
    "#         label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "#         lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA_fake = th.mean(output)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_ += lossA_fake\n",
    "#         lossA_fake.backward()\n",
    "        gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "        lossA_ = lossA_/3 + lambda_gp * gradient_penalty\n",
    "        \n",
    "        lossA_.backward()\n",
    "        optimA.step()\n",
    "    \n",
    "#         for p in neta.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "        if i % n_critic == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossGD = -th.mean(output)\n",
    "            lossG += lossGD.item()\n",
    "            lossG_ += lossGD\n",
    "#             lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "#             label.fill_(real_label)\n",
    "#             lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossGA = -th.mean(output)\n",
    "            lossG += lossGA.item()\n",
    "            lossG_ += lossGA\n",
    "#             lossGA.backward()\n",
    "            lossG_ = lossG_/2\n",
    "            lossG_.backward(retain_graph=True)\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self attention Gait GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T00:07:22.217162Z",
     "start_time": "2019-06-05T16:58:50.881140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "# lr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 0\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, dlr, glr, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        lossD_ = 0\n",
    "        optimD.zero_grad()\n",
    "        d_out_assreal,dr1 = netd(ass_label)\n",
    "        d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "        lossD_ += d_loss_assreal\n",
    "        lossD += d_loss_assreal.item()\n",
    "\n",
    "        d_out_noassreal,dr2 = netd(noass_label)\n",
    "        d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "        lossD_ += d_loss_noassreal\n",
    "        lossD += d_loss_noassreal.item()\n",
    "\n",
    "        fake, gf1 = netg(img)\n",
    "        d_out_fake, df1 = netd(fake.detach())  #需要 detach 因為不希望更新fake的參數\n",
    "        d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "        lossD_ += d_loss_fake\n",
    "        lossD += d_loss_fake.item()\n",
    "#         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "        lossD_ = lossD_/3\n",
    "        lossD_.backward()\n",
    "        optimD.step()\n",
    "        \n",
    "#         for p in netd.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        lossA_ = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked, gf1 = netg(img)\n",
    "        faked = th.cat((img, faked.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "        d_out_assreal,dr1 = neta(assd)\n",
    "        d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "        lossA += d_loss_assreal.item()\n",
    "        lossA_ += d_loss_assreal\n",
    "\n",
    "        d_out_noassreal,dr2 = neta(noassd)\n",
    "        d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "        lossA_ += d_loss_noassreal\n",
    "        lossA += d_loss_noassreal.item()\n",
    "        \n",
    "        d_out_faked, df3 = neta(faked)\n",
    "        d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "        lossA_ += d_loss_faked\n",
    "        lossA += d_loss_faked.item()\n",
    "#         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "        lossA_ = lossA_/3\n",
    "        lossA_.backward()\n",
    "        optimA.step()\n",
    "    \n",
    "#         for p in neta.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "#         if i % n_critic == 0:\n",
    "        lossG = 0\n",
    "        lossG_ = 0\n",
    "        optimG.zero_grad()\n",
    "        fake,_= netg(img)\n",
    "        g_out_fake,_ = netd(fake)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "        lossG += g_loss_fake.item()\n",
    "        lossG_ += g_loss_fake\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        g_out_faked,_ = neta(faked)\n",
    "        g_loss_faked = - g_out_faked.mean()\n",
    "        lossG += g_loss_faked.item()\n",
    "        lossG_ += g_loss_faked\n",
    "        \n",
    "        lossG_ = lossG_/2\n",
    "        lossG_.backward(retain_graph=True) ##其實這裡也不需要retain graph 因為他只 backward 一次；\n",
    "        #如果爾後有要再backward，第一次就需要retain graph\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine siamese and SAGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-05T02:02:27.563775Z",
     "start_time": "2019-06-04T16:19:36.552572Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "# lr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 0\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 5\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        lossD_ = 0\n",
    "        optimD.zero_grad()\n",
    "        d_out_assreal,dr1 = netd(ass_label)\n",
    "        d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "        lossD_ += d_loss_assreal\n",
    "        lossD += d_loss_assreal.item()\n",
    "\n",
    "        d_out_noassreal,dr2 = netd(noass_label)\n",
    "        d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "        lossD_ += d_loss_noassreal\n",
    "        lossD += d_loss_noassreal.item()\n",
    "\n",
    "        fake, gf1 = netg(img)\n",
    "        d_out_fake, df1 = netd(fake.detach())\n",
    "        d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "        lossD_ += d_loss_fake\n",
    "        lossD += d_loss_fake.item()\n",
    "#         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "        lossD_ = lossD_/3\n",
    "        lossD_.backward()\n",
    "        optimD.step()\n",
    "        \n",
    "#         for p in netd.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        lossA_ = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked, gf1 = netg(img)\n",
    "        faked = th.cat((img, faked.detach()), 1)\n",
    "\n",
    "        d_out_assreal,dr1 = neta(assd)\n",
    "        d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "        lossA += d_loss_assreal.item()\n",
    "        lossA_ += d_loss_assreal\n",
    "\n",
    "        d_out_noassreal,dr2 = neta(noassd)\n",
    "        d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "        lossA_ += d_loss_noassreal\n",
    "        lossA += d_loss_noassreal.item()\n",
    "        \n",
    "        d_out_faked, df3 = neta(faked)\n",
    "        d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "        lossA_ += d_loss_faked\n",
    "        lossA += d_loss_faked.item()\n",
    "#         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "        lossA_ = lossA_/3\n",
    "        lossA_.backward()\n",
    "        optimA.step()\n",
    "    \n",
    "#         for p in neta.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "#         if i % n_critic == 0:\n",
    "        lossG = 0\n",
    "        lossG_ = 0\n",
    "        optimG.zero_grad()\n",
    "        fake,_= netg(img)\n",
    "        g_out_fake,_ = netd(fake)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "        lossG += g_loss_fake.item()\n",
    "        lossG_ += g_loss_fake\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        g_out_faked,_ = neta(faked)\n",
    "        g_loss_faked = - g_out_faked.mean()\n",
    "        lossG += g_loss_faked.item()\n",
    "        lossG_ += g_loss_faked\n",
    "        \n",
    "        # constrain on generator\n",
    "        fake_ass, P = netg(ass_label)\n",
    "        fake_noass, N = netg(noass_label)\n",
    "        lossTriplet = F.triplet_margin_loss(fake, fake_ass, fake_noass, margin = margin)\n",
    "        lossG_ += lossTriplet\n",
    "        lossG += lossTriplet.item()\n",
    "#         lossTriplet.backward()\n",
    "        \n",
    "        lossG_ = lossG_/3\n",
    "        lossG_.backward(retain_graph=True)\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrTri = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/3,lossTriplet.item(), lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/3)<low_loss:  \n",
    "        low_loss = lossG/3\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_ting_cv]",
   "language": "python",
   "name": "conda-env-py36_ting_cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
