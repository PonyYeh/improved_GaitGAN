{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:29:03.844114Z",
     "start_time": "2019-08-13T16:29:01.427298Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from onlineTripletloss import *\n",
    "from selector import *\n",
    "from model_SAGAN1_1_2att import NetG, NetD, NetA\n",
    "# from model_SAGAN2_Triplet import NetG, NetD, NetA\n",
    "# from model_WGANGP import NetG, NetD, NetA\n",
    "# from model_WGAN import NetG, NetD, NetA\n",
    "# from model_siGAN import NetG, NetD, NetA\n",
    "from dataset2Loader import CASIABDataset\n",
    "# from dataset2Loader_newtriplet import CASIABDataset\n",
    "# from dataset2Loader_triplet import CASIABDataset\n",
    "import torch.optim as optim\n",
    "import visdom\n",
    "from torchvision.utils import make_grid\n",
    "# Data_Dir = '../GaitRecognition/DatasetB_GEI_64x64_allseq/'\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "Model_Name = 'Model_64x64_SAGAN_90_trial15'\n",
    "Model_dir = './Transform_Model/'+ Model_Name\n",
    "if not os.path.isdir(Model_dir):\n",
    "    os.mkdir(Model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T11:51:23.878764Z",
     "start_time": "2019-05-17T11:51:22.490886Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "import os\n",
    "\n",
    "for r, d, files in os.walk(Data_Dir):\n",
    "    print(r)\n",
    "    print(len(d))\n",
    "    print(len(files))\n",
    "    \n",
    "# cpt = sum([len(files) for r, d, files in os.walk(Data_Dir)])\n",
    "# cpt = sum([len(d) for r, d, files in os.walk(Data_Dir)])\n",
    "# print(cpt)\n",
    "# list = os.listdir(Data_Dir) # dir is your directory path\n",
    "# number_files = len(list)\n",
    "# print(number_files)\n",
    "\n",
    "# import fnmatch\n",
    "# print(len(fnmatch.filter(os.listdir(Data_Dir), '*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T06:02:12.747164Z",
     "start_time": "2019-05-27T06:02:12.676816Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "ass_label, noass_label, img = dataset.getbatch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteration 刪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T08:08:38.785029Z",
     "start_time": "2019-06-16T08:08:38.768214Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(tensor, gain=1.)\n",
    "#         init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 128\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print('Training starts')\n",
    "while iteration < 30000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    # update D\n",
    "    lossD = 0\n",
    "    optimD.zero_grad()\n",
    "    output = netd(ass_label)\n",
    "    label.fill_(real_label)\n",
    "    lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "    lossD += lossD_real1.item()\n",
    "    lossD_real1.backward()\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output1 = netd(noass_label)\n",
    "    lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "    lossD += lossD_real2.item()\n",
    "    lossD_real2.backward()\n",
    "\n",
    "    fake = netg(img).detach()\n",
    "    label.fill_(fake_label)\n",
    "    output2 = netd(fake)\n",
    "    lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "    lossD += lossD_fake.item()\n",
    "    lossD_fake.backward()\n",
    "\n",
    "    optimD.step()\n",
    "    \n",
    "    # update A\n",
    "    lossA = 0\n",
    "    optimA.zero_grad()\n",
    "    assd = th.cat((img, ass_label), 1)\n",
    "    noassd = th.cat((img, noass_label), 1)\n",
    "    fake = netg(img).detach()\n",
    "    faked = th.cat((img, fake), 1)\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output1 = neta(assd)\n",
    "    lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "    lossA += lossA_real1.item()\n",
    "    lossA_real1.backward()\n",
    "\n",
    "    label.fill_(fake_label)\n",
    "    output = neta(noassd)\n",
    "    lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "    lossA += lossA_real2.item()\n",
    "    lossA_real2.backward()\n",
    "\n",
    "    label.fill_(fake_label)\n",
    "    output = neta(faked)\n",
    "    lossA_fake = F.binary_cross_entropy(output, label)\n",
    "    lossA += lossA_fake.item()\n",
    "    lossA_fake.backward()\n",
    "    \n",
    "    optimA.step()\n",
    "    \n",
    "    # update G\n",
    "    lossG = 0\n",
    "    optimG.zero_grad()\n",
    "    fake = netg(img)\n",
    "    output = netd(fake)\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    lossGD = F.binary_cross_entropy(output, label)\n",
    "    lossG += lossGD.item()\n",
    "    lossGD.backward(retain_graph=True)\n",
    "\n",
    "    faked = th.cat((img, fake), 1)\n",
    "    output = neta(faked)\n",
    "    label.fill_(real_label)\n",
    "    lossGA = F.binary_cross_entropy(output, label)\n",
    "    lossG += lossGA.item()\n",
    "    lossGA.backward()\n",
    "    \n",
    "    optimG.step()\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration % 20 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            fake = netg(img) 25\n",
    "            netg.train() #切換回去\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 20).cpu().numpy()\n",
    "        if win1 is None:\n",
    "            win1 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train'))\n",
    "        else:\n",
    "            vis.image(display, win=win1)\n",
    "    if iteration % 1000 == 0 or iteration==500:\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)\n",
    "\n",
    "    if iteration % 100==0 or iteration==10 :\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration, iteration,\n",
    "                                        iteration]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration,\n",
    "                                  iteration]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "            \n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            iteration, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('iter = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            iteration, lossG/2, lossA/3, lossD/3\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T05:25:59.661560Z",
     "start_time": "2019-05-27T05:25:59.620596Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=False)\n",
    "train_loader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T08:46:23.327475Z",
     "start_time": "2019-06-16T08:23:19.736325Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 0\n",
    "n_g = 0\n",
    "n_d = 0\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "print('Training starts')\n",
    "low_loss = 10\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "#         ass_img = ass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "#         noass_img = noass_img.to(device).to(th.float32)\n",
    "\n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            fake = netg(img).detach()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "\n",
    "        if i % n_d ==0: \n",
    "            # update G\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "            label.fill_(real_label)\n",
    "            lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:  \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "    \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update k times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:08:32.658055Z",
     "start_time": "2019-06-15T08:18:03.792818Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 0\n",
    "n_g = 2\n",
    "n_d = 0\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "#         noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "#         ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "        if i % n_d ==0: \n",
    "            # update G\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "            label.fill_(real_label)\n",
    "            lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model changed +Dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T09:39:59.973452Z",
     "start_time": "2019-06-17T01:57:16.530081Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netp = NetP(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netp.children())[0].children(),\n",
    "    list(neta.children())[0].children(),\n",
    "    list(netd.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netp = netp.to(device)\n",
    "neta = neta.to(device)\n",
    "netd = netd.to(device)\n",
    "netg.train()\n",
    "netp.train()\n",
    "neta.train()\n",
    "netd.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimP = optim.Adam(netp.parameters(), lr=lr/3)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, target = {} \\n'.format(\n",
    "            epoches, lr, batchSize, target))\n",
    "\n",
    "print('Training starts')\n",
    "low_loss = 10\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, ass_img, img, noass_img) in enumerate(train_loader): \n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        \n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "        label.fill_(real_label)\n",
    "        lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "        lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "        label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "        lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "\n",
    "\n",
    "        # update P\n",
    "        lossP = 0\n",
    "        optimP.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_img), 1)\n",
    "        noassd = th.cat((img, noass_img), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossP_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossP += lossP_real1.item()/2\n",
    "        lossP_real1 = lossP_real1/2\n",
    "        lossP_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossP_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossP += lossP_real2.item()/2\n",
    "        lossP_real2 = lossP_real2/2\n",
    "        lossP_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossP_fake = F.binary_cross_entropy(output, label)\n",
    "        lossP += lossP_fake.item()/2\n",
    "        lossP_fake = lossP_fake/2\n",
    "        lossP_fake.backward()\n",
    "\n",
    "        optimP.step()\n",
    "    \n",
    "\n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "\n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        \n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward(retain_graph=True)\n",
    "        \n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = netp(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGP = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGP.item()/2\n",
    "        lossGP = lossGP/2\n",
    "        lossGP.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch, epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3, lossP/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD', 'lossP']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch, epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3, lossP/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:  \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict(),\n",
    "            'netP': netp.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "    \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict(),\n",
    "            'netP': netp.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {}  \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model only D_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T05:21:59.261901Z",
     "start_time": "2019-06-23T02:19:01.856865Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "g_k = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "# netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "# optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, g_k = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, g_k, target))\n",
    "\n",
    "low_loss = 10\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "#         noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "#         ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % g_k ==0:\n",
    "#             # update D\n",
    "#             lossD = 0\n",
    "#             optimD.zero_grad()\n",
    "#             output = netd(ass_label)\n",
    "#             label.fill_(real_label)\n",
    "#             lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "#             lossD += lossD_real1.item()\n",
    "#             lossD_real1.backward()\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             output1 = netd(noass_label)\n",
    "#             lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "#             lossD += lossD_real2.item()\n",
    "#             lossD_real2.backward()\n",
    "\n",
    "#             fake = netg(img).detach()\n",
    "#             label.fill_(fake_label)\n",
    "#             output2 = netd(fake)\n",
    "#             lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "#             lossD += lossD_fake.item()\n",
    "#             lossD_fake.backward()\n",
    "\n",
    "#             optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "#         if i % k ==0: \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        ]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  ]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3,\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, \n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}\\n'.format(\n",
    "            epoch, lossG/2, lossA/3\n",
    "        ))    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaitGAN and triplet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T21:13:30.999315Z",
     "start_time": "2019-05-29T14:16:28.502269Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '036'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 5\n",
    "n_g = 0\n",
    "n_d = 0\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        if i % n_g==0:\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake, _ = netg(img)\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake.detach())\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake,_ = netg(img)\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked.detach())\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "        if i % n_d ==0: \n",
    "            # update G\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake, A = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "            label.fill_(real_label)\n",
    "            lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            # constrain on generator\n",
    "            fake_ass, P = netg(ass_label)\n",
    "            fake_noass, N = netg(noass_label)\n",
    "            lossTriplet = F.triplet_margin_loss(fake, fake_ass, fake_noass, margin = margin)\n",
    "            lossG += lossTriplet.item()\n",
    "            lossTriplet.backward()\n",
    "\n",
    "            # constrain on encoder\n",
    "    #         __, P = netg(ass_label)\n",
    "    #         __, N = netg(noass_label)\n",
    "    #         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "    #         lossG += lossTriplet.item()\n",
    "    #         lossTriplet.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaitGAN k times and triplet   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T17:27:36.724552Z",
     "start_time": "2019-06-18T06:30:54.000065Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 10\n",
    "n_g = 2\n",
    "n_d = 2\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr/3)\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         com_img = th.cat((noass_img, img, ass_img), 0)\n",
    "#         com_label = th.cat(( label_neg, label_anc, label_pos), 0)\n",
    "#         com_img = com_img.to(device).to(th.float32)\n",
    "#         com_label = com_label.to(device).to(th.float32)\n",
    "        \n",
    "#         if(i ==0):\n",
    "#             print(label_neg,label_anc,label_pos)\n",
    "#             print(com_label)\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape,com_img.shape, com_label.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        # update D\n",
    "        if i % n_g==0:\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake, _ = netg(img)\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake.detach()) #需要 detach 因為不希望更新fake的參數\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake,_ = netg(img)\n",
    "            faked = th.cat((img, fake.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "        if i % n_d ==0: \n",
    "            # update G\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake, A = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)  ##這裡需要retain graph 因為他之後有需要fake，因此需要retain\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "            label.fill_(real_label)\n",
    "            lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            ## new tripletloss\n",
    "            _, P = netg(ass_img)\n",
    "            __, N = netg(noass_img)\n",
    "            lossf = TripletLoss(margin) #因為之前的A都沒被使用過所以不會遺失，如果是拿fake ，LossGA就需要再retain graph\n",
    "            lossTriplet =lossf(A, P, N)\n",
    "            lossG += lossTriplet.item()\n",
    "            lossTriplet.backward()\n",
    "\n",
    "    #         ## new onlinetripletloss\n",
    "    #         __, com = netg(com_img)\n",
    "    #         loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "    #         lossTriplet,len_triplet = loss_fn(com, com_label)\n",
    "    #         lossG += lossTriplet.item()\n",
    "    #         lossTriplet.backward()\n",
    "    # #         print(lossTriplet.item(),len_triplet)\n",
    "\n",
    "    #         ## triplet loss\n",
    "    #         __, P = netg(ass_img)\n",
    "    #         __, N = netg(noass_img)\n",
    "    #         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin) #因為之前的A都沒被使用過所以不會遺失，如果是拿fake ，LossGA就需要再retain graph\n",
    "    #         lossG += lossTriplet.item()\n",
    "    #         lossTriplet.backward()\n",
    "    # #         if i%10==0:\n",
    "    # #             print(\"tripletloss \",lossTriplet.item())\n",
    "\n",
    "            ## tripletloss no negative\n",
    "    #         N_plus = th.zeros((A.size()), requires_grad=False).to(device)\n",
    "    #         lossTriplet_AP = F.triplet_margin_loss(A, P, N_plus, margin = margin)\n",
    "    #         lossG += lossTriplet_AP.item()\n",
    "    #         lossTriplet += lossTriplet_AP\n",
    "    #         lossTriplet.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG  Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from PixelDT code刪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:13:36.331308Z",
     "start_time": "2019-04-13T08:01:32.315792Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 128\n",
    "\n",
    "real_label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "fake_label = th.ones((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr)\n",
    "\n",
    "print('Training starts')\n",
    "while iteration < 40000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    # update D\n",
    "    lossD = 0\n",
    "    optimD.zero_grad()\n",
    "    output = netd(ass_label)\n",
    "#     label.fill_(real_label)\n",
    "    lossD_real1 = F.binary_cross_entropy(output, real_label)\n",
    "#     lossD += lossD_real1.item()\n",
    "#     lossD_real1.backward()\n",
    "\n",
    "#     label.fill_(real_label)\n",
    "    output1 = netd(noass_label)\n",
    "    lossD_real2 = F.binary_cross_entropy(output1, real_label)\n",
    "#     lossD += lossD_real2.item()\n",
    "#     lossD_real2.backward()\n",
    "\n",
    "    fake = netg(img).detach()\n",
    "#     label.fill_(fake_label)\n",
    "    output2 = netd(fake)\n",
    "    lossD_fake = F.binary_cross_entropy(output2, fake_label)\n",
    "#     lossD += lossD_fake.item()\n",
    "#     lossD_fake.backward()\n",
    "    lossD = (lossD_real1+ lossD_real2+ lossD_fake)/3\n",
    "    lossD.backward()\n",
    "\n",
    "    lossD_item = lossD.item()\n",
    "    optimD.step()\n",
    "    \n",
    "    # update A\n",
    "    lossA = 0\n",
    "    optimA.zero_grad()\n",
    "    assd = th.cat((img, ass_label), 1)\n",
    "    noassd = th.cat((img, noass_label), 1)\n",
    "    fake = netg(img).detach()\n",
    "    faked = th.cat((img, fake), 1)\n",
    "\n",
    "#     label.fill_(real_label)\n",
    "    output = neta(assd)\n",
    "    lossA_real1 = F.binary_cross_entropy(output, real_label)\n",
    "#     lossA += lossA_real1.item()\n",
    "#     lossA_real1.backward()\n",
    "\n",
    "#     label.fill_(fake_label)\n",
    "    output1 = neta(noassd)\n",
    "    lossA_real2 = F.binary_cross_entropy(output1, fake_label)\n",
    "#     lossA += lossA_real2.item()\n",
    "#     lossA_real2.backward()\n",
    "\n",
    "#     label.fill_(fake_label)\n",
    "    output2 = neta(faked)\n",
    "    lossA_fake = F.binary_cross_entropy(output2, fake_label)\n",
    "#     lossA += lossA_fake.item()\n",
    "#     lossA_fake.backward()\n",
    "    lossA = (lossA_real1+ lossA_real2 +lossA_fake)/3\n",
    "    lossA.backward()\n",
    "    \n",
    "    lossA_item = lossA.item()\n",
    "    optimA.step()\n",
    "    \n",
    "    # update G\n",
    "    lossG = 0\n",
    "    optimG.zero_grad()\n",
    "    fake = netg(img)\n",
    "    output = netd(fake)\n",
    "#     label.fill_(real_label)\n",
    "    lossGD = F.binary_cross_entropy(output, real_label)\n",
    "#     lossG += lossGD.item()\n",
    "#     lossGD.backward(retain_graph=True)\n",
    "\n",
    "    faked = th.cat((img, fake), 1)\n",
    "    output = neta(faked)\n",
    "#     label.fill_(real_label)\n",
    "    lossGA = F.binary_cross_entropy(output, real_label)\n",
    "#     lossG += lossGA.item()\n",
    "#     lossGA.backward()\n",
    "    lossG = (lossGD + lossGA)/2\n",
    "    lossG.backward()\n",
    "    \n",
    "    lossG_item = lossG.item()\n",
    "    optimG.step()\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration % 20 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            fake = netg(img) \n",
    "            netg.train() #切換回去\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 20).cpu().numpy()\n",
    "        if win1 is None:\n",
    "            win1 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train'))\n",
    "        else:\n",
    "            vis.image(display, win=win1)\n",
    "    if iteration % 5000 == 0 or iteration==500:\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)\n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            iteration, lossG_item, lossA_item, lossD_item\n",
    "        ))\n",
    "        print('iter = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            iteration, lossG_item, lossA_item, lossD_item\n",
    "        ))\n",
    "    if iteration % 5000==0 or iteration==10 or iteration==500:\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration, iteration,\n",
    "                                        iteration]]),\n",
    "                           Y=np.array([[lossG_item, lossA_item, lossD_item]]),\n",
    "                           opts=dict(\n",
    "                               title='GaitGAN',\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration,\n",
    "                                  iteration]]),\n",
    "                     Y=np.array([[lossG_item, lossA_item, lossD_item]]),\n",
    "                     win=win,\n",
    "                     update='append')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-12T16:51:42.619Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 3.752237558364868, ErrA = -1.8985527356465657, ErrD = -3.5465147892634072\n",
      "Epoch = 4, ErrG = 5.705430269241333, ErrA = -2.807316621144613, ErrD = -5.611066023508708\n",
      "Epoch = 6, ErrG = 4.896071195602417, ErrA = -3.07237180074056, ErrD = -6.601948658625285\n",
      "Epoch = 8, ErrG = 8.87260103225708, ErrA = -4.403616587320964, ErrD = -9.87374464670817\n",
      "Epoch = 10, ErrG = 7.947443723678589, ErrA = -4.1470723152160645, ErrD = -8.064921021461487\n",
      "Epoch = 12, ErrG = 1.238088607788086, ErrA = -4.921435038248698, ErrD = -4.710442225138347\n",
      "Epoch = 14, ErrG = 0.5194168090820312, ErrA = -5.6255998611450195, ErrD = -5.323735237121582\n",
      "Epoch = 16, ErrG = 6.348399639129639, ErrA = -7.5277970631917315, ErrD = -7.016017913818359\n",
      "Epoch = 18, ErrG = 0.8842306137084961, ErrA = -7.25491460164388, ErrD = -7.062686284383138\n",
      "Epoch = 20, ErrG = 0.0035724639892578125, ErrA = -7.803771336873372, ErrD = -7.927731831868489\n",
      "Epoch = 22, ErrG = 1.2339839935302734, ErrA = -8.73021380106608, ErrD = -8.565280278523764\n",
      "Epoch = 24, ErrG = 1.2255611419677734, ErrA = -9.72688357035319, ErrD = -9.670048395792643\n",
      "Epoch = 26, ErrG = 0.15535354614257812, ErrA = -10.620674769083658, ErrD = -10.38158925374349\n",
      "Epoch = 28, ErrG = 4.176642417907715, ErrA = -12.133074442545572, ErrD = -10.76137606302897\n",
      "Epoch = 30, ErrG = 4.427227973937988, ErrA = -12.199844360351562, ErrD = -12.158490498860678\n",
      "Epoch = 32, ErrG = 3.9799652099609375, ErrA = -14.347677866617838, ErrD = -14.839614232381185\n",
      "Epoch = 34, ErrG = 3.2736902236938477, ErrA = -14.609235127766928, ErrD = -15.713889439900717\n",
      "Epoch = 36, ErrG = 5.752946853637695, ErrA = -15.246897379557291, ErrD = -16.766225179036457\n",
      "Epoch = 38, ErrG = 1.6820240020751953, ErrA = -16.648352305094402, ErrD = -17.338180541992188\n",
      "Epoch = 40, ErrG = 10.724223136901855, ErrA = -17.55199940999349, ErrD = -20.6812006632487\n",
      "Epoch = 42, ErrG = 10.82100772857666, ErrA = -17.30973943074544, ErrD = -19.197577158610027\n",
      "Epoch = 44, ErrG = 6.142007827758789, ErrA = -19.585198720296223, ErrD = -21.98925272623698\n",
      "Epoch = 46, ErrG = 4.614898681640625, ErrA = -20.6905943552653, ErrD = -21.187957763671875\n",
      "Epoch = 48, ErrG = 14.935154914855957, ErrA = -20.511363983154297, ErrD = -22.849955240885418\n",
      "Epoch = 50, ErrG = 8.494245529174805, ErrA = -23.74848810831706, ErrD = -31.115222930908203\n",
      "Epoch = 52, ErrG = 9.508050918579102, ErrA = -24.220165252685547, ErrD = -25.16811243693034\n",
      "Epoch = 54, ErrG = 9.283670425415039, ErrA = -26.20640691121419, ErrD = -32.25322977701823\n",
      "Epoch = 56, ErrG = 13.134300231933594, ErrA = -23.950950622558594, ErrD = -31.37301762898763\n",
      "Epoch = 58, ErrG = 16.310850143432617, ErrA = -27.30752182006836, ErrD = -35.64556376139323\n",
      "Epoch = 60, ErrG = 9.128986358642578, ErrA = -25.83734639485677, ErrD = -38.91717656453451\n",
      "Epoch = 62, ErrG = 8.424102783203125, ErrA = -29.642303466796875, ErrD = -37.35610580444336\n",
      "Epoch = 64, ErrG = 25.559022903442383, ErrA = -31.677706400553387, ErrD = -32.23673756917318\n",
      "Epoch = 66, ErrG = 22.559337615966797, ErrA = -30.57117462158203, ErrD = -36.400753021240234\n",
      "Epoch = 68, ErrG = 15.052131652832031, ErrA = -35.96826934814453, ErrD = -46.180502573649086\n",
      "Epoch = 70, ErrG = -0.43895721435546875, ErrA = -32.98573303222656, ErrD = -43.57259877522787\n"
     ]
    }
   ],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 0\n",
    "n_g = 1\n",
    "n_d = 2\n",
    "clip = 0.1\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.RMSprop(netg.parameters(), lr=glr/2)\n",
    "optimD = optim.RMSprop(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.RMSprop(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={},clip={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp, clip))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        if i % n_g==0:\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "    #         label.fill_(real_label)\n",
    "    #         lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD_real1 = -th.mean(output)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "    #         label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "    #         lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD_real2 = -th.mean(output1)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "    #         label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "    #         lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD_fake = th.mean(output2)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            for p in netd.parameters():\n",
    "                p.data.clamp_(-clip, clip)\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "    #         label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "    #         lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA_real1 = -th.mean(output1)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "    #         label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "    #         lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA_real2 = th.mean(output)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "    #         label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "    #         lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA_fake = th.mean(output)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "\n",
    "            for p in neta.parameters():\n",
    "                p.data.clamp_(-clip, clip)\n",
    "\n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossGD = -th.mean(output)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "#             label.fill_(real_label)\n",
    "#             lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossGA = -th.mean(output)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T17:54:50.674179Z",
     "start_time": "2019-06-02T12:25:08.423036Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 10\n",
    "beta1 = 0\n",
    "beta2 = 0.999\n",
    "margin = 0\n",
    "n_g = 0\n",
    "n_d = 5\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        \n",
    "        # update D\n",
    "        if i % n_g==0:\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "    #         label.fill_(real_label)\n",
    "    #         lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD_real1 = -th.mean(output)\n",
    "            lossD_ += lossD_real1\n",
    "            lossD += lossD_real1.item()\n",
    "    #         lossD_real1.backward()\n",
    "\n",
    "    #         label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "    #         lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD_real2 = -th.mean(output1)\n",
    "            lossD_ += lossD_real2\n",
    "            lossD += lossD_real2.item()\n",
    "    #         lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "    #         label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "    #         lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD_fake = th.mean(output2)\n",
    "            lossD_ += lossD_fake\n",
    "            lossD += lossD_fake.item()\n",
    "            gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "    #         lossD_fake.backward()\n",
    "            lossD_ = lossD_/3 + lambda_gp * gradient_penalty\n",
    "            lossD_.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "    #         label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "    #         lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA_real1 = -th.mean(output1)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_ += lossA_real1\n",
    "    #         lossA_real1.backward()\n",
    "\n",
    "    #         label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "    #         lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA_real2 = th.mean(output)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_ += lossA_real2\n",
    "    #         lossA_real2.backward()\n",
    "\n",
    "    #         label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "    #         lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA_fake = th.mean(output)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_ += lossA_fake\n",
    "    #         lossA_fake.backward()\n",
    "            gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3 + lambda_gp * gradient_penalty\n",
    "\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "    \n",
    "            \n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossGD = -th.mean(output)\n",
    "            lossG += lossGD.item()\n",
    "            lossG_ += lossGD\n",
    "#             lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "#             label.fill_(real_label)\n",
    "#             lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossGA = -th.mean(output)\n",
    "            lossG += lossGA.item()\n",
    "            lossG_ += lossGA\n",
    "#             lossGA.backward()\n",
    "            lossG_ = lossG_/2\n",
    "            lossG_.backward(retain_graph=True)\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN (hing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T02:06:28.038804Z",
     "start_time": "2019-08-13T16:29:31.715693Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 1.8996484279632568, ErrA = 0.617903919890523, ErrD = 0.02228272706270218, Gattn=-0.0034067004453390837, Dattn=0.001238542958162725, Aattn=-0.00010161368118133396\n",
      "Epoch = 4, ErrG = 0.7542737275362015, ErrA = 0.6713284552097321, ErrD = 0.45941516508658725, Gattn=-0.005732168909162283, Dattn=0.001418719650246203, Aattn=-3.125678631477058e-05\n",
      "Epoch = 6, ErrG = -0.08506286144256592, ErrA = 0.6819584127515554, ErrD = 0.7010320872068405, Gattn=-0.0071759894490242004, Dattn=0.0016002730699256063, Aattn=2.4452589059364982e-05\n",
      "Epoch = 8, ErrG = -0.05347627401351929, ErrA = 0.6719489550838867, ErrD = 0.7059540351231893, Gattn=-0.00781609583646059, Dattn=0.0016207138542085886, Aattn=0.0002464703575242311\n",
      "Epoch = 10, ErrG = -0.026103854179382324, ErrA = 0.6940227796634039, ErrD = 0.7041413262486458, Gattn=-0.0080963633954525, Dattn=0.0016738295089453459, Aattn=0.0009498585131950676\n",
      "Epoch = 12, ErrG = -0.008958220481872559, ErrA = 0.6947894841432571, ErrD = 0.6914249459902445, Gattn=-0.008429276756942272, Dattn=0.0017530947225168347, Aattn=0.0024924036115407944\n",
      "Epoch = 14, ErrG = -0.069510817527771, ErrA = 0.6860089910527071, ErrD = 0.684453380604585, Gattn=-0.008670824579894543, Dattn=0.0018386957235634327, Aattn=0.003664677729830146\n",
      "Epoch = 16, ErrG = -0.02189311385154724, ErrA = 0.6906006932258606, ErrD = 0.6819733915229639, Gattn=-0.00887072179466486, Dattn=0.0019334076205268502, Aattn=0.004826304502785206\n",
      "Epoch = 18, ErrG = 0.012313544750213623, ErrA = 0.6689306137462457, ErrD = 0.689777784049511, Gattn=-0.009002765640616417, Dattn=0.0020284198690205812, Aattn=0.005714855622500181\n",
      "Epoch = 20, ErrG = -0.004877299070358276, ErrA = 0.6803036232789358, ErrD = 0.685962309439977, Gattn=-0.00910521112382412, Dattn=0.00214191572740674, Aattn=0.006212237756699324\n",
      "Epoch = 22, ErrG = 0.011550724506378174, ErrA = 0.672126700480779, ErrD = 0.688556561867396, Gattn=-0.009221971035003662, Dattn=0.002267439616844058, Aattn=0.006649875547736883\n",
      "Epoch = 24, ErrG = 0.012795686721801758, ErrA = 0.6729740866770347, ErrD = 0.6658606920391321, Gattn=-0.009285534732043743, Dattn=0.0023485785350203514, Aattn=0.006934553850442171\n",
      "Epoch = 26, ErrG = -0.00348740816116333, ErrA = 0.6680499265591303, ErrD = 0.6723377058903376, Gattn=-0.009375165216624737, Dattn=0.0025506876409053802, Aattn=0.007166765630245209\n",
      "Epoch = 28, ErrG = 0.009449183940887451, ErrA = 0.6689975230644146, ErrD = 0.670838197072347, Gattn=-0.009458332322537899, Dattn=0.0027005064766854048, Aattn=0.007191774435341358\n",
      "Epoch = 30, ErrG = -0.0030355453491210938, ErrA = 0.6635777726769447, ErrD = 0.6863780518372854, Gattn=-0.009555195458233356, Dattn=0.0029516287613660097, Aattn=0.007325607351958752\n",
      "Epoch = 32, ErrG = 0.06275668740272522, ErrA = 0.6831803744037946, ErrD = 0.6619868433723847, Gattn=-0.009671651758253574, Dattn=0.0031516982708126307, Aattn=0.007416027598083019\n",
      "Epoch = 34, ErrG = 0.07855814695358276, ErrA = 0.6313771232962608, ErrD = 0.6718025611092647, Gattn=-0.009764078073203564, Dattn=0.003393525490537286, Aattn=0.007649185135960579\n",
      "Epoch = 36, ErrG = -0.01017153263092041, ErrA = 0.6339223471780618, ErrD = 0.6439562973876795, Gattn=-0.009835007600486279, Dattn=0.003669791156426072, Aattn=0.007904627360403538\n",
      "Epoch = 38, ErrG = 0.10660338401794434, ErrA = 0.6400431121389071, ErrD = 0.6587344259023666, Gattn=-0.009906620718538761, Dattn=0.00394292501732707, Aattn=0.00839855708181858\n",
      "Epoch = 40, ErrG = 0.1027214527130127, ErrA = 0.5761763627330462, ErrD = 0.6512865026791891, Gattn=-0.009970024228096008, Dattn=0.004212888423353434, Aattn=0.008884385228157043\n",
      "Epoch = 42, ErrG = 0.004084110260009766, ErrA = 0.5894554580251375, ErrD = 0.6602304304639498, Gattn=-0.01006905548274517, Dattn=0.004518318455666304, Aattn=0.009513942524790764\n",
      "Epoch = 44, ErrG = 0.023264437913894653, ErrA = 0.6419072486460209, ErrD = 0.6451995378981034, Gattn=-0.010104352608323097, Dattn=0.004750988911837339, Aattn=0.010201729834079742\n",
      "Epoch = 46, ErrG = 0.1534847617149353, ErrA = 0.6714826251069704, ErrD = 0.6744585037231445, Gattn=-0.01016548927873373, Dattn=0.005012851674109697, Aattn=0.011011621914803982\n",
      "Epoch = 48, ErrG = 0.24396026134490967, ErrA = 0.6179952820142111, ErrD = 0.6398845383276542, Gattn=-0.010210745967924595, Dattn=0.005249275825917721, Aattn=0.011943614110350609\n",
      "Epoch = 50, ErrG = -0.028797268867492676, ErrA = 0.5682707590361437, ErrD = 0.6873711347579956, Gattn=-0.01023556012660265, Dattn=0.005577866453677416, Aattn=0.012891554273664951\n",
      "Epoch = 52, ErrG = -0.028794467449188232, ErrA = 0.5932543917248646, ErrD = 0.6504349708557129, Gattn=-0.010314763523638248, Dattn=0.005834020674228668, Aattn=0.013780751265585423\n",
      "Epoch = 54, ErrG = 0.18831318616867065, ErrA = 0.6058163444201151, ErrD = 0.6281071926156679, Gattn=-0.010396512225270271, Dattn=0.006054899655282497, Aattn=0.014873802661895752\n",
      "Epoch = 56, ErrG = 0.11738651990890503, ErrA = 0.5961640800038973, ErrD = 0.6777730286121368, Gattn=-0.010454291477799416, Dattn=0.006354833487421274, Aattn=0.01610591448843479\n",
      "Epoch = 58, ErrG = -0.04280298948287964, ErrA = 0.5579312102248272, ErrD = 0.6356449276208878, Gattn=-0.010507095605134964, Dattn=0.006612061057239771, Aattn=0.017311615869402885\n",
      "Epoch = 60, ErrG = -0.048855364322662354, ErrA = 0.6116657902797064, ErrD = 0.6435471984247366, Gattn=-0.010556729510426521, Dattn=0.006801033392548561, Aattn=0.018590793013572693\n",
      "Epoch = 62, ErrG = 0.1584741473197937, ErrA = 0.6175745551784834, ErrD = 0.6558288857340813, Gattn=-0.0106199961155653, Dattn=0.007058065850287676, Aattn=0.020209018141031265\n",
      "Epoch = 64, ErrG = 0.07127025723457336, ErrA = 0.5585269543031851, ErrD = 0.6492914706468582, Gattn=-0.010688952170312405, Dattn=0.007317171897739172, Aattn=0.021838977932929993\n",
      "Epoch = 66, ErrG = 0.13893884420394897, ErrA = 0.558985186740756, ErrD = 0.639741288498044, Gattn=-0.010757782496511936, Dattn=0.007578200660645962, Aattn=0.023307139053940773\n",
      "Epoch = 68, ErrG = 0.1111772358417511, ErrA = 0.576408659418424, ErrD = 0.6246786868820587, Gattn=-0.010827526450157166, Dattn=0.00789584033191204, Aattn=0.025102179497480392\n",
      "Epoch = 70, ErrG = -0.0503561794757843, ErrA = 0.5338209792971611, ErrD = 0.6377219061056772, Gattn=-0.010879007168114185, Dattn=0.008251162245869637, Aattn=0.026646163314580917\n",
      "Epoch = 72, ErrG = 0.023297280073165894, ErrA = 0.6081486319502195, ErrD = 0.6774985293547312, Gattn=-0.01091937255114317, Dattn=0.008656148798763752, Aattn=0.028046414256095886\n",
      "Epoch = 74, ErrG = 0.03998890519142151, ErrA = 0.6054479454954466, ErrD = 0.6472466041644415, Gattn=-0.01093550119549036, Dattn=0.009094753302633762, Aattn=0.029549527913331985\n",
      "Epoch = 76, ErrG = 0.20169195532798767, ErrA = 0.6227894077698389, ErrD = 0.6393225441376368, Gattn=-0.011006125248968601, Dattn=0.009654136374592781, Aattn=0.031134312972426414\n",
      "Epoch = 78, ErrG = 0.361538827419281, ErrA = 0.5049182350436846, ErrD = 0.6487287680308024, Gattn=-0.01105301734060049, Dattn=0.010473829694092274, Aattn=0.0326511524617672\n",
      "Epoch = 80, ErrG = 0.017121165990829468, ErrA = 0.5618525197108587, ErrD = 0.5470163921515147, Gattn=-0.011084120720624924, Dattn=0.01170576922595501, Aattn=0.03417137637734413\n",
      "Epoch = 82, ErrG = 0.23427805304527283, ErrA = 0.553745781381925, ErrD = 0.5414446492989858, Gattn=-0.01111601386219263, Dattn=0.013146752491593361, Aattn=0.03588421642780304\n",
      "Epoch = 84, ErrG = 0.3851574510335922, ErrA = 0.5506237174073855, ErrD = 0.5533385227123896, Gattn=-0.011179556138813496, Dattn=0.014255774207413197, Aattn=0.0371936671435833\n",
      "Epoch = 86, ErrG = 0.9268454611301422, ErrA = 0.4775523543357849, ErrD = 0.4568436071276665, Gattn=-0.011272932402789593, Dattn=0.015490524470806122, Aattn=0.038479000329971313\n",
      "Epoch = 88, ErrG = 0.10999345779418945, ErrA = 0.5088476488987604, ErrD = 0.4382554789384206, Gattn=-0.011321050114929676, Dattn=0.01655658893287182, Aattn=0.03999285399913788\n",
      "Epoch = 90, ErrG = 0.6605142652988434, ErrA = 0.5181331659356753, ErrD = 0.4612181931734085, Gattn=-0.011360742151737213, Dattn=0.01752123050391674, Aattn=0.041271764785051346\n",
      "Epoch = 92, ErrG = 0.6920592784881592, ErrA = 0.5390481154123942, ErrD = 0.5477011054754257, Gattn=-0.011380845680832863, Dattn=0.018498342484235764, Aattn=0.04311281815171242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 94, ErrG = 0.6470556482672691, ErrA = 0.5078609151144823, ErrD = 0.4706652561823527, Gattn=-0.011430235579609871, Dattn=0.018935296684503555, Aattn=0.04463759809732437\n",
      "Epoch = 96, ErrG = 0.004471957683563232, ErrA = 0.3324270291874806, ErrD = 0.3612421900033951, Gattn=-0.011442427523434162, Dattn=0.019414205104112625, Aattn=0.046229250729084015\n",
      "Epoch = 98, ErrG = 0.9115673899650574, ErrA = 0.5088222300012907, ErrD = 0.4312947802245617, Gattn=-0.011487491428852081, Dattn=0.0196624007076025, Aattn=0.047660376876592636\n",
      "Epoch = 100, ErrG = 1.221674919128418, ErrA = 0.44035592178503674, ErrD = 0.6016119252890348, Gattn=-0.011491957120597363, Dattn=0.020076587796211243, Aattn=0.0494144931435585\n",
      "Epoch = 102, ErrG = 0.687450647354126, ErrA = 0.487853745619456, ErrD = 0.4375476986169815, Gattn=-0.011560247279703617, Dattn=0.020314455032348633, Aattn=0.05109594017267227\n",
      "Epoch = 104, ErrG = 0.9769279956817627, ErrA = 0.5190529078245163, ErrD = 0.3872065593798955, Gattn=-0.0116104232147336, Dattn=0.020458977669477463, Aattn=0.052619270980358124\n",
      "Epoch = 106, ErrG = 0.322946697473526, ErrA = 0.514123110100627, ErrD = 0.6972471872965494, Gattn=-0.011646315455436707, Dattn=0.020691970363259315, Aattn=0.054251473397016525\n",
      "Epoch = 108, ErrG = 0.5909524112939835, ErrA = 0.48286426067352295, ErrD = 0.3854738821585973, Gattn=-0.011673522181808949, Dattn=0.020748449489474297, Aattn=0.055587176233530045\n",
      "Epoch = 110, ErrG = 1.0175666809082031, ErrA = 0.48901964724063873, ErrD = 0.5549633353948593, Gattn=-0.011733557097613811, Dattn=0.020826812833547592, Aattn=0.05726734921336174\n",
      "Epoch = 112, ErrG = 0.0025653839111328125, ErrA = 0.533255639175574, ErrD = 0.496675506234169, Gattn=-0.011783468537032604, Dattn=0.02094048447906971, Aattn=0.05877433717250824\n",
      "Epoch = 114, ErrG = 0.6675653457641602, ErrA = 0.47292758524417877, ErrD = 0.5812193850676218, Gattn=-0.01181779708713293, Dattn=0.021098194643855095, Aattn=0.06006673350930214\n",
      "Epoch = 116, ErrG = 0.3530256152153015, ErrA = 0.35925386225183803, ErrD = 0.3472176690896352, Gattn=-0.011873862706124783, Dattn=0.021285520866513252, Aattn=0.06145781651139259\n",
      "Epoch = 118, ErrG = 0.42578327655792236, ErrA = 0.5301799476146698, ErrD = 0.4402375320593516, Gattn=-0.011899351142346859, Dattn=0.02145286463201046, Aattn=0.06308846175670624\n",
      "Epoch = 120, ErrG = 0.7014947533607483, ErrA = 0.47252126038074493, ErrD = 0.5327011061211427, Gattn=-0.011953907087445259, Dattn=0.021545657888054848, Aattn=0.06437998265028\n",
      "Epoch = 122, ErrG = 1.019495815038681, ErrA = 0.44738967282076675, ErrD = 0.4712832321723302, Gattn=-0.01200900413095951, Dattn=0.02164384350180626, Aattn=0.06533796340227127\n",
      "Epoch = 124, ErrG = 0.19315456971526146, ErrA = 0.5676376620928446, ErrD = 0.4709712266921997, Gattn=-0.012041125446557999, Dattn=0.021818893030285835, Aattn=0.06664905697107315\n",
      "Epoch = 126, ErrG = 0.768790528178215, ErrA = 0.4319058954715729, ErrD = 0.5529229305684566, Gattn=-0.012076052837073803, Dattn=0.02188960835337639, Aattn=0.06793378293514252\n",
      "Epoch = 128, ErrG = 0.2536225914955139, ErrA = 0.5223322908083597, ErrD = 0.6665974538773298, Gattn=-0.012125679291784763, Dattn=0.022022170946002007, Aattn=0.06917881220579147\n",
      "Epoch = 130, ErrG = 0.479257196187973, ErrA = 0.4149623184154431, ErrD = 0.509129690627257, Gattn=-0.01216553058475256, Dattn=0.02211090177297592, Aattn=0.07029876112937927\n",
      "Epoch = 132, ErrG = 0.7362053692340851, ErrA = 0.5030484342326721, ErrD = 0.5184285913904508, Gattn=-0.012210593558847904, Dattn=0.022138118743896484, Aattn=0.0715331882238388\n",
      "Epoch = 134, ErrG = 1.4140505194664001, ErrA = 0.439872865875562, ErrD = 0.40519438311457634, Gattn=-0.012256212532520294, Dattn=0.022228620946407318, Aattn=0.07286137342453003\n",
      "Epoch = 136, ErrG = 0.5436712503433228, ErrA = 0.4265225927035014, ErrD = 0.37784058849016827, Gattn=-0.012302068993449211, Dattn=0.0222975742071867, Aattn=0.07393907010555267\n",
      "Epoch = 138, ErrG = 0.7457673829048872, ErrA = 0.3946995735168457, ErrD = 0.546600698803862, Gattn=-0.012364414520561695, Dattn=0.02238394133746624, Aattn=0.07514800131320953\n",
      "Epoch = 140, ErrG = 0.33316269516944885, ErrA = 0.5202607413132986, ErrD = 0.42670224110285443, Gattn=-0.012408564798533916, Dattn=0.022477582097053528, Aattn=0.07641847431659698\n",
      "Epoch = 142, ErrG = 1.18413707613945, ErrA = 0.4126505143940449, ErrD = 0.3043880636493365, Gattn=-0.012460213154554367, Dattn=0.022485997527837753, Aattn=0.07740642875432968\n",
      "Epoch = 144, ErrG = 0.526681125164032, ErrA = 0.504986310377717, ErrD = 0.3871438403924306, Gattn=-0.012494378723204136, Dattn=0.02257353812456131, Aattn=0.07845285534858704\n",
      "Epoch = 146, ErrG = 0.31832537055015564, ErrA = 0.33668093631664914, ErrD = 0.6438455283641815, Gattn=-0.012550454586744308, Dattn=0.02266518957912922, Aattn=0.07963359355926514\n",
      "Epoch = 148, ErrG = 0.03719174861907959, ErrA = 0.4654648502667745, ErrD = 0.4980063239733378, Gattn=-0.01258866023272276, Dattn=0.022706689313054085, Aattn=0.080718994140625\n",
      "Epoch = 150, ErrG = 1.3673790991306305, ErrA = 0.34678588310877484, ErrD = 0.38995122412840527, Gattn=-0.012635589577257633, Dattn=0.022610854357481003, Aattn=0.08167747408151627\n",
      "Epoch = 152, ErrG = 0.740918904542923, ErrA = 0.42144976059595746, ErrD = 0.45486372088392574, Gattn=-0.012674939818680286, Dattn=0.022699184715747833, Aattn=0.08290174603462219\n",
      "Epoch = 154, ErrG = 0.47384755313396454, ErrA = 0.5112754826744398, ErrD = 0.472862313191096, Gattn=-0.012709108181297779, Dattn=0.022740306332707405, Aattn=0.08395256102085114\n",
      "Epoch = 156, ErrG = 1.036824882030487, ErrA = 0.4008522840837638, ErrD = 0.5154137071222067, Gattn=-0.012743428349494934, Dattn=0.02266845665872097, Aattn=0.08511260151863098\n",
      "Epoch = 158, ErrG = 1.0092434883117676, ErrA = 0.3834868036210537, ErrD = 0.5378426810105642, Gattn=-0.012786252424120903, Dattn=0.02266618423163891, Aattn=0.08606532216072083\n",
      "Epoch = 160, ErrG = 0.7698818445205688, ErrA = 0.32048582037289935, ErrD = 0.4842298223326604, Gattn=-0.01281164214015007, Dattn=0.022717956453561783, Aattn=0.08707123249769211\n",
      "Epoch = 162, ErrG = 1.7463963031768799, ErrA = 0.5127997497717539, ErrD = 0.3700088628878196, Gattn=-0.012833178974688053, Dattn=0.022679347544908524, Aattn=0.08764681220054626\n",
      "Epoch = 164, ErrG = 0.7519591301679611, ErrA = 0.4458303898572922, ErrD = 0.38313308854897815, Gattn=-0.01287105679512024, Dattn=0.022719914093613625, Aattn=0.08878639340400696\n",
      "Epoch = 166, ErrG = 1.4227089881896973, ErrA = 0.42266956716775894, ErrD = 0.3222362194210291, Gattn=-0.012906884774565697, Dattn=0.022666219621896744, Aattn=0.08983687311410904\n",
      "Epoch = 168, ErrG = 0.12373098731040955, ErrA = 0.39296961451570195, ErrD = 0.3453335265318553, Gattn=-0.012956369668245316, Dattn=0.022760828956961632, Aattn=0.0904434472322464\n",
      "Epoch = 170, ErrG = 0.9711933732032776, ErrA = 0.48444629088044167, ErrD = 0.36663592606782913, Gattn=-0.012982935644686222, Dattn=0.02275817282497883, Aattn=0.09123720228672028\n",
      "Epoch = 172, ErrG = 1.1256594061851501, ErrA = 0.310086856285731, ErrD = 0.26859237253665924, Gattn=-0.013008346781134605, Dattn=0.022765787318348885, Aattn=0.09218155592679977\n",
      "Epoch = 174, ErrG = 2.098876416683197, ErrA = 0.44485197961330414, ErrD = 0.3040811065584421, Gattn=-0.013041258789598942, Dattn=0.022759804502129555, Aattn=0.09288939833641052\n",
      "Epoch = 176, ErrG = 0.455326059833169, ErrA = 0.40147213886181515, ErrD = 0.28719191749890643, Gattn=-0.013082630932331085, Dattn=0.022800521925091743, Aattn=0.0938795879483223\n",
      "Epoch = 178, ErrG = 0.7344689965248108, ErrA = 0.4962209289272626, ErrD = 0.3642098406950633, Gattn=-0.013110317289829254, Dattn=0.02277453802525997, Aattn=0.09473336488008499\n",
      "Epoch = 180, ErrG = 1.4750690460205078, ErrA = 0.35644084215164185, ErrD = 0.02167210231224696, Gattn=-0.013142499141395092, Dattn=0.02283979207277298, Aattn=0.09553620219230652\n",
      "Epoch = 182, ErrG = 0.9422885179519653, ErrA = 0.495390884578228, ErrD = 0.5440639654795328, Gattn=-0.01315941009670496, Dattn=0.02256573550403118, Aattn=0.09624879062175751\n",
      "Epoch = 184, ErrG = 0.5213383883237839, ErrA = 0.3823191076517105, ErrD = 0.27963992953300476, Gattn=-0.013202017173171043, Dattn=0.022509856149554253, Aattn=0.0970902144908905\n",
      "Epoch = 186, ErrG = 0.47378990054130554, ErrA = 0.42039642731348675, ErrD = 0.2930278715988, Gattn=-0.013231354765594006, Dattn=0.022483445703983307, Aattn=0.0980929285287857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 188, ErrG = 0.6759753674268723, ErrA = 0.3857127403219541, ErrD = 0.3561445126930873, Gattn=-0.013287266716361046, Dattn=0.02251395583152771, Aattn=0.09869275987148285\n",
      "Epoch = 190, ErrG = -0.34217745065689087, ErrA = 0.48853286045293015, ErrD = 0.5048794994751612, Gattn=-0.013311813585460186, Dattn=0.02252340316772461, Aattn=0.0994398221373558\n",
      "Epoch = 192, ErrG = 1.00471830368042, ErrA = 0.44253737355271977, ErrD = 0.27458227674166363, Gattn=-0.01331554725766182, Dattn=0.02247766964137554, Aattn=0.10004102438688278\n",
      "Epoch = 194, ErrG = 0.7553345859050751, ErrA = 0.47755634722610313, ErrD = 0.4919276957710584, Gattn=-0.013378213159739971, Dattn=0.022476568818092346, Aattn=0.10103055089712143\n",
      "Epoch = 196, ErrG = 0.71193066239357, ErrA = 0.545421801507473, ErrD = 0.45395897328853607, Gattn=-0.013416052795946598, Dattn=0.022486018016934395, Aattn=0.10193054378032684\n",
      "Epoch = 198, ErrG = 1.7210158705711365, ErrA = 0.42164099713166553, ErrD = 0.2774216930071513, Gattn=-0.013447616249322891, Dattn=0.02243947796523571, Aattn=0.10246042162179947\n",
      "Epoch = 200, ErrG = 0.7580780982971191, ErrA = 0.3725424961497386, ErrD = 0.24270936474204063, Gattn=-0.013483129441738129, Dattn=0.022453850135207176, Aattn=0.10336346924304962\n",
      "Epoch = 202, ErrG = 0.9023535698652267, ErrA = 0.434036244948705, ErrD = 0.22445418126881123, Gattn=-0.013522247783839703, Dattn=0.022346321493387222, Aattn=0.10421109944581985\n",
      "Epoch = 204, ErrG = 1.3000727891921997, ErrA = 0.5399630318085352, ErrD = 0.1635531485080719, Gattn=-0.013569516129791737, Dattn=0.02236299216747284, Aattn=0.10466333478689194\n",
      "Epoch = 206, ErrG = 1.5420011579990387, ErrA = 0.4491953756660223, ErrD = 0.24039187903205553, Gattn=-0.013589692302048206, Dattn=0.022320060059428215, Aattn=0.10547588020563126\n",
      "Epoch = 208, ErrG = 0.2386850267648697, ErrA = 0.37285222361485165, ErrD = 0.6108832856019338, Gattn=-0.01363869197666645, Dattn=0.022391783073544502, Aattn=0.10621581226587296\n",
      "Epoch = 210, ErrG = 1.4812753796577454, ErrA = 0.5188995003700256, ErrD = 0.3975478410720825, Gattn=-0.013649791479110718, Dattn=0.022294141352176666, Aattn=0.10686381161212921\n",
      "Epoch = 212, ErrG = 0.9143053293228149, ErrA = 0.3969939611852169, ErrD = 0.3649420415361722, Gattn=-0.013683800585567951, Dattn=0.02224639616906643, Aattn=0.10760597884654999\n",
      "Epoch = 214, ErrG = 1.8312013149261475, ErrA = 0.4664795696735382, ErrD = 0.15822285848359266, Gattn=-0.013711720705032349, Dattn=0.022166162729263306, Aattn=0.1083541065454483\n",
      "Epoch = 216, ErrG = 0.20582035183906555, ErrA = 0.3541298458973567, ErrD = 0.4272223711013794, Gattn=-0.01373358815908432, Dattn=0.02220783568918705, Aattn=0.1088983342051506\n",
      "Epoch = 218, ErrG = 0.8216986656188965, ErrA = 0.501069908340772, ErrD = 0.32777339220046997, Gattn=-0.01377793401479721, Dattn=0.022162480279803276, Aattn=0.10940200090408325\n",
      "Epoch = 220, ErrG = 0.9588289856910706, ErrA = 0.4085983633995056, ErrD = 0.41394840367138386, Gattn=-0.013839267194271088, Dattn=0.022117555141448975, Aattn=0.11014913022518158\n",
      "Epoch = 222, ErrG = 0.81749626994133, ErrA = 0.3984279086192449, ErrD = 0.16887137045462927, Gattn=-0.013885335996747017, Dattn=0.022079763934016228, Aattn=0.11082866787910461\n",
      "Epoch = 224, ErrG = 0.38085781037807465, ErrA = 0.276174183934927, ErrD = 0.17735861738522848, Gattn=-0.013926871120929718, Dattn=0.022061491385102272, Aattn=0.11140574514865875\n",
      "Epoch = 226, ErrG = 1.5496849119663239, ErrA = 0.4535134832064311, ErrD = 0.29757382969061535, Gattn=-0.013971807435154915, Dattn=0.021956345066428185, Aattn=0.1119636595249176\n",
      "Epoch = 228, ErrG = -0.612547904253006, ErrA = 0.48708613341053325, ErrD = 0.604349156220754, Gattn=-0.014024736359715462, Dattn=0.021999776363372803, Aattn=0.11252498626708984\n",
      "Epoch = 230, ErrG = 0.37393102794885635, ErrA = 0.34376535067955655, ErrD = 0.2504119426012039, Gattn=-0.014051917940378189, Dattn=0.02191711775958538, Aattn=0.11302624642848969\n",
      "Epoch = 232, ErrG = 0.6920098662376404, ErrA = 0.35385662317276, ErrD = 0.2373384733994802, Gattn=-0.01408542413264513, Dattn=0.021903663873672485, Aattn=0.11385670304298401\n",
      "Epoch = 234, ErrG = 0.6524372100830078, ErrA = 0.40083133180936176, ErrD = 0.25832700232664746, Gattn=-0.014134050346910954, Dattn=0.021837648004293442, Aattn=0.11422353982925415\n",
      "Epoch = 236, ErrG = 1.2101105451583862, ErrA = 0.3342659920454025, ErrD = 0.25618352741003036, Gattn=-0.014152090065181255, Dattn=0.021803494542837143, Aattn=0.11479134857654572\n",
      "Epoch = 238, ErrG = 1.4843524098396301, ErrA = 0.4738062272469203, ErrD = 0.4241989478468895, Gattn=-0.014195835217833519, Dattn=0.021756811067461967, Aattn=0.11555913090705872\n",
      "Epoch = 240, ErrG = 1.7820961475372314, ErrA = 0.42845791826645535, ErrD = 0.23645940298835436, Gattn=-0.014230375178158283, Dattn=0.02170456573367119, Aattn=0.11603298783302307\n",
      "Epoch = 242, ErrG = 1.677609622478485, ErrA = 0.39555523296197254, ErrD = 0.2718867361545563, Gattn=-0.014269860461354256, Dattn=0.021609848365187645, Aattn=0.11662115156650543\n",
      "Epoch = 244, ErrG = 0.6174497902393341, ErrA = 0.23880831400553384, ErrD = 0.384883563965559, Gattn=-0.014294740743935108, Dattn=0.02157589979469776, Aattn=0.11733544617891312\n",
      "Epoch = 246, ErrG = 1.5175326466560364, ErrA = 0.47891077895959216, ErrD = 0.419728039453427, Gattn=-0.01433546096086502, Dattn=0.021503804251551628, Aattn=0.11800350993871689\n",
      "Epoch = 248, ErrG = 2.114924907684326, ErrA = 0.5141981020569801, ErrD = 0.3341788227359454, Gattn=-0.01438572071492672, Dattn=0.021444085985422134, Aattn=0.11853261291980743\n",
      "Epoch = 250, ErrG = 0.644835464656353, ErrA = 0.3025324468811353, ErrD = 0.5054467419783274, Gattn=-0.01440601795911789, Dattn=0.021408751606941223, Aattn=0.1191079318523407\n",
      "Epoch = 252, ErrG = 1.7216481566429138, ErrA = 0.3791455353299777, ErrD = 0.15385115208725134, Gattn=-0.014465834014117718, Dattn=0.02125631645321846, Aattn=0.11959508806467056\n",
      "Epoch = 254, ErrG = 1.0662919580936432, ErrA = 0.2797669855256875, ErrD = 0.10358728654682636, Gattn=-0.014499536715447903, Dattn=0.021198321133852005, Aattn=0.1199914813041687\n",
      "Epoch = 256, ErrG = 1.588460624217987, ErrA = 0.3675580198566119, ErrD = 0.19933976791799068, Gattn=-0.014534338377416134, Dattn=0.021184591576457024, Aattn=0.12062019854784012\n",
      "Epoch = 258, ErrG = 1.7879351377487183, ErrA = 0.3651784285902977, ErrD = 0.22932703296343485, Gattn=-0.014577689580619335, Dattn=0.021128971129655838, Aattn=0.12106076627969742\n",
      "Epoch = 260, ErrG = 1.2717735767364502, ErrA = 0.4041665221254031, ErrD = 0.26559223234653473, Gattn=-0.014602923765778542, Dattn=0.021066749468445778, Aattn=0.12167699635028839\n",
      "Epoch = 262, ErrG = 1.3420521020889282, ErrA = 0.3951620894173781, ErrD = 0.2493357335527738, Gattn=-0.014639385044574738, Dattn=0.021031709387898445, Aattn=0.12216842919588089\n",
      "Epoch = 264, ErrG = 0.4871515929698944, ErrA = 0.34239620963732403, ErrD = 0.19422721366087595, Gattn=-0.014676823280751705, Dattn=0.02102929726243019, Aattn=0.12257184833288193\n",
      "Epoch = 266, ErrG = 0.7336223721504211, ErrA = 0.3471677303314209, ErrD = 0.3385629951953888, Gattn=-0.014707761816680431, Dattn=0.02097153849899769, Aattn=0.12302938103675842\n",
      "Epoch = 268, ErrG = 0.8355037569999695, ErrA = 0.7376533448696136, ErrD = 0.27606950265665847, Gattn=-0.014719588682055473, Dattn=0.020935622975230217, Aattn=0.12351001054048538\n",
      "Epoch = 270, ErrG = 1.597642421722412, ErrA = 0.3905226141214371, ErrD = 0.10456570734580357, Gattn=-0.014768669381737709, Dattn=0.020853612571954727, Aattn=0.12385730445384979\n",
      "Epoch = 272, ErrG = 0.5371950268745422, ErrA = 0.4283544222513835, ErrD = 0.39273977279663086, Gattn=-0.014820803888142109, Dattn=0.02084442786872387, Aattn=0.12442628294229507\n",
      "Epoch = 274, ErrG = 1.1880142539739609, ErrA = 0.3787616689999898, ErrD = 0.22922465205192566, Gattn=-0.01486673392355442, Dattn=0.020635994151234627, Aattn=0.12484227865934372\n",
      "Epoch = 276, ErrG = 1.8794270753860474, ErrA = 0.40530773003896076, ErrD = 0.24026617469886938, Gattn=-0.014901531860232353, Dattn=0.02067873626947403, Aattn=0.12522022426128387\n",
      "Epoch = 278, ErrG = 2.0639444291591644, ErrA = 0.20886817201972008, ErrD = 0.11657086263100307, Gattn=-0.014948074705898762, Dattn=0.020537156611680984, Aattn=0.12603214383125305\n",
      "Epoch = 280, ErrG = 1.0843743830919266, ErrA = 0.3248751585682233, ErrD = 0.2982386847337087, Gattn=-0.015000897459685802, Dattn=0.02054479531943798, Aattn=0.12649793922901154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 282, ErrG = 1.5556307435035706, ErrA = 0.4463205710053444, ErrD = 0.31928500284751254, Gattn=-0.015047806315124035, Dattn=0.020505735650658607, Aattn=0.12681598961353302\n",
      "Epoch = 284, ErrG = 1.2538426518440247, ErrA = 0.2810995342830817, ErrD = 0.31066010457774, Gattn=-0.01509208232164383, Dattn=0.020398883149027824, Aattn=0.12747325003147125\n",
      "Epoch = 286, ErrG = 0.967411682009697, ErrA = 0.2551736906170845, ErrD = 0.24104593694210052, Gattn=-0.01512041687965393, Dattn=0.020315047353506088, Aattn=0.1280733197927475\n",
      "Epoch = 288, ErrG = 1.8535668849945068, ErrA = 0.4252461517850558, ErrD = 0.38152264927824336, Gattn=-0.015167401172220707, Dattn=0.020258860662579536, Aattn=0.12857785820960999\n",
      "Epoch = 290, ErrG = 0.6663249433040619, ErrA = 0.27613263328870136, ErrD = 0.23087313771247864, Gattn=-0.015194619074463844, Dattn=0.020278174430131912, Aattn=0.1289464831352234\n",
      "Epoch = 292, ErrG = 1.5400712490081787, ErrA = 0.33082864930232364, ErrD = 0.32124556849400204, Gattn=-0.01523568294942379, Dattn=0.02021743357181549, Aattn=0.12954266369342804\n",
      "Epoch = 294, ErrG = 1.8832976818084717, ErrA = 0.3044256766637166, ErrD = 0.35657548904418945, Gattn=-0.015279601328074932, Dattn=0.020157989114522934, Aattn=0.13000118732452393\n",
      "Epoch = 296, ErrG = 1.1733938455581665, ErrA = 0.3272169927755992, ErrD = 0.3370304045577844, Gattn=-0.01531517505645752, Dattn=0.020141802728176117, Aattn=0.13049471378326416\n",
      "Epoch = 298, ErrG = 1.5367016196250916, ErrA = 0.3942062109708786, ErrD = 0.13319189473986626, Gattn=-0.015350431203842163, Dattn=0.02010941132903099, Aattn=0.13068415224552155\n",
      "Epoch = 300, ErrG = 1.1162893176078796, ErrA = 0.3416499098141988, ErrD = 0.48864444096883136, Gattn=-0.015394283458590508, Dattn=0.020068282261490822, Aattn=0.1313009262084961\n",
      "Epoch = 302, ErrG = 0.5640727877616882, ErrA = 0.3515700300534566, ErrD = 0.2163138141234716, Gattn=-0.015448149293661118, Dattn=0.01999656856060028, Aattn=0.13147814571857452\n",
      "Epoch = 304, ErrG = 1.334097683429718, ErrA = 0.26839453106125194, ErrD = 0.2407871882120768, Gattn=-0.015501365065574646, Dattn=0.019958503544330597, Aattn=0.13189542293548584\n",
      "Epoch = 306, ErrG = 2.2509820461273193, ErrA = 0.30387830796341103, ErrD = 0.3368615706761678, Gattn=-0.015524592250585556, Dattn=0.019901251420378685, Aattn=0.1321810483932495\n",
      "Epoch = 308, ErrG = 1.1516504436731339, ErrA = 0.2711264385531346, ErrD = 0.3470606555541356, Gattn=-0.015577074140310287, Dattn=0.01984409987926483, Aattn=0.13253891468048096\n",
      "Epoch = 310, ErrG = 0.5776814222335815, ErrA = 0.3211362486084302, ErrD = 0.15186400711536407, Gattn=-0.015607385896146297, Dattn=0.01983780786395073, Aattn=0.13298842310905457\n",
      "Epoch = 312, ErrG = 1.7860646545886993, ErrA = 0.3319481089711189, ErrD = 0.14041130927701792, Gattn=-0.01565154828131199, Dattn=0.019796965643763542, Aattn=0.13357314467430115\n",
      "Epoch = 314, ErrG = 1.349558174610138, ErrA = 0.3607330272595088, ErrD = 0.1470794975757599, Gattn=-0.01569266803562641, Dattn=0.019718250259757042, Aattn=0.13398779928684235\n",
      "Epoch = 316, ErrG = 1.7058307528495789, ErrA = 0.3564046348134677, ErrD = 0.19925089677174887, Gattn=-0.01574576087296009, Dattn=0.019707398489117622, Aattn=0.1343257576227188\n",
      "Epoch = 318, ErrG = 0.8070605099201202, ErrA = 0.222557802995046, ErrD = 0.17376371224721274, Gattn=-0.015784328803420067, Dattn=0.019620852544903755, Aattn=0.13467943668365479\n",
      "Epoch = 320, ErrG = 1.7969069480895996, ErrA = 0.28228154468039673, ErrD = 0.2252467374006907, Gattn=-0.01583011820912361, Dattn=0.019573554396629333, Aattn=0.13491836190223694\n",
      "Epoch = 322, ErrG = 1.5197557210922241, ErrA = 0.32021346129477024, ErrD = 0.22479591146111488, Gattn=-0.01586179994046688, Dattn=0.019507726654410362, Aattn=0.13580191135406494\n",
      "Epoch = 324, ErrG = 1.4136715531349182, ErrA = 0.321527694662412, ErrD = 0.09186071778337161, Gattn=-0.01590772159397602, Dattn=0.0195574052631855, Aattn=0.13611596822738647\n",
      "Epoch = 326, ErrG = 1.9074566960334778, ErrA = 0.35411446293195087, ErrD = 0.4007062378029029, Gattn=-0.015941478312015533, Dattn=0.019433293491601944, Aattn=0.13636232912540436\n",
      "Epoch = 328, ErrG = 1.3164629936218262, ErrA = 0.32425988217194873, ErrD = 0.2411800722281138, Gattn=-0.015996938571333885, Dattn=0.019511325284838676, Aattn=0.1366102248430252\n",
      "Epoch = 330, ErrG = 1.2584526538848877, ErrA = 0.3816433946291606, ErrD = 0.18481232225894928, Gattn=-0.016027051955461502, Dattn=0.019468054175376892, Aattn=0.13708911836147308\n",
      "Epoch = 332, ErrG = 1.9694120287895203, ErrA = 0.3030138990531365, ErrD = 0.08181513162950675, Gattn=-0.016060257330536842, Dattn=0.0194386076182127, Aattn=0.13741613924503326\n",
      "Epoch = 334, ErrG = 1.3321025967597961, ErrA = 0.2411449352900187, ErrD = 0.10384101110200088, Gattn=-0.016114631667733192, Dattn=0.019344966858625412, Aattn=0.13796459138393402\n",
      "Epoch = 336, ErrG = 1.8534225225448608, ErrA = 0.30676605304082233, ErrD = 0.2680614988009135, Gattn=-0.01617276854813099, Dattn=0.019206734374165535, Aattn=0.1382177174091339\n",
      "Epoch = 338, ErrG = 1.5147197842597961, ErrA = 0.2763860747218132, ErrD = 0.08788725112875302, Gattn=-0.01622508279979229, Dattn=0.01920389197766781, Aattn=0.13855071365833282\n",
      "Epoch = 340, ErrG = 2.1297035217285156, ErrA = 0.23658949074645838, ErrD = 0.140617569287618, Gattn=-0.01627403497695923, Dattn=0.019218886271119118, Aattn=0.1389501690864563\n",
      "Epoch = 342, ErrG = 1.2747008204460144, ErrA = 0.3312329252560933, ErrD = 0.1676554928223292, Gattn=-0.01632492057979107, Dattn=0.019133999943733215, Aattn=0.13940289616584778\n",
      "Epoch = 344, ErrG = 1.6692572236061096, ErrA = 0.2724941248695056, ErrD = 0.02647874380151431, Gattn=-0.016400475054979324, Dattn=0.019141456112265587, Aattn=0.13972124457359314\n",
      "Epoch = 346, ErrG = 0.9803408086299896, ErrA = 0.2931245391567548, ErrD = 0.24373057236274084, Gattn=-0.01640918478369713, Dattn=0.019153451547026634, Aattn=0.1400776505470276\n",
      "Epoch = 348, ErrG = 1.5645398497581482, ErrA = 0.27939560015996295, ErrD = 0.11987873663504918, Gattn=-0.01646224595606327, Dattn=0.019027873873710632, Aattn=0.14050284028053284\n",
      "Epoch = 350, ErrG = 0.9132517278194427, ErrA = 0.2954002767801285, ErrD = 0.3983361391971509, Gattn=-0.016532035544514656, Dattn=0.019061744213104248, Aattn=0.14081986248493195\n",
      "Epoch = 352, ErrG = 1.7154659032821655, ErrA = 0.2785043232142925, ErrD = 0.1027648001909256, Gattn=-0.01656939834356308, Dattn=0.01898074895143509, Aattn=0.14132654666900635\n",
      "Epoch = 354, ErrG = 1.7180015444755554, ErrA = 0.2909222189337015, ErrD = 0.04410538636147976, Gattn=-0.016612034291028976, Dattn=0.018896078690886497, Aattn=0.14147521555423737\n",
      "Epoch = 356, ErrG = 2.192271649837494, ErrA = 0.33891426647702855, ErrD = 0.1056767242650191, Gattn=-0.016650622710585594, Dattn=0.018793879076838493, Aattn=0.14196722209453583\n",
      "Epoch = 358, ErrG = 2.872151255607605, ErrA = 0.29246968030929565, ErrD = 0.06095592180887858, Gattn=-0.016705118119716644, Dattn=0.01878267712891102, Aattn=0.14216698706150055\n",
      "Epoch = 360, ErrG = 1.7119807600975037, ErrA = 0.3243212290108204, ErrD = 0.1425518443187078, Gattn=-0.01676267571747303, Dattn=0.018763378262519836, Aattn=0.14235618710517883\n",
      "Epoch = 362, ErrG = 1.6342381536960602, ErrA = 0.30423004801074666, ErrD = 0.23325739552577338, Gattn=-0.016801977530121803, Dattn=0.018781235441565514, Aattn=0.14237159490585327\n",
      "Epoch = 364, ErrG = 2.2226245403289795, ErrA = 0.35071974992752075, ErrD = 0.00496968316535155, Gattn=-0.016858812421560287, Dattn=0.018734507262706757, Aattn=0.1425582468509674\n",
      "Epoch = 366, ErrG = 0.8943896293640137, ErrA = 0.30061686784029007, ErrD = 0.21556337674458823, Gattn=-0.016921980306506157, Dattn=0.01871906779706478, Aattn=0.14321811497211456\n",
      "Epoch = 368, ErrG = 2.0555087327957153, ErrA = 0.1686107808103164, ErrD = 0.07722278373936813, Gattn=-0.01697332039475441, Dattn=0.01868237368762493, Aattn=0.14372821152210236\n",
      "Epoch = 370, ErrG = 2.1286012530326843, ErrA = 0.2837948327263196, ErrD = 0.17264924943447113, Gattn=-0.01701500080525875, Dattn=0.018644047901034355, Aattn=0.14379581809043884\n",
      "Epoch = 372, ErrG = 1.4068997502326965, ErrA = 0.33554914593696594, ErrD = 0.14856122247874737, Gattn=-0.017081499099731445, Dattn=0.01862260326743126, Aattn=0.14411526918411255\n",
      "Epoch = 374, ErrG = 1.4292734265327454, ErrA = 0.15618711585799852, ErrD = 0.25767852862675983, Gattn=-0.017125526443123817, Dattn=0.018619177863001823, Aattn=0.144328311085701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 376, ErrG = 2.3277333974838257, ErrA = 0.28991857171058655, ErrD = 0.09432371705770493, Gattn=-0.01715625450015068, Dattn=0.01855456456542015, Aattn=0.14471375942230225\n",
      "Epoch = 378, ErrG = 0.8720053434371948, ErrA = 0.1527638422946135, ErrD = 0.3949868530035019, Gattn=-0.017211779952049255, Dattn=0.018550043925642967, Aattn=0.1450711488723755\n",
      "Epoch = 380, ErrG = 2.8400436639785767, ErrA = 0.3514976470420758, ErrD = 0.17523590723673502, Gattn=-0.017252475023269653, Dattn=0.018460793420672417, Aattn=0.14536993205547333\n",
      "Epoch = 382, ErrG = 2.4275747537612915, ErrA = 0.1701316460967064, ErrD = 0.04692357654372851, Gattn=-0.017306765541434288, Dattn=0.01838310807943344, Aattn=0.14577271044254303\n",
      "Epoch = 384, ErrG = 2.262136220932007, ErrA = 0.36663631722331047, ErrD = 0.1500918666521708, Gattn=-0.017352014780044556, Dattn=0.018454043194651604, Aattn=0.14621219038963318\n",
      "Epoch = 386, ErrG = 1.5769317150115967, ErrA = 0.21206103513638178, ErrD = 0.08238822221755981, Gattn=-0.01741015911102295, Dattn=0.018355272710323334, Aattn=0.14624154567718506\n",
      "Epoch = 388, ErrG = 2.240892171859741, ErrA = 0.2130833069483439, ErrD = 0.08895175469418366, Gattn=-0.017449762672185898, Dattn=0.018255487084388733, Aattn=0.14653868973255157\n",
      "Epoch = 390, ErrG = 2.157979965209961, ErrA = 0.2130830635627111, ErrD = 0.0898389033973217, Gattn=-0.01749582029879093, Dattn=0.018201392143964767, Aattn=0.14668500423431396\n",
      "Epoch = 392, ErrG = 2.5858618021011353, ErrA = 0.23129835476477942, ErrD = 0.10394499513010184, Gattn=-0.017533108592033386, Dattn=0.018192891031503677, Aattn=0.147127166390419\n",
      "Epoch = 394, ErrG = 1.474388301372528, ErrA = 0.1532778770973285, ErrD = 0.1465866050372521, Gattn=-0.01759207807481289, Dattn=0.018239332363009453, Aattn=0.1472359001636505\n",
      "Epoch = 396, ErrG = 2.5556966066360474, ErrA = 0.2801169945547978, ErrD = 0.12950665752092996, Gattn=-0.01764359511435032, Dattn=0.018123574554920197, Aattn=0.14758048951625824\n",
      "Epoch = 398, ErrG = 2.1234837770462036, ErrA = 0.23052387746671835, ErrD = 0.1243153524895509, Gattn=-0.017692014575004578, Dattn=0.01815273053944111, Aattn=0.1477750986814499\n",
      "Epoch = 400, ErrG = 1.8472098112106323, ErrA = 0.18280236919720969, ErrD = 0.1668268864353498, Gattn=-0.017722923308610916, Dattn=0.018105629831552505, Aattn=0.14816763997077942\n",
      "Epoch = 402, ErrG = 1.3191162943840027, ErrA = 0.22424103630085787, ErrD = 0.24760136008262634, Gattn=-0.01777677796781063, Dattn=0.018077442422509193, Aattn=0.14854298532009125\n",
      "Epoch = 404, ErrG = 2.41850209236145, ErrA = 0.3799243705968062, ErrD = 0.10426256060600281, Gattn=-0.01781732216477394, Dattn=0.0179513618350029, Aattn=0.1489880234003067\n",
      "Epoch = 406, ErrG = 2.196542263031006, ErrA = 0.20835462088386217, ErrD = 0.047989935924609504, Gattn=-0.01788106933236122, Dattn=0.017934145405888557, Aattn=0.14924390614032745\n",
      "Epoch = 408, ErrG = 2.6624934673309326, ErrA = 0.3003178909420967, ErrD = 0.05264204305907091, Gattn=-0.01791602000594139, Dattn=0.017903607338666916, Aattn=0.14962291717529297\n",
      "Epoch = 410, ErrG = 1.9535666704177856, ErrA = 0.20871558785438538, ErrD = 0.03746199049055576, Gattn=-0.017940104007720947, Dattn=0.017850711941719055, Aattn=0.14973823726177216\n",
      "Epoch = 412, ErrG = 1.8415675461292267, ErrA = 0.1717816268404325, ErrD = 0.10690601853032906, Gattn=-0.017979862168431282, Dattn=0.0178932286798954, Aattn=0.150104820728302\n",
      "Epoch = 414, ErrG = 3.072325825691223, ErrA = 0.13330959777037302, ErrD = 0.15501675258080164, Gattn=-0.01805407553911209, Dattn=0.017850661650300026, Aattn=0.1501658856868744\n",
      "Epoch = 416, ErrG = 2.337629973888397, ErrA = 0.3035847010711829, ErrD = 0.10908926961322625, Gattn=-0.018083037808537483, Dattn=0.017772311344742775, Aattn=0.15079690515995026\n",
      "Epoch = 418, ErrG = 1.340487539768219, ErrA = 0.3664422780275345, ErrD = 0.03048774724205335, Gattn=-0.01813729666173458, Dattn=0.01784379780292511, Aattn=0.15106083452701569\n",
      "Epoch = 420, ErrG = 1.6230440735816956, ErrA = 0.18939383576313654, ErrD = 0.04833731551965078, Gattn=-0.01819627732038498, Dattn=0.017728324979543686, Aattn=0.1515948325395584\n",
      "Epoch = 422, ErrG = 2.809857189655304, ErrA = 0.27622084381679696, ErrD = 0.034127713491519295, Gattn=-0.018243348225951195, Dattn=0.017789214849472046, Aattn=0.15167488157749176\n",
      "Epoch = 424, ErrG = 2.275072693824768, ErrA = 0.16892089943091074, ErrD = 0.12848160105446974, Gattn=-0.018312422558665276, Dattn=0.017772845923900604, Aattn=0.15218298137187958\n",
      "Epoch = 426, ErrG = 2.2670395374298096, ErrA = 0.35461196800072986, ErrD = 0.07390439386169116, Gattn=-0.018390024080872536, Dattn=0.017745714634656906, Aattn=0.1526573896408081\n",
      "Epoch = 428, ErrG = 2.190929889678955, ErrA = 0.10954115974406402, ErrD = 0.244313915570577, Gattn=-0.01843966357409954, Dattn=0.01772758550941944, Aattn=0.15306240320205688\n",
      "Epoch = 430, ErrG = 2.1806538701057434, ErrA = 0.22267372906208038, ErrD = 0.1781211861719688, Gattn=-0.018499014899134636, Dattn=0.017619553953409195, Aattn=0.15329375863075256\n",
      "Epoch = 432, ErrG = 1.9541661739349365, ErrA = 0.13047660887241364, ErrD = 0.10687159498532613, Gattn=-0.018548060208559036, Dattn=0.017717206850647926, Aattn=0.1533764898777008\n",
      "Epoch = 434, ErrG = 2.5450901985168457, ErrA = 0.2854213739434878, ErrD = 0.08687404791514079, Gattn=-0.01859724149107933, Dattn=0.017652161419391632, Aattn=0.15387636423110962\n",
      "Epoch = 436, ErrG = 2.2381080389022827, ErrA = 0.24739666531483331, ErrD = 0.05519682914018631, Gattn=-0.018635254353284836, Dattn=0.01760459877550602, Aattn=0.15424631536006927\n",
      "Epoch = 438, ErrG = 2.4749494194984436, ErrA = 0.1859369476636251, ErrD = 0.11832006772359212, Gattn=-0.018688134849071503, Dattn=0.017577240243554115, Aattn=0.154711052775383\n",
      "Epoch = 440, ErrG = 1.2915718257427216, ErrA = 0.26446321482459706, ErrD = 0.3891329566637675, Gattn=-0.018703116104006767, Dattn=0.017608754336833954, Aattn=0.15476514399051666\n",
      "Epoch = 442, ErrG = 1.4777776002883911, ErrA = 0.25458306074142456, ErrD = 0.16283971071243286, Gattn=-0.018783798441290855, Dattn=0.017557092010974884, Aattn=0.15510623157024384\n",
      "Epoch = 444, ErrG = 2.7621755599975586, ErrA = 0.25404487550258636, ErrD = 0.06643430702388287, Gattn=-0.01881837472319603, Dattn=0.017498232424259186, Aattn=0.15546004474163055\n",
      "Epoch = 446, ErrG = 1.8861705660820007, ErrA = 0.2244578351577123, ErrD = 0.032626633842786155, Gattn=-0.018889715895056725, Dattn=0.01744980923831463, Aattn=0.15575547516345978\n",
      "Epoch = 448, ErrG = 2.028794527053833, ErrA = 0.28898151963949203, ErrD = 0.07722022632757823, Gattn=-0.018921364098787308, Dattn=0.01751246675848961, Aattn=0.15598109364509583\n",
      "Epoch = 450, ErrG = 2.7778728008270264, ErrA = 0.21193835884332657, ErrD = 0.12159252911806107, Gattn=-0.018986450508236885, Dattn=0.017426978796720505, Aattn=0.1563301533460617\n",
      "Epoch = 452, ErrG = 2.4353467226028442, ErrA = 0.1663770725329717, ErrD = 0.0943836768468221, Gattn=-0.01901046186685562, Dattn=0.017439477145671844, Aattn=0.15682034194469452\n",
      "Epoch = 454, ErrG = 2.3955132961273193, ErrA = 0.21135846773783365, ErrD = 0.08234776991109054, Gattn=-0.01906462013721466, Dattn=0.017414536327123642, Aattn=0.15732520818710327\n",
      "Epoch = 456, ErrG = 2.332502245903015, ErrA = 0.09067249422272046, ErrD = 0.02264031395316124, Gattn=-0.019092220813035965, Dattn=0.017404714599251747, Aattn=0.15743933618068695\n",
      "Epoch = 458, ErrG = 2.334995985031128, ErrA = 0.15371781090895334, ErrD = 0.08209060939649741, Gattn=-0.01912790723145008, Dattn=0.017260905355215073, Aattn=0.15801015496253967\n",
      "Epoch = 460, ErrG = 1.8463170528411865, ErrA = 0.19956203984717527, ErrD = 0.09211302051941554, Gattn=-0.019177120178937912, Dattn=0.01726231537759304, Aattn=0.1582866758108139\n",
      "Epoch = 462, ErrG = 1.991324782371521, ErrA = 0.2594951130449772, ErrD = 0.024068606396516163, Gattn=-0.019247351214289665, Dattn=0.017231186851859093, Aattn=0.1583748459815979\n",
      "Epoch = 464, ErrG = 2.5846287608146667, ErrA = 0.19335672010978064, ErrD = 0.11816878616809845, Gattn=-0.019293271005153656, Dattn=0.017133811488747597, Aattn=0.158648282289505\n",
      "Epoch = 466, ErrG = 2.654039740562439, ErrA = 0.17924344539642334, ErrD = 0.09429061412811279, Gattn=-0.019320564344525337, Dattn=0.01708528958261013, Aattn=0.15919223427772522\n",
      "Epoch = 468, ErrG = 1.796250581741333, ErrA = 0.13106991350650787, ErrD = 0.1573592871427536, Gattn=-0.019389737397432327, Dattn=0.017070753499865532, Aattn=0.15973226726055145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 470, ErrG = 2.577104091644287, ErrA = 0.1917615681886673, ErrD = 0.02472281518081824, Gattn=-0.019432472065091133, Dattn=0.016977449879050255, Aattn=0.1597951501607895\n",
      "Epoch = 472, ErrG = 1.9232202768325806, ErrA = 0.31466099930306274, ErrD = 0.1260106364885966, Gattn=-0.019514458253979683, Dattn=0.016977353021502495, Aattn=0.16015253961086273\n",
      "Epoch = 474, ErrG = 2.4668508768081665, ErrA = 0.12074443697929382, ErrD = 0.11391653617223103, Gattn=-0.01956813782453537, Dattn=0.016921386122703552, Aattn=0.16036516427993774\n",
      "Epoch = 476, ErrG = 2.2352635860443115, ErrA = 0.06397978713115056, ErrD = 0.04118705044190089, Gattn=-0.01961853727698326, Dattn=0.01690421998500824, Aattn=0.16071023046970367\n",
      "Epoch = 478, ErrG = 1.7247258126735687, ErrA = 0.20517059167226157, ErrD = 0.12780851125717163, Gattn=-0.019655214622616768, Dattn=0.016919000074267387, Aattn=0.1611608862876892\n",
      "Epoch = 480, ErrG = 1.457535445690155, ErrA = 0.18085120618343353, ErrD = 0.18368761241436005, Gattn=-0.019703712314367294, Dattn=0.016927363350987434, Aattn=0.16146589815616608\n",
      "Epoch = 482, ErrG = 2.2219552993774414, ErrA = 0.1382643481095632, ErrD = 0.04395672492682934, Gattn=-0.01973852515220642, Dattn=0.01677107624709606, Aattn=0.16186772286891937\n",
      "Epoch = 484, ErrG = 2.1274081468582153, ErrA = 0.1471883232394854, ErrD = 0.08583161979913712, Gattn=-0.019803956151008606, Dattn=0.016770195215940475, Aattn=0.16222859919071198\n",
      "Epoch = 486, ErrG = 2.384068250656128, ErrA = 0.18975570984184742, ErrD = 0.05297025913993517, Gattn=-0.019823500886559486, Dattn=0.01678803376853466, Aattn=0.16251733899116516\n",
      "Epoch = 488, ErrG = 3.090442657470703, ErrA = 0.24416342626015344, ErrD = 0.06359854961435, Gattn=-0.019877303391695023, Dattn=0.016716131940484047, Aattn=0.16287803649902344\n",
      "Epoch = 490, ErrG = 2.9111557006835938, ErrA = 0.1555295983950297, ErrD = 0.025785254935423534, Gattn=-0.01991935260593891, Dattn=0.016715601086616516, Aattn=0.16335536539554596\n",
      "Epoch = 492, ErrG = 2.4213607907295227, ErrA = 0.1533020536104838, ErrD = 0.06401854505141576, Gattn=-0.019960127770900726, Dattn=0.01673026941716671, Aattn=0.16344209015369415\n",
      "Epoch = 494, ErrG = 2.220160484313965, ErrA = 0.27426234632730484, ErrD = 0.12797214835882187, Gattn=-0.02000420168042183, Dattn=0.016758056357502937, Aattn=0.16389226913452148\n",
      "Epoch = 496, ErrG = 1.9407318830490112, ErrA = 0.1485858162244161, ErrD = 0.05113051335016886, Gattn=-0.020043935626745224, Dattn=0.01667352207005024, Aattn=0.16434736549854279\n",
      "Epoch = 498, ErrG = 1.640555500984192, ErrA = 0.14726870507001877, ErrD = 0.34854046006997425, Gattn=-0.020075878128409386, Dattn=0.0166372861713171, Aattn=0.1646869033575058\n",
      "Epoch = 500, ErrG = 2.3107354044914246, ErrA = 0.21469277143478394, ErrD = 0.1274883101383845, Gattn=-0.020132897421717644, Dattn=0.01669047772884369, Aattn=0.164581298828125\n",
      "Epoch = 502, ErrG = 3.1641703844070435, ErrA = 0.16073394504686198, ErrD = 0.09064971034725507, Gattn=-0.02017485722899437, Dattn=0.01656286232173443, Aattn=0.16460779309272766\n",
      "Epoch = 504, ErrG = 3.043241500854492, ErrA = 0.13662519368032613, ErrD = 0.20161886513233185, Gattn=-0.020225347951054573, Dattn=0.016519151628017426, Aattn=0.16496598720550537\n",
      "Epoch = 506, ErrG = 2.517410635948181, ErrA = 0.1193239837884903, ErrD = 0.027838968361417454, Gattn=-0.020244652405381203, Dattn=0.016526812687516212, Aattn=0.16495288908481598\n",
      "Epoch = 508, ErrG = 2.4189988374710083, ErrA = 0.11892651269833247, ErrD = 0.15294766426086426, Gattn=-0.020301243290305138, Dattn=0.016549544408917427, Aattn=0.16496659815311432\n",
      "Epoch = 510, ErrG = 2.2408385276794434, ErrA = 0.1587598646680514, ErrD = 0.07711210536460082, Gattn=-0.020351525396108627, Dattn=0.01644947938621044, Aattn=0.16541892290115356\n",
      "Epoch = 512, ErrG = 2.6935726404190063, ErrA = 0.26007623473803204, ErrD = 0.1120181530714035, Gattn=-0.020412251353263855, Dattn=0.01645812578499317, Aattn=0.1656608283519745\n",
      "Epoch = 514, ErrG = 2.8797390460968018, ErrA = 0.1406441070139408, ErrD = 0.13990268607934317, Gattn=-0.020429102703928947, Dattn=0.01644713059067726, Aattn=0.16608545184135437\n",
      "Epoch = 516, ErrG = 2.326095700263977, ErrA = 0.13187002887328467, ErrD = 0.042914762472112976, Gattn=-0.0204805675894022, Dattn=0.01635550521314144, Aattn=0.16656872630119324\n",
      "Epoch = 518, ErrG = 2.449114501476288, ErrA = 0.1666634033123652, ErrD = 0.03702334314584732, Gattn=-0.020517993718385696, Dattn=0.016312794759869576, Aattn=0.16676226258277893\n",
      "Epoch = 520, ErrG = 2.1960291862487793, ErrA = 0.19240283283094564, ErrD = 0.08613582452138265, Gattn=-0.02055882103741169, Dattn=0.016323896124958992, Aattn=0.16677142679691315\n",
      "Epoch = 522, ErrG = 1.7504672408103943, ErrA = 0.2240377360333999, ErrD = 0.08836277201771736, Gattn=-0.020640885457396507, Dattn=0.016311073675751686, Aattn=0.1672617644071579\n",
      "Epoch = 524, ErrG = 2.305437684059143, ErrA = 0.20849264164765677, ErrD = 0.14114087261259556, Gattn=-0.02067175693809986, Dattn=0.016232676804065704, Aattn=0.16775593161582947\n",
      "Epoch = 526, ErrG = 2.9802733659744263, ErrA = 0.15279272136588892, ErrD = 0.07730993752678235, Gattn=-0.0207243412733078, Dattn=0.016292361542582512, Aattn=0.1678779572248459\n",
      "Epoch = 528, ErrG = 2.0819522738456726, ErrA = 0.2851831987500191, ErrD = 0.18086710385978222, Gattn=-0.020767614245414734, Dattn=0.01627625711262226, Aattn=0.16839222609996796\n",
      "Epoch = 530, ErrG = 2.6492992639541626, ErrA = 0.10087320332725842, ErrD = 0.11571358268459637, Gattn=-0.020792249590158463, Dattn=0.01628737524151802, Aattn=0.16839711368083954\n",
      "Epoch = 532, ErrG = 1.8406533598899841, ErrA = 0.16390163699785867, ErrD = 0.17656412223974863, Gattn=-0.0208500437438488, Dattn=0.016266915947198868, Aattn=0.1686260849237442\n",
      "Epoch = 534, ErrG = 3.3126583099365234, ErrA = 0.14846614003181458, ErrD = 0.04897451400756836, Gattn=-0.020899230614304543, Dattn=0.01622837409377098, Aattn=0.16894471645355225\n",
      "Epoch = 536, ErrG = 1.953449308872223, ErrA = 0.19409223397572836, ErrD = 0.1566312611103058, Gattn=-0.02095363475382328, Dattn=0.01617203652858734, Aattn=0.1693345010280609\n",
      "Epoch = 538, ErrG = 2.5487077236175537, ErrA = 0.24095629590253034, ErrD = 0.0718034307161967, Gattn=-0.021004408597946167, Dattn=0.016117578372359276, Aattn=0.16977135837078094\n",
      "Epoch = 540, ErrG = 1.645449936389923, ErrA = 0.19233633453647295, ErrD = 0.08039978394905727, Gattn=-0.021044710651040077, Dattn=0.016142958775162697, Aattn=0.17015554010868073\n",
      "Epoch = 542, ErrG = 2.9478567838668823, ErrA = 0.06895598707099755, ErrD = 0.10318504025538762, Gattn=-0.021080587059259415, Dattn=0.015967445448040962, Aattn=0.17043434083461761\n",
      "Epoch = 544, ErrG = 2.0630261301994324, ErrA = 0.2010529711842537, ErrD = 0.06918290133277576, Gattn=-0.021133670583367348, Dattn=0.01610713265836239, Aattn=0.17070941627025604\n",
      "Epoch = 546, ErrG = 2.313456654548645, ErrA = 0.1066869677354892, ErrD = 0.06719555022815864, Gattn=-0.021151598542928696, Dattn=0.016116933897137642, Aattn=0.17103171348571777\n",
      "Epoch = 548, ErrG = 2.2294801473617554, ErrA = 0.09270875714719296, ErrD = 0.10982064406077068, Gattn=-0.02122049406170845, Dattn=0.016090301796793938, Aattn=0.17102350294589996\n",
      "Epoch = 550, ErrG = 2.5907633304595947, ErrA = 0.2067567159732183, ErrD = 0.12069628636042277, Gattn=-0.021236063912510872, Dattn=0.01605795882642269, Aattn=0.17165245115756989\n",
      "Epoch = 552, ErrG = 1.781039834022522, ErrA = 0.1509850745399793, ErrD = 0.07560873900850613, Gattn=-0.021305115893483162, Dattn=0.01603231206536293, Aattn=0.17187094688415527\n",
      "Epoch = 554, ErrG = 2.633515477180481, ErrA = 0.1030818944176038, ErrD = 0.028858575969934464, Gattn=-0.021346595138311386, Dattn=0.016002150252461433, Aattn=0.17193087935447693\n",
      "Epoch = 556, ErrG = 1.6275794506072998, ErrA = 0.2355877123773098, ErrD = 0.15734353599449, Gattn=-0.021417582407593727, Dattn=0.015913888812065125, Aattn=0.17218397557735443\n",
      "Epoch = 558, ErrG = 3.168055772781372, ErrA = 0.17047377675771713, ErrD = 0.2379798206190268, Gattn=-0.021453091874718666, Dattn=0.015953781083226204, Aattn=0.17238810658454895\n",
      "Epoch = 560, ErrG = 1.5002872347831726, ErrA = 0.21525250375270844, ErrD = 0.13810500875115395, Gattn=-0.021494034677743912, Dattn=0.015885362401604652, Aattn=0.1728002429008484\n",
      "Epoch = 562, ErrG = 2.5425772070884705, ErrA = 0.1470357986787955, ErrD = 0.015591543167829514, Gattn=-0.021542692556977272, Dattn=0.015873661264777184, Aattn=0.1731312870979309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 564, ErrG = 2.9840166568756104, ErrA = 0.23537293883661428, ErrD = 0.030452149609724682, Gattn=-0.02156555838882923, Dattn=0.01581835374236107, Aattn=0.1732722818851471\n",
      "Epoch = 566, ErrG = 2.473421812057495, ErrA = 0.1275919501980146, ErrD = 0.04912359640002251, Gattn=-0.02162042260169983, Dattn=0.01576497219502926, Aattn=0.1735120564699173\n",
      "Epoch = 568, ErrG = 3.299262523651123, ErrA = 0.20995665589968363, ErrD = 0.039668520291646324, Gattn=-0.021638594567775726, Dattn=0.015688465908169746, Aattn=0.17374356091022491\n",
      "Epoch = 570, ErrG = 2.7525181770324707, ErrA = 0.17016186813513437, ErrD = 0.03715775596598784, Gattn=-0.021681267768144608, Dattn=0.015672758221626282, Aattn=0.17396995425224304\n",
      "Epoch = 572, ErrG = 2.8531715869903564, ErrA = 0.25313299149274826, ErrD = 0.05841648702820142, Gattn=-0.021715225651860237, Dattn=0.015561922453343868, Aattn=0.17432363331317902\n",
      "Epoch = 574, ErrG = 2.450057864189148, ErrA = 0.07816040515899658, ErrD = 0.07907374699910481, Gattn=-0.021795181557536125, Dattn=0.015577335841953754, Aattn=0.17446856200695038\n",
      "Epoch = 576, ErrG = 2.8663718700408936, ErrA = 0.1617142508427302, ErrD = 0.017791593447327614, Gattn=-0.02181478589773178, Dattn=0.015595318749547005, Aattn=0.1746373027563095\n",
      "Epoch = 578, ErrG = 2.2915322184562683, ErrA = 0.12495341897010803, ErrD = 0.08091335060695808, Gattn=-0.02186429873108864, Dattn=0.015536981634795666, Aattn=0.17498086392879486\n",
      "Epoch = 580, ErrG = 2.7744003534317017, ErrA = 0.13536009564995766, ErrD = 0.009310547883311907, Gattn=-0.021923014894127846, Dattn=0.015510868281126022, Aattn=0.17531301081180573\n",
      "Epoch = 582, ErrG = 3.0600656867027283, ErrA = 0.12041983008384705, ErrD = 0.06775170564651489, Gattn=-0.021954774856567383, Dattn=0.015392146073281765, Aattn=0.17557696998119354\n",
      "Epoch = 584, ErrG = 1.1912477016448975, ErrA = 0.15512156238158545, ErrD = 0.4678671968479951, Gattn=-0.02200206182897091, Dattn=0.015440590679645538, Aattn=0.17587575316429138\n",
      "Epoch = 586, ErrG = 2.4733359813690186, ErrA = 0.13732416927814484, ErrD = 0.1224524254600207, Gattn=-0.02205801196396351, Dattn=0.015418664552271366, Aattn=0.17606745660305023\n",
      "Epoch = 588, ErrG = 2.575588822364807, ErrA = 0.04097691426674525, ErrD = 0.041651032865047455, Gattn=-0.0220925472676754, Dattn=0.015327073633670807, Aattn=0.1763114482164383\n",
      "Epoch = 590, ErrG = 2.1923950910568237, ErrA = 0.17220083003242811, ErrD = 0.32313972401122254, Gattn=-0.02215912751853466, Dattn=0.015362785197794437, Aattn=0.1765761375427246\n",
      "Epoch = 592, ErrG = 2.8172130584716797, ErrA = 0.1669405090312163, ErrD = 0.2583230137825012, Gattn=-0.02219724841415882, Dattn=0.015290053561329842, Aattn=0.17675898969173431\n",
      "Epoch = 594, ErrG = 1.934712827205658, ErrA = 0.1900447110335032, ErrD = 0.27006057898203534, Gattn=-0.022234320640563965, Dattn=0.0152165861800313, Aattn=0.1770062893629074\n",
      "Epoch = 596, ErrG = 2.1109127402305603, ErrA = 0.11306645721197128, ErrD = 0.1098051971445481, Gattn=-0.02227645367383957, Dattn=0.015202597714960575, Aattn=0.17734073102474213\n",
      "Epoch = 598, ErrG = 2.1357077956199646, ErrA = 0.19855865091085434, ErrD = 0.02712438814342022, Gattn=-0.02234526164829731, Dattn=0.015193931758403778, Aattn=0.17748169600963593\n",
      "Epoch = 600, ErrG = 2.5414671897888184, ErrA = 0.17433172464370728, ErrD = 0.07867102324962616, Gattn=-0.022377265617251396, Dattn=0.015143956989049911, Aattn=0.17774562537670135\n",
      "Epoch = 602, ErrG = 2.403267025947571, ErrA = 0.06666971991459529, ErrD = 0.08031955361366272, Gattn=-0.02242078073322773, Dattn=0.015216442756354809, Aattn=0.1777997761964798\n",
      "Epoch = 604, ErrG = 2.8658881187438965, ErrA = 0.1672071429590384, ErrD = 0.018554003909230232, Gattn=-0.02246333658695221, Dattn=0.01515888050198555, Aattn=0.1781662255525589\n",
      "Epoch = 606, ErrG = 1.8065120577812195, ErrA = 0.10771413085361321, ErrD = 0.1008668194214503, Gattn=-0.0225230660289526, Dattn=0.01519456971436739, Aattn=0.17833903431892395\n",
      "Epoch = 608, ErrG = 2.038807988166809, ErrA = 0.13735739886760712, ErrD = 0.03537734349568685, Gattn=-0.022539930418133736, Dattn=0.015112042427062988, Aattn=0.17874500155448914\n",
      "Epoch = 610, ErrG = 2.6104865074157715, ErrA = 0.10645422836144765, ErrD = 0.09397141138712566, Gattn=-0.02260756865143776, Dattn=0.015082752332091331, Aattn=0.1791059672832489\n",
      "Epoch = 612, ErrG = 2.2924602031707764, ErrA = 0.22266408801078796, ErrD = 0.05384655793507894, Gattn=-0.022639980539679527, Dattn=0.015049463137984276, Aattn=0.17945997416973114\n",
      "Epoch = 614, ErrG = 2.300854802131653, ErrA = 0.15098968148231506, ErrD = 0.01732419120768706, Gattn=-0.022656438872218132, Dattn=0.015110444277524948, Aattn=0.17979680001735687\n",
      "Epoch = 616, ErrG = 2.289306640625, ErrA = 0.12540947397549948, ErrD = 0.023999690388639767, Gattn=-0.02268531732261181, Dattn=0.015061001293361187, Aattn=0.1800154447555542\n",
      "Epoch = 618, ErrG = 4.260157465934753, ErrA = 0.1382063813507557, ErrD = 0.22946309857070446, Gattn=-0.02274182438850403, Dattn=0.015077689662575722, Aattn=0.1803569346666336\n",
      "Epoch = 620, ErrG = 3.1619937419891357, ErrA = 0.18427915622790655, ErrD = 0.0915611982345581, Gattn=-0.02276778779923916, Dattn=0.015027249231934547, Aattn=0.18060792982578278\n",
      "Epoch = 622, ErrG = 3.4989104866981506, ErrA = 0.1520340840021769, ErrD = 0.17088993390401205, Gattn=-0.02282816357910633, Dattn=0.01492201816290617, Aattn=0.18055668473243713\n",
      "Epoch = 624, ErrG = 1.6712876558303833, ErrA = 0.19859972099463144, ErrD = 0.21337709948420525, Gattn=-0.022880395874381065, Dattn=0.014949186705052853, Aattn=0.1810288429260254\n",
      "Epoch = 626, ErrG = 3.500941812992096, ErrA = 0.14922628303368887, ErrD = 0.24250789483388266, Gattn=-0.022893767803907394, Dattn=0.014811476692557335, Aattn=0.18123073875904083\n",
      "Epoch = 628, ErrG = 1.5508247017860413, ErrA = 0.12671258486807346, ErrD = 0.12914328773816428, Gattn=-0.022949853911995888, Dattn=0.014874635264277458, Aattn=0.1815500557422638\n",
      "Epoch = 630, ErrG = 3.053354859352112, ErrA = 0.057254351675510406, ErrD = 0.05878249245385329, Gattn=-0.022972995415329933, Dattn=0.014776165597140789, Aattn=0.18178442120552063\n",
      "Epoch = 632, ErrG = 2.6403263807296753, ErrA = 0.12274341285228729, ErrD = 0.06803776572148006, Gattn=-0.02301662601530552, Dattn=0.01475592516362667, Aattn=0.18230906128883362\n",
      "Epoch = 634, ErrG = 1.8819419145584106, ErrA = 0.182242039591074, ErrD = 0.029082871973514557, Gattn=-0.02304999716579914, Dattn=0.01472688652575016, Aattn=0.18239726126194\n",
      "Epoch = 636, ErrG = 2.775229573249817, ErrA = 0.1367396761973699, ErrD = 0.06020602583885193, Gattn=-0.02310623973608017, Dattn=0.014637445099651814, Aattn=0.1828709840774536\n",
      "Epoch = 638, ErrG = 2.3633223176002502, ErrA = 0.09968853121002515, ErrD = 0.05858970060944557, Gattn=-0.023134833201766014, Dattn=0.014625652693212032, Aattn=0.18320240080356598\n",
      "Epoch = 640, ErrG = 3.4517730474472046, ErrA = 0.07029527301589648, ErrD = 0.05184558344384035, Gattn=-0.023194311186671257, Dattn=0.014582408592104912, Aattn=0.18350088596343994\n",
      "Epoch = 642, ErrG = 1.4882547855377197, ErrA = 0.10598133069773515, ErrD = 0.23729245364665985, Gattn=-0.023224521428346634, Dattn=0.014635924249887466, Aattn=0.18358741700649261\n",
      "Epoch = 644, ErrG = 2.0077064037323, ErrA = 0.10629516839981079, ErrD = 0.20319212476412454, Gattn=-0.02328522503376007, Dattn=0.014627325348556042, Aattn=0.18395842611789703\n",
      "Epoch = 646, ErrG = 2.7161961793899536, ErrA = 0.15323696533838907, ErrD = 0.08645868301391602, Gattn=-0.02332448773086071, Dattn=0.014480997808277607, Aattn=0.1840820461511612\n",
      "Epoch = 648, ErrG = 3.123834252357483, ErrA = 0.12835891296466193, ErrD = 0.0942606230576833, Gattn=-0.023342831060290337, Dattn=0.01439816877245903, Aattn=0.18421584367752075\n",
      "Epoch = 650, ErrG = 2.6358799934387207, ErrA = 0.08749352395534515, ErrD = 0.05607865254084269, Gattn=-0.023374466225504875, Dattn=0.014410256408154964, Aattn=0.18439240753650665\n",
      "Epoch = 652, ErrG = 2.423340320587158, ErrA = 0.21997223297754923, ErrD = 0.1730047290523847, Gattn=-0.023440593853592873, Dattn=0.014318554662168026, Aattn=0.18491481244564056\n",
      "Epoch = 654, ErrG = 2.862180471420288, ErrA = 0.15677551925182343, ErrD = 0.020783916115760803, Gattn=-0.023514272645115852, Dattn=0.014269445091485977, Aattn=0.18512234091758728\n",
      "Epoch = 656, ErrG = 3.439285635948181, ErrA = 0.1048032424102227, ErrD = 0.05683941642443339, Gattn=-0.023574890568852425, Dattn=0.01436123251914978, Aattn=0.18547187745571136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 658, ErrG = 3.0978980660438538, ErrA = 0.1924865779777368, ErrD = 0.06667035321394603, Gattn=-0.023618437349796295, Dattn=0.01440544705837965, Aattn=0.18596096336841583\n",
      "Epoch = 660, ErrG = 2.274911880493164, ErrA = 0.05331048804024855, ErrD = 0.06769030727446079, Gattn=-0.023651763796806335, Dattn=0.014346727170050144, Aattn=0.18619690835475922\n",
      "Epoch = 662, ErrG = 2.2050634622573853, ErrA = 0.1165768491725127, ErrD = 0.08983064691225688, Gattn=-0.023709945380687714, Dattn=0.014274507761001587, Aattn=0.18638008832931519\n",
      "Epoch = 664, ErrG = 2.3505425453186035, ErrA = 0.15459846208492914, ErrD = 0.013870025674502054, Gattn=-0.0237516388297081, Dattn=0.014064074493944645, Aattn=0.1867741197347641\n",
      "Epoch = 666, ErrG = 2.161745846271515, ErrA = 0.20249265929063162, ErrD = 0.04775057236353556, Gattn=-0.02379130944609642, Dattn=0.01412009634077549, Aattn=0.18691669404506683\n",
      "Epoch = 668, ErrG = 3.1226245164871216, ErrA = 0.1581517687688271, ErrD = 0.06907273332277934, Gattn=-0.02381758950650692, Dattn=0.014125156216323376, Aattn=0.18717554211616516\n",
      "Epoch = 670, ErrG = 2.5530534982681274, ErrA = 0.13167441387971243, ErrD = 0.03226768535872301, Gattn=-0.02385144680738449, Dattn=0.014050677418708801, Aattn=0.18758171796798706\n",
      "Epoch = 672, ErrG = 3.2997002601623535, ErrA = 0.17135695616404215, ErrD = 0.03641535776356856, Gattn=-0.023902196437120438, Dattn=0.0140157425776124, Aattn=0.1879434585571289\n",
      "Epoch = 674, ErrG = 3.2619292736053467, ErrA = 0.12168964371085167, ErrD = 0.1639533738295237, Gattn=-0.023967858403921127, Dattn=0.013947868719696999, Aattn=0.1880032867193222\n",
      "Epoch = 676, ErrG = 2.231270432472229, ErrA = 0.1622741644581159, ErrD = 0.07181637485822041, Gattn=-0.024008022621273994, Dattn=0.01396334357559681, Aattn=0.18835914134979248\n",
      "Epoch = 678, ErrG = 2.0367623567581177, ErrA = 0.14129704361160597, ErrD = 0.17474888265132904, Gattn=-0.024084046483039856, Dattn=0.013961803168058395, Aattn=0.18840540945529938\n",
      "Epoch = 680, ErrG = 2.325122594833374, ErrA = 0.0983757022768259, ErrD = 0.1593718628088633, Gattn=-0.02410435490310192, Dattn=0.013855206780135632, Aattn=0.18877483904361725\n",
      "Epoch = 682, ErrG = 2.6448835134506226, ErrA = 0.08526734262704849, ErrD = 0.036377292747298874, Gattn=-0.024155260995030403, Dattn=0.013925089500844479, Aattn=0.18911583721637726\n",
      "Epoch = 684, ErrG = 2.3857659697532654, ErrA = 0.12212927639484406, ErrD = 0.12835086012880007, Gattn=-0.024194104596972466, Dattn=0.013871056959033012, Aattn=0.18938788771629333\n",
      "Epoch = 686, ErrG = 3.132717549800873, ErrA = 0.07298841575781505, ErrD = 0.02258615754544735, Gattn=-0.024211108684539795, Dattn=0.013885990716516972, Aattn=0.189752995967865\n",
      "Epoch = 688, ErrG = 2.3992451429367065, ErrA = 0.099838025867939, ErrD = 0.041265307615200676, Gattn=-0.024264076724648476, Dattn=0.013894504867494106, Aattn=0.18979470431804657\n",
      "Epoch = 690, ErrG = 2.2293639183044434, ErrA = 0.13550707263251147, ErrD = 0.18835943937301636, Gattn=-0.024318169802427292, Dattn=0.013918970711529255, Aattn=0.1899223029613495\n",
      "Epoch = 692, ErrG = 2.9177111983299255, ErrA = 0.08938074856996536, ErrD = 0.11100250172118346, Gattn=-0.024361351504921913, Dattn=0.013787527568638325, Aattn=0.1905021071434021\n",
      "Epoch = 694, ErrG = 2.257061243057251, ErrA = 0.06467362244923909, ErrD = 0.2563348064819972, Gattn=-0.02439461462199688, Dattn=0.013793202117085457, Aattn=0.1907327026128769\n",
      "Epoch = 696, ErrG = 2.7506611347198486, ErrA = 0.04692762034634749, ErrD = 0.02502676161626975, Gattn=-0.024418119341135025, Dattn=0.013769281096756458, Aattn=0.1910109668970108\n",
      "Epoch = 698, ErrG = 2.9330440759658813, ErrA = 0.17438953866561255, ErrD = 0.05294388408462206, Gattn=-0.02448924072086811, Dattn=0.013758398592472076, Aattn=0.19100743532180786\n",
      "Epoch = 700, ErrG = 2.760422110557556, ErrA = 0.14944145580132803, ErrD = 0.09751899540424347, Gattn=-0.02454209513962269, Dattn=0.013703390955924988, Aattn=0.19116529822349548\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "\n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 0\n",
    "n_g = 2\n",
    "n_d = 1\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            d_out_assreal,dr1 = netd(ass_label)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_assreal\n",
    "            lossD += d_loss_assreal.item()\n",
    "\n",
    "            d_out_noassreal,dr2 = netd(noass_label)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_noassreal\n",
    "            lossD += d_loss_noassreal.item()\n",
    "\n",
    "            fake, gf1 = netg(img)\n",
    "            d_out_fake, df1 = netd(fake.detach())  #需要 detach 因為不希望更新fake的參數\n",
    "            d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "            lossD_ += d_loss_fake\n",
    "            lossD += d_loss_fake.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "            lossD_ = lossD_/3\n",
    "            lossD_.backward()\n",
    "            optimD.step()\n",
    "\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked, gf1 = netg(img)\n",
    "            faked = th.cat((img, faked.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "            d_out_assreal,dr1 = neta(assd)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "            lossA += d_loss_assreal.item()\n",
    "            lossA_ += d_loss_assreal\n",
    "\n",
    "            d_out_noassreal,dr2 = neta(noassd)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "            lossA_ += d_loss_noassreal\n",
    "            lossA += d_loss_noassreal.item()\n",
    "\n",
    "            d_out_faked, df3 = neta(faked)\n",
    "            d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "            lossA_ += d_loss_faked\n",
    "            lossA += d_loss_faked.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "\n",
    "            \n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake,_= netg(img)\n",
    "            g_out_fake,_ = netd(fake)\n",
    "            g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "            lossG += g_loss_fake.item()\n",
    "            lossG_ += g_loss_fake\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            g_out_faked,_ = neta(faked)\n",
    "            g_loss_faked = - g_out_faked.mean()\n",
    "            lossG += g_loss_faked.item()\n",
    "            lossG_ += g_loss_faked\n",
    "\n",
    "            lossG_ = lossG_/2\n",
    "            lossG_.backward(retain_graph=True) ##其實這裡也不需要retain graph 因為他只 backward 一次；\n",
    "            #如果爾後有要再backward，第一次就需要retain graph\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN (WGAN-GP) 刪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T00:07:22.217162Z",
     "start_time": "2019-06-05T16:58:50.881140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "# lr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 0\n",
    "target = '090'\n",
    "lambda_gp = 10\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, dlr, glr, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        \n",
    "        \n",
    "        # update D\n",
    "        lossD = 0\n",
    "        lossD_ = 0\n",
    "        optimD.zero_grad()\n",
    "        d_out_assreal,dr1 = netd(ass_label)\n",
    "        d_loss_assreal = -th.mean(d_out_assreal)\n",
    "\n",
    "        lossD_ += d_loss_assreal\n",
    "        lossD += d_loss_assreal.item()\n",
    "\n",
    "        d_out_noassreal,dr2 = netd(noass_label)\n",
    "        d_loss_noassreal = -th.mean(d_out_noassreal)\n",
    "\n",
    "        lossD_ += d_loss_noassreal\n",
    "        lossD += d_loss_noassreal.item()\n",
    "\n",
    "        fake, gf1 = netg(img)\n",
    "        d_out_fake, df1 = netd(fake.detach())  #需要 detach 因為不希望更新fake的參數\n",
    "        d_loss_fake = th.mean(d_out_fake)\n",
    "\n",
    "        lossD_ += d_loss_fake\n",
    "        lossD += d_loss_fake.item()\n",
    "        gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "        lossD_ = lossD_/3 + lambda_gp * gradient_penalty\n",
    "#         lossD_ = lossD_/3\n",
    "        lossD_.backward()\n",
    "        optimD.step()\n",
    "        \n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        lossA_ = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked, gf1 = netg(img)\n",
    "        faked = th.cat((img, faked.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "        d_out_assreal,dr1 = neta(assd)\n",
    "        d_loss_assreal = -th.mean(d_out_assreal)\n",
    "        lossA += d_loss_assreal.item()\n",
    "        lossA_ += d_loss_assreal\n",
    "\n",
    "        d_out_noassreal,dr2 = neta(noassd)\n",
    "        d_loss_noassreal = th.mean(d_out_noassreal)\n",
    "\n",
    "        lossA_ += d_loss_noassreal\n",
    "        lossA += d_loss_noassreal.item()\n",
    "        \n",
    "        d_out_faked, df3 = neta(faked)\n",
    "        d_loss_faked = th.mean(d_out_faked)\n",
    "\n",
    "        lossA_ += d_loss_faked\n",
    "        lossA += d_loss_faked.item()\n",
    "        gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "        lossA_ = lossA_/3 + lambda_gp * gradient_penalty\n",
    "#         lossA_ = lossA_/3\n",
    "        lossA_.backward()\n",
    "        optimA.step()\n",
    "\n",
    "            \n",
    "        # update G\n",
    "#         if i % n_critic == 0:\n",
    "        lossG = 0\n",
    "        lossG_ = 0\n",
    "        optimG.zero_grad()\n",
    "        fake,_= netg(img)\n",
    "        g_out_fake,_ = netd(fake)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "        lossG += g_loss_fake.item()\n",
    "        lossG_ += g_loss_fake\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        g_out_faked,_ = neta(faked)\n",
    "        g_loss_faked = - g_out_faked.mean()\n",
    "        lossG += g_loss_faked.item()\n",
    "        lossG_ += g_loss_faked\n",
    "        \n",
    "        lossG_ = lossG_/2\n",
    "        lossG_.backward(retain_graph=True) ##其實這裡也不需要retain graph 因為他只 backward 一次；\n",
    "        #如果爾後有要再backward，第一次就需要retain graph\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN and triplet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-06T11:04:01.107626Z",
     "start_time": "2019-07-06T04:16:43.132497Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 10\n",
    "n_g = 2\n",
    "n_d = 0\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "\n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            d_out_assreal,dr1 = netd(ass_label)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_assreal\n",
    "            lossD += d_loss_assreal.item()\n",
    "\n",
    "            d_out_noassreal,dr2 = netd(noass_label)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_noassreal\n",
    "            lossD += d_loss_noassreal.item()\n",
    "\n",
    "            fake, code = netg(img)\n",
    "            d_out_fake, df1 = netd(fake.detach())\n",
    "            d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "            lossD_ += d_loss_fake\n",
    "            lossD += d_loss_fake.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "            lossD_ = lossD_/3\n",
    "            lossD_.backward()\n",
    "            optimD.step()\n",
    "\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked, code = netg(img)\n",
    "            faked = th.cat((img, faked.detach()), 1)\n",
    "\n",
    "            d_out_assreal,dr1 = neta(assd)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "            lossA += d_loss_assreal.item()\n",
    "            lossA_ += d_loss_assreal\n",
    "\n",
    "            d_out_noassreal,dr2 = neta(noassd)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "            lossA_ += d_loss_noassreal\n",
    "            lossA += d_loss_noassreal.item()\n",
    "\n",
    "            d_out_faked, df3 = neta(faked)\n",
    "            d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "            lossA_ += d_loss_faked\n",
    "            lossA += d_loss_faked.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "\n",
    "            \n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake, A= netg(img)\n",
    "            g_out_fake,_ = netd(fake)\n",
    "            g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "            lossG += g_loss_fake.item()\n",
    "            lossG_ += g_loss_fake\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            g_out_faked,_ = neta(faked)\n",
    "            g_loss_faked = - g_out_faked.mean()\n",
    "            lossG += g_loss_faked.item()\n",
    "            lossG_ += g_loss_faked\n",
    "\n",
    "            # constrain on generator\n",
    "            fake_ass, P = netg(ass_img)\n",
    "            fake_noass, N = netg(noass_img)\n",
    "            lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "            lossG_ += lossTriplet\n",
    "            lossG += lossTriplet.item()\n",
    "    #         lossTriplet.backward()\n",
    "\n",
    "            lossG_ = lossG_/3\n",
    "            lossG_.backward(retain_graph=True)\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrTri = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/3,lossTriplet.item(), lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/3)<low_loss:  \n",
    "        low_loss = lossG/3\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN and triplet (onlineloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T00:29:55.922173Z",
     "start_time": "2019-07-06T16:40:51.825605Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 10\n",
    "n_g = 2\n",
    "n_d = 0\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img, label_neg, label_anc, label_pos) in enumerate(train_loader):\n",
    "        \n",
    "        com_img = th.cat((noass_img, img, ass_img), 0)\n",
    "        com_label = th.cat(( label_neg, label_anc, label_pos), 0)\n",
    "        com_img = com_img.to(device).to(th.float32)\n",
    "        com_label = com_label.to(device).to(th.float32)\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "\n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            d_out_assreal,dr1 = netd(ass_label)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_assreal\n",
    "            lossD += d_loss_assreal.item()\n",
    "\n",
    "            d_out_noassreal,dr2 = netd(noass_label)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_noassreal\n",
    "            lossD += d_loss_noassreal.item()\n",
    "\n",
    "            fake, code = netg(img)\n",
    "            d_out_fake, df1 = netd(fake.detach())\n",
    "            d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "            lossD_ += d_loss_fake\n",
    "            lossD += d_loss_fake.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "            lossD_ = lossD_/3\n",
    "            lossD_.backward()\n",
    "            optimD.step()\n",
    "\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked, code = netg(img)\n",
    "            faked = th.cat((img, faked.detach()), 1)\n",
    "\n",
    "            d_out_assreal,dr1 = neta(assd)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "            lossA += d_loss_assreal.item()\n",
    "            lossA_ += d_loss_assreal\n",
    "\n",
    "            d_out_noassreal,dr2 = neta(noassd)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "            lossA_ += d_loss_noassreal\n",
    "            lossA += d_loss_noassreal.item()\n",
    "\n",
    "            d_out_faked, df3 = neta(faked)\n",
    "            d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "            lossA_ += d_loss_faked\n",
    "            lossA += d_loss_faked.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "\n",
    "\n",
    "            \n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake, A= netg(img)\n",
    "            g_out_fake,_ = netd(fake)\n",
    "            g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "            lossG += g_loss_fake.item()\n",
    "            lossG_ += g_loss_fake\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            g_out_faked,_ = neta(faked)\n",
    "            g_loss_faked = - g_out_faked.mean()\n",
    "            lossG += g_loss_faked.item()\n",
    "            lossG_ += g_loss_faked\n",
    "\n",
    "    #         # constrain on encoder\n",
    "    #         fake_ass, P = netg(ass_img)\n",
    "    #         fake_noass, N = netg(noass_img)\n",
    "    #         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "    #         lossG_ += lossTriplet\n",
    "    #         lossG += lossTriplet.item()\n",
    "    # #         lossTriplet.backward()\n",
    "\n",
    "            ## new onlinetripletloss\n",
    "            __, com = netg(com_img)\n",
    "            loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "            lossTriplet,len_triplet = loss_fn(com, com_label)\n",
    "            lossG += lossTriplet.item()\n",
    "            lossG_ += lossTriplet\n",
    "    #         lossTriplet.backward()\n",
    "\n",
    "\n",
    "            lossG_ = lossG_/3\n",
    "            lossG_.backward(retain_graph=True)\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrTri = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/3,lossTriplet.item(), lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/3)<low_loss:  \n",
    "        low_loss = lossG/3\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_ting_cv]",
   "language": "python",
   "name": "conda-env-py36_ting_cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
