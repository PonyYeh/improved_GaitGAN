{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T06:36:38.280293Z",
     "start_time": "2019-08-14T06:36:37.027621Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from onlineTripletloss import *\n",
    "from selector import *\n",
    "from model_SAGAN1_1 import NetG, NetD, NetA\n",
    "# from model_SAGAN2_Triplet import NetG, NetD, NetA\n",
    "# from model_WGANGP import NetG, NetD, NetA\n",
    "# from model_WGAN import NetG, NetD, NetA\n",
    "# from model_siGAN import NetG, NetD, NetA\n",
    "# from dataset2Loader import CASIABDataset\n",
    "# from dataset2Loader_newtriplet import CASIABDataset\n",
    "from dataset2Loader_triplet import CASIABDataset\n",
    "import torch.optim as optim\n",
    "import visdom\n",
    "from torchvision.utils import make_grid\n",
    "# Data_Dir = '../GaitRecognition/DatasetB_GEI_64x64_allseq/'\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "Model_Name = 'Model_64x64_TripletSAGAN_90_trial11'\n",
    "Model_dir = './Transform_Model/'+ Model_Name\n",
    "if not os.path.isdir(Model_dir):\n",
    "    os.mkdir(Model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T11:51:23.878764Z",
     "start_time": "2019-05-17T11:51:22.490886Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "import os\n",
    "\n",
    "for r, d, files in os.walk(Data_Dir):\n",
    "    print(r)\n",
    "    print(len(d))\n",
    "    print(len(files))\n",
    "    \n",
    "# cpt = sum([len(files) for r, d, files in os.walk(Data_Dir)])\n",
    "# cpt = sum([len(d) for r, d, files in os.walk(Data_Dir)])\n",
    "# print(cpt)\n",
    "# list = os.listdir(Data_Dir) # dir is your directory path\n",
    "# number_files = len(list)\n",
    "# print(number_files)\n",
    "\n",
    "# import fnmatch\n",
    "# print(len(fnmatch.filter(os.listdir(Data_Dir), '*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T06:02:12.747164Z",
     "start_time": "2019-05-27T06:02:12.676816Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "ass_label, noass_label, img = dataset.getbatch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteration 刪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T08:08:38.785029Z",
     "start_time": "2019-06-16T08:08:38.768214Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(tensor, gain=1.)\n",
    "#         init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 128\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print('Training starts')\n",
    "while iteration < 30000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    # update D\n",
    "    lossD = 0\n",
    "    optimD.zero_grad()\n",
    "    output = netd(ass_label)\n",
    "    label.fill_(real_label)\n",
    "    lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "    lossD += lossD_real1.item()\n",
    "    lossD_real1.backward()\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output1 = netd(noass_label)\n",
    "    lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "    lossD += lossD_real2.item()\n",
    "    lossD_real2.backward()\n",
    "\n",
    "    fake = netg(img).detach()\n",
    "    label.fill_(fake_label)\n",
    "    output2 = netd(fake)\n",
    "    lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "    lossD += lossD_fake.item()\n",
    "    lossD_fake.backward()\n",
    "\n",
    "    optimD.step()\n",
    "    \n",
    "    # update A\n",
    "    lossA = 0\n",
    "    optimA.zero_grad()\n",
    "    assd = th.cat((img, ass_label), 1)\n",
    "    noassd = th.cat((img, noass_label), 1)\n",
    "    fake = netg(img).detach()\n",
    "    faked = th.cat((img, fake), 1)\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output1 = neta(assd)\n",
    "    lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "    lossA += lossA_real1.item()\n",
    "    lossA_real1.backward()\n",
    "\n",
    "    label.fill_(fake_label)\n",
    "    output = neta(noassd)\n",
    "    lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "    lossA += lossA_real2.item()\n",
    "    lossA_real2.backward()\n",
    "\n",
    "    label.fill_(fake_label)\n",
    "    output = neta(faked)\n",
    "    lossA_fake = F.binary_cross_entropy(output, label)\n",
    "    lossA += lossA_fake.item()\n",
    "    lossA_fake.backward()\n",
    "    \n",
    "    optimA.step()\n",
    "    \n",
    "    # update G\n",
    "    lossG = 0\n",
    "    optimG.zero_grad()\n",
    "    fake = netg(img)\n",
    "    output = netd(fake)\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    lossGD = F.binary_cross_entropy(output, label)\n",
    "    lossG += lossGD.item()\n",
    "    lossGD.backward(retain_graph=True)\n",
    "\n",
    "    faked = th.cat((img, fake), 1)\n",
    "    output = neta(faked)\n",
    "    label.fill_(real_label)\n",
    "    lossGA = F.binary_cross_entropy(output, label)\n",
    "    lossG += lossGA.item()\n",
    "    lossGA.backward()\n",
    "    \n",
    "    optimG.step()\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration % 20 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            fake = netg(img) 25\n",
    "            netg.train() #切換回去\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 20).cpu().numpy()\n",
    "        if win1 is None:\n",
    "            win1 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train'))\n",
    "        else:\n",
    "            vis.image(display, win=win1)\n",
    "    if iteration % 1000 == 0 or iteration==500:\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)\n",
    "\n",
    "    if iteration % 100==0 or iteration==10 :\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration, iteration,\n",
    "                                        iteration]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration,\n",
    "                                  iteration]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "            \n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            iteration, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('iter = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            iteration, lossG/2, lossA/3, lossD/3\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T05:25:59.661560Z",
     "start_time": "2019-05-27T05:25:59.620596Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=False)\n",
    "train_loader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T08:46:23.327475Z",
     "start_time": "2019-06-16T08:23:19.736325Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 0\n",
    "n_g = 0\n",
    "n_d = 0\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "print('Training starts')\n",
    "low_loss = 10\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "#         ass_img = ass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "#         noass_img = noass_img.to(device).to(th.float32)\n",
    "\n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            fake = netg(img).detach()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "\n",
    "        if i % n_d ==0: \n",
    "            # update G\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "            label.fill_(real_label)\n",
    "            lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:  \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "    \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update k times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:08:32.658055Z",
     "start_time": "2019-06-15T08:18:03.792818Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 0\n",
    "n_g = 2\n",
    "n_d = 0\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "#         noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "#         ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "        if i % n_d ==0: \n",
    "            # update G\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "            label.fill_(real_label)\n",
    "            lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model changed +Dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T09:39:59.973452Z",
     "start_time": "2019-06-17T01:57:16.530081Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netp = NetP(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netp.children())[0].children(),\n",
    "    list(neta.children())[0].children(),\n",
    "    list(netd.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netp = netp.to(device)\n",
    "neta = neta.to(device)\n",
    "netd = netd.to(device)\n",
    "netg.train()\n",
    "netp.train()\n",
    "neta.train()\n",
    "netd.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimP = optim.Adam(netp.parameters(), lr=lr/3)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, target = {} \\n'.format(\n",
    "            epoches, lr, batchSize, target))\n",
    "\n",
    "print('Training starts')\n",
    "low_loss = 10\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, ass_img, img, noass_img) in enumerate(train_loader): \n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        \n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "        label.fill_(real_label)\n",
    "        lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "        lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "        label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "        lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "\n",
    "\n",
    "        # update P\n",
    "        lossP = 0\n",
    "        optimP.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_img), 1)\n",
    "        noassd = th.cat((img, noass_img), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossP_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossP += lossP_real1.item()/2\n",
    "        lossP_real1 = lossP_real1/2\n",
    "        lossP_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossP_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossP += lossP_real2.item()/2\n",
    "        lossP_real2 = lossP_real2/2\n",
    "        lossP_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossP_fake = F.binary_cross_entropy(output, label)\n",
    "        lossP += lossP_fake.item()/2\n",
    "        lossP_fake = lossP_fake/2\n",
    "        lossP_fake.backward()\n",
    "\n",
    "        optimP.step()\n",
    "    \n",
    "\n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "\n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        \n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward(retain_graph=True)\n",
    "        \n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = netp(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGP = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGP.item()/2\n",
    "        lossGP = lossGP/2\n",
    "        lossGP.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch, epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3, lossP/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD', 'lossP']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch, epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3, lossP/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:  \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict(),\n",
    "            'netP': netp.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "    \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict(),\n",
    "            'netP': netp.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {}  \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model only D_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T05:21:59.261901Z",
     "start_time": "2019-06-23T02:19:01.856865Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "g_k = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "# netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "# optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, g_k = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, g_k, target))\n",
    "\n",
    "low_loss = 10\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "#         noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "#         ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % g_k ==0:\n",
    "#             # update D\n",
    "#             lossD = 0\n",
    "#             optimD.zero_grad()\n",
    "#             output = netd(ass_label)\n",
    "#             label.fill_(real_label)\n",
    "#             lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "#             lossD += lossD_real1.item()\n",
    "#             lossD_real1.backward()\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             output1 = netd(noass_label)\n",
    "#             lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "#             lossD += lossD_real2.item()\n",
    "#             lossD_real2.backward()\n",
    "\n",
    "#             fake = netg(img).detach()\n",
    "#             label.fill_(fake_label)\n",
    "#             output2 = netd(fake)\n",
    "#             lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "#             lossD += lossD_fake.item()\n",
    "#             lossD_fake.backward()\n",
    "\n",
    "#             optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "#         if i % k ==0: \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        ]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  ]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3,\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, \n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}\\n'.format(\n",
    "            epoch, lossG/2, lossA/3\n",
    "        ))    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaitGAN and triplet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T21:13:30.999315Z",
     "start_time": "2019-05-29T14:16:28.502269Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '036'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 5\n",
    "n_g = 0\n",
    "n_d = 0\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        if i % n_g==0:\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake, _ = netg(img)\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake.detach())\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake,_ = netg(img)\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked.detach())\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "        if i % n_d ==0: \n",
    "            # update G\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake, A = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "            label.fill_(real_label)\n",
    "            lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            # constrain on generator\n",
    "            fake_ass, P = netg(ass_label)\n",
    "            fake_noass, N = netg(noass_label)\n",
    "            lossTriplet = F.triplet_margin_loss(fake, fake_ass, fake_noass, margin = margin)\n",
    "            lossG += lossTriplet.item()\n",
    "            lossTriplet.backward()\n",
    "\n",
    "            # constrain on encoder\n",
    "    #         __, P = netg(ass_label)\n",
    "    #         __, N = netg(noass_label)\n",
    "    #         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "    #         lossG += lossTriplet.item()\n",
    "    #         lossTriplet.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaitGAN k times and triplet   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T17:27:36.724552Z",
     "start_time": "2019-06-18T06:30:54.000065Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 10\n",
    "n_g = 2\n",
    "n_d = 2\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr/3)\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         com_img = th.cat((noass_img, img, ass_img), 0)\n",
    "#         com_label = th.cat(( label_neg, label_anc, label_pos), 0)\n",
    "#         com_img = com_img.to(device).to(th.float32)\n",
    "#         com_label = com_label.to(device).to(th.float32)\n",
    "        \n",
    "#         if(i ==0):\n",
    "#             print(label_neg,label_anc,label_pos)\n",
    "#             print(com_label)\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape,com_img.shape, com_label.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        # update D\n",
    "        if i % n_g==0:\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake, _ = netg(img)\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake.detach()) #需要 detach 因為不希望更新fake的參數\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake,_ = netg(img)\n",
    "            faked = th.cat((img, fake.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "        if i % n_d ==0: \n",
    "            # update G\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake, A = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)  ##這裡需要retain graph 因為他之後有需要fake，因此需要retain\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "            label.fill_(real_label)\n",
    "            lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            ## new tripletloss\n",
    "            _, P = netg(ass_img)\n",
    "            __, N = netg(noass_img)\n",
    "            lossf = TripletLoss(margin) #因為之前的A都沒被使用過所以不會遺失，如果是拿fake ，LossGA就需要再retain graph\n",
    "            lossTriplet =lossf(A, P, N)\n",
    "            lossG += lossTriplet.item()\n",
    "            lossTriplet.backward()\n",
    "\n",
    "    #         ## new onlinetripletloss\n",
    "    #         __, com = netg(com_img)\n",
    "    #         loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "    #         lossTriplet,len_triplet = loss_fn(com, com_label)\n",
    "    #         lossG += lossTriplet.item()\n",
    "    #         lossTriplet.backward()\n",
    "    # #         print(lossTriplet.item(),len_triplet)\n",
    "\n",
    "    #         ## triplet loss\n",
    "    #         __, P = netg(ass_img)\n",
    "    #         __, N = netg(noass_img)\n",
    "    #         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin) #因為之前的A都沒被使用過所以不會遺失，如果是拿fake ，LossGA就需要再retain graph\n",
    "    #         lossG += lossTriplet.item()\n",
    "    #         lossTriplet.backward()\n",
    "    # #         if i%10==0:\n",
    "    # #             print(\"tripletloss \",lossTriplet.item())\n",
    "\n",
    "            ## tripletloss no negative\n",
    "    #         N_plus = th.zeros((A.size()), requires_grad=False).to(device)\n",
    "    #         lossTriplet_AP = F.triplet_margin_loss(A, P, N_plus, margin = margin)\n",
    "    #         lossG += lossTriplet_AP.item()\n",
    "    #         lossTriplet += lossTriplet_AP\n",
    "    #         lossTriplet.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG  Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from PixelDT code刪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:13:36.331308Z",
     "start_time": "2019-04-13T08:01:32.315792Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 128\n",
    "\n",
    "real_label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "fake_label = th.ones((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr)\n",
    "\n",
    "print('Training starts')\n",
    "while iteration < 40000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    # update D\n",
    "    lossD = 0\n",
    "    optimD.zero_grad()\n",
    "    output = netd(ass_label)\n",
    "#     label.fill_(real_label)\n",
    "    lossD_real1 = F.binary_cross_entropy(output, real_label)\n",
    "#     lossD += lossD_real1.item()\n",
    "#     lossD_real1.backward()\n",
    "\n",
    "#     label.fill_(real_label)\n",
    "    output1 = netd(noass_label)\n",
    "    lossD_real2 = F.binary_cross_entropy(output1, real_label)\n",
    "#     lossD += lossD_real2.item()\n",
    "#     lossD_real2.backward()\n",
    "\n",
    "    fake = netg(img).detach()\n",
    "#     label.fill_(fake_label)\n",
    "    output2 = netd(fake)\n",
    "    lossD_fake = F.binary_cross_entropy(output2, fake_label)\n",
    "#     lossD += lossD_fake.item()\n",
    "#     lossD_fake.backward()\n",
    "    lossD = (lossD_real1+ lossD_real2+ lossD_fake)/3\n",
    "    lossD.backward()\n",
    "\n",
    "    lossD_item = lossD.item()\n",
    "    optimD.step()\n",
    "    \n",
    "    # update A\n",
    "    lossA = 0\n",
    "    optimA.zero_grad()\n",
    "    assd = th.cat((img, ass_label), 1)\n",
    "    noassd = th.cat((img, noass_label), 1)\n",
    "    fake = netg(img).detach()\n",
    "    faked = th.cat((img, fake), 1)\n",
    "\n",
    "#     label.fill_(real_label)\n",
    "    output = neta(assd)\n",
    "    lossA_real1 = F.binary_cross_entropy(output, real_label)\n",
    "#     lossA += lossA_real1.item()\n",
    "#     lossA_real1.backward()\n",
    "\n",
    "#     label.fill_(fake_label)\n",
    "    output1 = neta(noassd)\n",
    "    lossA_real2 = F.binary_cross_entropy(output1, fake_label)\n",
    "#     lossA += lossA_real2.item()\n",
    "#     lossA_real2.backward()\n",
    "\n",
    "#     label.fill_(fake_label)\n",
    "    output2 = neta(faked)\n",
    "    lossA_fake = F.binary_cross_entropy(output2, fake_label)\n",
    "#     lossA += lossA_fake.item()\n",
    "#     lossA_fake.backward()\n",
    "    lossA = (lossA_real1+ lossA_real2 +lossA_fake)/3\n",
    "    lossA.backward()\n",
    "    \n",
    "    lossA_item = lossA.item()\n",
    "    optimA.step()\n",
    "    \n",
    "    # update G\n",
    "    lossG = 0\n",
    "    optimG.zero_grad()\n",
    "    fake = netg(img)\n",
    "    output = netd(fake)\n",
    "#     label.fill_(real_label)\n",
    "    lossGD = F.binary_cross_entropy(output, real_label)\n",
    "#     lossG += lossGD.item()\n",
    "#     lossGD.backward(retain_graph=True)\n",
    "\n",
    "    faked = th.cat((img, fake), 1)\n",
    "    output = neta(faked)\n",
    "#     label.fill_(real_label)\n",
    "    lossGA = F.binary_cross_entropy(output, real_label)\n",
    "#     lossG += lossGA.item()\n",
    "#     lossGA.backward()\n",
    "    lossG = (lossGD + lossGA)/2\n",
    "    lossG.backward()\n",
    "    \n",
    "    lossG_item = lossG.item()\n",
    "    optimG.step()\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration % 20 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            fake = netg(img) \n",
    "            netg.train() #切換回去\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 20).cpu().numpy()\n",
    "        if win1 is None:\n",
    "            win1 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train'))\n",
    "        else:\n",
    "            vis.image(display, win=win1)\n",
    "    if iteration % 5000 == 0 or iteration==500:\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)\n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            iteration, lossG_item, lossA_item, lossD_item\n",
    "        ))\n",
    "        print('iter = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            iteration, lossG_item, lossA_item, lossD_item\n",
    "        ))\n",
    "    if iteration % 5000==0 or iteration==10 or iteration==500:\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration, iteration,\n",
    "                                        iteration]]),\n",
    "                           Y=np.array([[lossG_item, lossA_item, lossD_item]]),\n",
    "                           opts=dict(\n",
    "                               title='GaitGAN',\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration,\n",
    "                                  iteration]]),\n",
    "                     Y=np.array([[lossG_item, lossA_item, lossD_item]]),\n",
    "                     win=win,\n",
    "                     update='append')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T21:10:50.374217Z",
     "start_time": "2019-08-12T16:51:41.263663Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 3.752237558364868, ErrA = -1.8985527356465657, ErrD = -3.5465147892634072\n",
      "Epoch = 4, ErrG = 5.705430269241333, ErrA = -2.807316621144613, ErrD = -5.611066023508708\n",
      "Epoch = 6, ErrG = 4.896071195602417, ErrA = -3.07237180074056, ErrD = -6.601948658625285\n",
      "Epoch = 8, ErrG = 8.87260103225708, ErrA = -4.403616587320964, ErrD = -9.87374464670817\n",
      "Epoch = 10, ErrG = 7.947443723678589, ErrA = -4.1470723152160645, ErrD = -8.064921021461487\n",
      "Epoch = 12, ErrG = 1.238088607788086, ErrA = -4.921435038248698, ErrD = -4.710442225138347\n",
      "Epoch = 14, ErrG = 0.5194168090820312, ErrA = -5.6255998611450195, ErrD = -5.323735237121582\n",
      "Epoch = 16, ErrG = 6.348399639129639, ErrA = -7.5277970631917315, ErrD = -7.016017913818359\n",
      "Epoch = 18, ErrG = 0.8842306137084961, ErrA = -7.25491460164388, ErrD = -7.062686284383138\n",
      "Epoch = 20, ErrG = 0.0035724639892578125, ErrA = -7.803771336873372, ErrD = -7.927731831868489\n",
      "Epoch = 22, ErrG = 1.2339839935302734, ErrA = -8.73021380106608, ErrD = -8.565280278523764\n",
      "Epoch = 24, ErrG = 1.2255611419677734, ErrA = -9.72688357035319, ErrD = -9.670048395792643\n",
      "Epoch = 26, ErrG = 0.15535354614257812, ErrA = -10.620674769083658, ErrD = -10.38158925374349\n",
      "Epoch = 28, ErrG = 4.176642417907715, ErrA = -12.133074442545572, ErrD = -10.76137606302897\n",
      "Epoch = 30, ErrG = 4.427227973937988, ErrA = -12.199844360351562, ErrD = -12.158490498860678\n",
      "Epoch = 32, ErrG = 3.9799652099609375, ErrA = -14.347677866617838, ErrD = -14.839614232381185\n",
      "Epoch = 34, ErrG = 3.2736902236938477, ErrA = -14.609235127766928, ErrD = -15.713889439900717\n",
      "Epoch = 36, ErrG = 5.752946853637695, ErrA = -15.246897379557291, ErrD = -16.766225179036457\n",
      "Epoch = 38, ErrG = 1.6820240020751953, ErrA = -16.648352305094402, ErrD = -17.338180541992188\n",
      "Epoch = 40, ErrG = 10.724223136901855, ErrA = -17.55199940999349, ErrD = -20.6812006632487\n",
      "Epoch = 42, ErrG = 10.82100772857666, ErrA = -17.30973943074544, ErrD = -19.197577158610027\n",
      "Epoch = 44, ErrG = 6.142007827758789, ErrA = -19.585198720296223, ErrD = -21.98925272623698\n",
      "Epoch = 46, ErrG = 4.614898681640625, ErrA = -20.6905943552653, ErrD = -21.187957763671875\n",
      "Epoch = 48, ErrG = 14.935154914855957, ErrA = -20.511363983154297, ErrD = -22.849955240885418\n",
      "Epoch = 50, ErrG = 8.494245529174805, ErrA = -23.74848810831706, ErrD = -31.115222930908203\n",
      "Epoch = 52, ErrG = 9.508050918579102, ErrA = -24.220165252685547, ErrD = -25.16811243693034\n",
      "Epoch = 54, ErrG = 9.283670425415039, ErrA = -26.20640691121419, ErrD = -32.25322977701823\n",
      "Epoch = 56, ErrG = 13.134300231933594, ErrA = -23.950950622558594, ErrD = -31.37301762898763\n",
      "Epoch = 58, ErrG = 16.310850143432617, ErrA = -27.30752182006836, ErrD = -35.64556376139323\n",
      "Epoch = 60, ErrG = 9.128986358642578, ErrA = -25.83734639485677, ErrD = -38.91717656453451\n",
      "Epoch = 62, ErrG = 8.424102783203125, ErrA = -29.642303466796875, ErrD = -37.35610580444336\n",
      "Epoch = 64, ErrG = 25.559022903442383, ErrA = -31.677706400553387, ErrD = -32.23673756917318\n",
      "Epoch = 66, ErrG = 22.559337615966797, ErrA = -30.57117462158203, ErrD = -36.400753021240234\n",
      "Epoch = 68, ErrG = 15.052131652832031, ErrA = -35.96826934814453, ErrD = -46.180502573649086\n",
      "Epoch = 70, ErrG = -0.43895721435546875, ErrA = -32.98573303222656, ErrD = -43.57259877522787\n",
      "Epoch = 72, ErrG = 20.29894256591797, ErrA = -31.93470573425293, ErrD = -37.67890421549479\n",
      "Epoch = 74, ErrG = 21.782943725585938, ErrA = -34.07020823160807, ErrD = -43.74110539754232\n",
      "Epoch = 76, ErrG = 17.07122039794922, ErrA = -36.35697682698568, ErrD = -43.905600229899086\n",
      "Epoch = 78, ErrG = 24.486148834228516, ErrA = -33.160257975260414, ErrD = -43.00210825602213\n",
      "Epoch = 80, ErrG = 15.440643310546875, ErrA = -37.9337158203125, ErrD = -40.34435017903646\n",
      "Epoch = 82, ErrG = 29.550189971923828, ErrA = -35.814918518066406, ErrD = -36.93999989827474\n",
      "Epoch = 84, ErrG = 35.63076400756836, ErrA = -33.67802937825521, ErrD = -39.35210164388021\n",
      "Epoch = 86, ErrG = 5.164623260498047, ErrA = -36.27676010131836, ErrD = -45.937704722086586\n",
      "Epoch = 88, ErrG = 34.15803337097168, ErrA = -34.38240051269531, ErrD = -36.078348795572914\n",
      "Epoch = 90, ErrG = 27.58734130859375, ErrA = -35.30627187093099, ErrD = -36.39269765218099\n",
      "Epoch = 92, ErrG = 21.712127685546875, ErrA = -43.05618794759115, ErrD = -43.50933329264323\n",
      "Epoch = 94, ErrG = 23.809022903442383, ErrA = -35.48206075032552, ErrD = -43.326897939046226\n",
      "Epoch = 96, ErrG = 7.748218536376953, ErrA = -40.57562255859375, ErrD = -37.02054087320963\n",
      "Epoch = 98, ErrG = 26.957927703857422, ErrA = -38.756151835123696, ErrD = -43.28245290120443\n",
      "Epoch = 100, ErrG = 23.970237731933594, ErrA = -37.00896962483724, ErrD = -53.31181208292643\n",
      "Epoch = 102, ErrG = 32.94005584716797, ErrA = -39.04310099283854, ErrD = -51.9184201558431\n",
      "Epoch = 104, ErrG = 19.669761657714844, ErrA = -43.722066243489586, ErrD = -40.6604372660319\n",
      "Epoch = 106, ErrG = 30.4774227142334, ErrA = -38.271830240885414, ErrD = -53.44103177388509\n",
      "Epoch = 108, ErrG = 23.701269149780273, ErrA = -33.69484074910482, ErrD = -50.71127955118815\n",
      "Epoch = 110, ErrG = 21.733970642089844, ErrA = -42.21501159667969, ErrD = -46.632896423339844\n",
      "Epoch = 112, ErrG = 15.799474716186523, ErrA = -43.70868047078451, ErrD = -49.64525349934896\n",
      "Epoch = 114, ErrG = 27.10312271118164, ErrA = -41.81016540527344, ErrD = -44.88124211629232\n",
      "Epoch = 116, ErrG = 23.331727981567383, ErrA = -42.46739196777344, ErrD = -52.138458887736\n",
      "Epoch = 118, ErrG = 14.420063018798828, ErrA = -42.84778340657552, ErrD = -52.99237314860026\n",
      "Epoch = 120, ErrG = 10.393743515014648, ErrA = -45.924853006998696, ErrD = -47.42411422729492\n",
      "Epoch = 122, ErrG = 30.84074592590332, ErrA = -41.41245142618815, ErrD = -41.43104553222656\n",
      "Epoch = 124, ErrG = 24.6036376953125, ErrA = -47.508253733317055, ErrD = -49.0322634379069\n",
      "Epoch = 126, ErrG = 7.567792892456055, ErrA = -43.6812318166097, ErrD = -45.534558614095054\n",
      "Epoch = 128, ErrG = 20.735679626464844, ErrA = -44.79042053222656, ErrD = -49.46401723225912\n",
      "Epoch = 130, ErrG = 34.88346481323242, ErrA = -43.56171671549479, ErrD = -53.02450307210287\n",
      "Epoch = 132, ErrG = 14.784172058105469, ErrA = -47.639919916788735, ErrD = -56.534576416015625\n",
      "Epoch = 134, ErrG = 5.3000335693359375, ErrA = -45.719713846842446, ErrD = -47.3958485921224\n",
      "Epoch = 136, ErrG = 33.13093566894531, ErrA = -46.01913579305013, ErrD = -45.147561391194664\n",
      "Epoch = 138, ErrG = 7.9607696533203125, ErrA = -44.981788635253906, ErrD = -45.9197031656901\n",
      "Epoch = 140, ErrG = 32.752577781677246, ErrA = -50.14874267578125, ErrD = -48.33478037516276\n",
      "Epoch = 142, ErrG = 27.397136688232422, ErrA = -51.0384521484375, ErrD = -45.8910166422526\n",
      "Epoch = 144, ErrG = 18.818775177001953, ErrA = -46.139442443847656, ErrD = -53.372047424316406\n",
      "Epoch = 146, ErrG = 12.755931854248047, ErrA = -50.660491943359375, ErrD = -42.15100351969401\n",
      "Epoch = 148, ErrG = 36.428768157958984, ErrA = -40.090606689453125, ErrD = -50.37515640258789\n",
      "Epoch = 150, ErrG = 26.392959594726562, ErrA = -45.61802673339844, ErrD = -57.03471883138021\n",
      "Epoch = 152, ErrG = 32.42155647277832, ErrA = -49.17280197143555, ErrD = -55.87982432047526\n",
      "Epoch = 154, ErrG = 28.329788208007812, ErrA = -46.74053955078125, ErrD = -54.31385167439779\n",
      "Epoch = 156, ErrG = 28.82765007019043, ErrA = -49.074896494547524, ErrD = -51.165435791015625\n",
      "Epoch = 158, ErrG = 38.087825775146484, ErrA = -48.276031494140625, ErrD = -46.57391357421875\n",
      "Epoch = 160, ErrG = 33.847015380859375, ErrA = -52.00985972086588, ErrD = -54.78546396891276\n",
      "Epoch = 162, ErrG = 27.009334564208984, ErrA = -52.78433736165365, ErrD = -46.339029947916664\n",
      "Epoch = 164, ErrG = 40.22963905334473, ErrA = -47.421844482421875, ErrD = -50.96429443359375\n",
      "Epoch = 166, ErrG = 16.37985610961914, ErrA = -51.617088317871094, ErrD = -42.452301025390625\n",
      "Epoch = 168, ErrG = 39.59768009185791, ErrA = -50.21680450439453, ErrD = -48.176429748535156\n",
      "Epoch = 170, ErrG = 16.476112365722656, ErrA = -54.13165537516276, ErrD = -48.20995585123698\n",
      "Epoch = 172, ErrG = 13.669944763183594, ErrA = -56.07218805948893, ErrD = -47.43832143147787\n",
      "Epoch = 174, ErrG = 43.97322463989258, ErrA = -49.44780476888021, ErrD = -60.40503692626953\n",
      "Epoch = 176, ErrG = 51.41545104980469, ErrA = -48.0418701171875, ErrD = -49.61841074625651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 178, ErrG = 13.589683532714844, ErrA = -53.47724533081055, ErrD = -60.667805989583336\n",
      "Epoch = 180, ErrG = 27.157360076904297, ErrA = -54.507459004720054, ErrD = -51.485514322916664\n",
      "Epoch = 182, ErrG = 56.5279426574707, ErrA = -54.72101338704427, ErrD = -54.934326171875\n",
      "Epoch = 184, ErrG = 26.18047523498535, ErrA = -55.34730529785156, ErrD = -59.38808059692383\n",
      "Epoch = 186, ErrG = 13.245643615722656, ErrA = -56.8813362121582, ErrD = -60.9880002339681\n",
      "Epoch = 188, ErrG = 14.880294799804688, ErrA = -53.91685994466146, ErrD = -41.10221862792969\n",
      "Epoch = 190, ErrG = 33.4071044921875, ErrA = -55.473968505859375, ErrD = -54.388196309407554\n",
      "Epoch = 192, ErrG = 54.02478504180908, ErrA = -50.48332722981771, ErrD = -56.40521113077799\n",
      "Epoch = 194, ErrG = 35.50703430175781, ErrA = -58.89679463704427, ErrD = -55.31469599405924\n",
      "Epoch = 196, ErrG = 47.07379150390625, ErrA = -56.774068196614586, ErrD = -64.39537811279297\n",
      "Epoch = 198, ErrG = 8.856361389160156, ErrA = -59.77715301513672, ErrD = -64.9952163696289\n",
      "Epoch = 200, ErrG = 29.70721435546875, ErrA = -56.79498545328776, ErrD = -54.51270294189453\n",
      "Epoch = 202, ErrG = 26.80780792236328, ErrA = -52.97642262776693, ErrD = -64.11403401692708\n",
      "Epoch = 204, ErrG = 40.808549880981445, ErrA = -57.87753041585287, ErrD = -58.921887715657554\n",
      "Epoch = 206, ErrG = 31.963516235351562, ErrA = -57.01087443033854, ErrD = -62.27792104085287\n",
      "Epoch = 208, ErrG = 29.492111206054688, ErrA = -59.22845204671224, ErrD = -62.509283701578774\n",
      "Epoch = 210, ErrG = 24.597782135009766, ErrA = -51.43456522623698, ErrD = -46.685526529947914\n",
      "Epoch = 212, ErrG = 41.20795440673828, ErrA = -51.82847340901693, ErrD = -59.94965616861979\n",
      "Epoch = 214, ErrG = 24.700300216674805, ErrA = -58.8781483968099, ErrD = -56.99071248372396\n",
      "Epoch = 216, ErrG = 43.80158233642578, ErrA = -66.13713200887044, ErrD = -57.41633097330729\n",
      "Epoch = 218, ErrG = 21.087066650390625, ErrA = -61.43894958496094, ErrD = -63.81585947672526\n",
      "Epoch = 220, ErrG = 12.300617218017578, ErrA = -53.04488627115885, ErrD = -59.854827880859375\n",
      "Epoch = 222, ErrG = 46.30165481567383, ErrA = -59.692169189453125, ErrD = -53.75653584798177\n",
      "Epoch = 224, ErrG = 0.5765094757080078, ErrA = -50.81816482543945, ErrD = -63.12418174743652\n",
      "Epoch = 226, ErrG = 32.272850036621094, ErrA = -57.97929890950521, ErrD = -62.49226379394531\n",
      "Epoch = 228, ErrG = 35.99797821044922, ErrA = -56.8940175374349, ErrD = -61.08178965250651\n",
      "Epoch = 230, ErrG = 39.069908142089844, ErrA = -55.732154846191406, ErrD = -56.85692596435547\n",
      "Epoch = 232, ErrG = 49.18810272216797, ErrA = -63.86371103922526, ErrD = -58.29519271850586\n",
      "Epoch = 234, ErrG = 37.361642837524414, ErrA = -54.640785217285156, ErrD = -56.61802673339844\n",
      "Epoch = 236, ErrG = 38.99468421936035, ErrA = -59.13226826985677, ErrD = -64.7657470703125\n",
      "Epoch = 238, ErrG = 29.59778594970703, ErrA = -57.40739313761393, ErrD = -52.86402893066406\n",
      "Epoch = 240, ErrG = 48.086307525634766, ErrA = -62.1838633219401, ErrD = -65.8669802347819\n",
      "Epoch = 242, ErrG = 42.80795669555664, ErrA = -57.47236633300781, ErrD = -60.1668955485026\n",
      "Epoch = 244, ErrG = 37.5455436706543, ErrA = -60.02565002441406, ErrD = -61.89683532714844\n",
      "Epoch = 246, ErrG = 24.923423767089844, ErrA = -55.64678700764974, ErrD = -53.671793619791664\n",
      "Epoch = 248, ErrG = 21.554122924804688, ErrA = -55.187459309895836, ErrD = -68.6442273457845\n",
      "Epoch = 250, ErrG = 39.532044410705566, ErrA = -61.48728688557943, ErrD = -60.739175160725914\n",
      "Epoch = 252, ErrG = 44.82626724243164, ErrA = -55.3868662516276, ErrD = -62.29729461669922\n",
      "Epoch = 254, ErrG = 23.156665802001953, ErrA = -58.65504455566406, ErrD = -61.06082407633463\n",
      "Epoch = 256, ErrG = 50.57086181640625, ErrA = -54.708353678385414, ErrD = -57.953992207845054\n",
      "Epoch = 258, ErrG = 24.920055389404297, ErrA = -60.98302714029948, ErrD = -52.59061940511068\n",
      "Epoch = 260, ErrG = 11.361351013183594, ErrA = -54.09619267781576, ErrD = -68.87776692708333\n",
      "Epoch = 262, ErrG = 45.97099304199219, ErrA = -57.943921407063804, ErrD = -62.40335210164388\n",
      "Epoch = 264, ErrG = 33.69055938720703, ErrA = -54.812835693359375, ErrD = -60.143880208333336\n",
      "Epoch = 266, ErrG = 29.74732208251953, ErrA = -59.415992736816406, ErrD = -57.41911315917969\n",
      "Epoch = 268, ErrG = 29.44239616394043, ErrA = -52.65238698323568, ErrD = -58.71290715535482\n",
      "Epoch = 270, ErrG = 37.98057746887207, ErrA = -62.95439147949219, ErrD = -59.59795379638672\n",
      "Epoch = 272, ErrG = 38.75329113006592, ErrA = -55.74959055582682, ErrD = -64.18805694580078\n",
      "Epoch = 274, ErrG = 47.832807540893555, ErrA = -57.017738342285156, ErrD = -56.38230641682943\n",
      "Epoch = 276, ErrG = 14.78870964050293, ErrA = -52.4200070699056, ErrD = -59.957374572753906\n",
      "Epoch = 278, ErrG = 26.867733001708984, ErrA = -57.29559834798177, ErrD = -49.60607655843099\n",
      "Epoch = 280, ErrG = 37.02639389038086, ErrA = -66.94647979736328, ErrD = -63.072410583496094\n",
      "Epoch = 282, ErrG = -0.3623046875, ErrA = -54.25152715047201, ErrD = -66.59829584757487\n",
      "Epoch = 284, ErrG = 13.158088684082031, ErrA = -54.0291748046875, ErrD = -63.78947321573893\n",
      "Epoch = 286, ErrG = 27.65243148803711, ErrA = -53.52515665690104, ErrD = -61.45234171549479\n",
      "Epoch = 288, ErrG = 61.394615173339844, ErrA = -51.240264892578125, ErrD = -63.935760498046875\n",
      "Epoch = 290, ErrG = 29.450422286987305, ErrA = -61.39708455403646, ErrD = -66.13375536600749\n",
      "Epoch = 292, ErrG = 34.73390197753906, ErrA = -60.84249369303385, ErrD = -58.56263987223307\n",
      "Epoch = 294, ErrG = 17.038246154785156, ErrA = -63.12732950846354, ErrD = -52.300315856933594\n",
      "Epoch = 296, ErrG = 28.44264793395996, ErrA = -60.0536855061849, ErrD = -65.03005727132161\n",
      "Epoch = 298, ErrG = 31.967235565185547, ErrA = -57.93494415283203, ErrD = -61.87687428792318\n",
      "Epoch = 300, ErrG = 38.189605712890625, ErrA = -56.009785970052086, ErrD = -63.901527404785156\n",
      "Epoch = 302, ErrG = 45.43501663208008, ErrA = -53.444671630859375, ErrD = -60.79595184326172\n",
      "Epoch = 304, ErrG = 33.71999740600586, ErrA = -57.73729451497396, ErrD = -61.60076649983724\n",
      "Epoch = 306, ErrG = 31.36231231689453, ErrA = -56.054649353027344, ErrD = -64.25700378417969\n",
      "Epoch = 308, ErrG = 34.849470138549805, ErrA = -58.81513214111328, ErrD = -69.3256352742513\n",
      "Epoch = 310, ErrG = 7.066127777099609, ErrA = -54.39345041910807, ErrD = -68.54374186197917\n",
      "Epoch = 312, ErrG = 16.75394058227539, ErrA = -60.0110117594401, ErrD = -59.644727071126304\n",
      "Epoch = 314, ErrG = 39.84816360473633, ErrA = -53.07177988688151, ErrD = -62.842041015625\n",
      "Epoch = 316, ErrG = 17.476280212402344, ErrA = -53.02575429280599, ErrD = -64.14187367757161\n",
      "Epoch = 318, ErrG = 24.248268127441406, ErrA = -51.51179504394531, ErrD = -64.31844075520833\n",
      "Epoch = 320, ErrG = 50.94792938232422, ErrA = -52.61750793457031, ErrD = -58.396888732910156\n",
      "Epoch = 322, ErrG = 17.860322952270508, ErrA = -55.21711730957031, ErrD = -61.709059397379555\n",
      "Epoch = 324, ErrG = 19.570438385009766, ErrA = -57.94499715169271, ErrD = -55.465250651041664\n",
      "Epoch = 326, ErrG = 23.74677276611328, ErrA = -56.7961680094401, ErrD = -62.61913299560547\n",
      "Epoch = 328, ErrG = 29.372756958007812, ErrA = -54.7065175374349, ErrD = -64.84056218465169\n",
      "Epoch = 330, ErrG = 31.334259033203125, ErrA = -59.301544189453125, ErrD = -71.14505259195964\n",
      "Epoch = 332, ErrG = 33.93251991271973, ErrA = -71.69486999511719, ErrD = -65.12302017211914\n",
      "Epoch = 334, ErrG = 51.6334342956543, ErrA = -65.22751744588216, ErrD = -57.3493906656901\n",
      "Epoch = 336, ErrG = 58.711320877075195, ErrA = -56.8249766031901, ErrD = -61.98045349121094\n",
      "Epoch = 338, ErrG = 48.212547302246094, ErrA = -53.58669789632162, ErrD = -62.310699462890625\n",
      "Epoch = 340, ErrG = 35.288429260253906, ErrA = -58.79040273030599, ErrD = -68.10496266682942\n",
      "Epoch = 342, ErrG = 19.792076110839844, ErrA = -58.24455261230469, ErrD = -58.91251118977865\n",
      "Epoch = 344, ErrG = 39.308786392211914, ErrA = -63.048632303873696, ErrD = -70.51083310445149\n",
      "Epoch = 346, ErrG = 33.952796936035156, ErrA = -66.32902399698894, ErrD = -60.6352907816569\n",
      "Epoch = 348, ErrG = 32.641130447387695, ErrA = -55.43011728922526, ErrD = -64.15465799967448\n",
      "Epoch = 350, ErrG = 55.34505081176758, ErrA = -68.11125183105469, ErrD = -60.92284901936849\n",
      "Epoch = 352, ErrG = 19.385807037353516, ErrA = -61.203216552734375, ErrD = -59.771802266438804\n",
      "Epoch = 354, ErrG = 23.754371643066406, ErrA = -53.464691162109375, ErrD = -53.68300120035807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 356, ErrG = 33.6126594543457, ErrA = -54.70630900065104, ErrD = -60.700757344563804\n",
      "Epoch = 358, ErrG = 38.190752029418945, ErrA = -54.00933074951172, ErrD = -58.47474924723307\n",
      "Epoch = 360, ErrG = 24.69669532775879, ErrA = -51.98524602254232, ErrD = -69.35917663574219\n",
      "Epoch = 362, ErrG = 20.46735382080078, ErrA = -58.84796142578125, ErrD = -65.61435190836589\n",
      "Epoch = 364, ErrG = 32.753963470458984, ErrA = -54.45555623372396, ErrD = -72.78407796223958\n",
      "Epoch = 366, ErrG = 50.228535652160645, ErrA = -63.61809285481771, ErrD = -68.19214502970378\n",
      "Epoch = 368, ErrG = 35.94788932800293, ErrA = -55.87086486816406, ErrD = -63.45636494954427\n",
      "Epoch = 370, ErrG = 13.586647033691406, ErrA = -55.783398946126304, ErrD = -54.916760762532554\n",
      "Epoch = 372, ErrG = 17.255874633789062, ErrA = -48.30359903971354, ErrD = -46.36835225423177\n",
      "Epoch = 374, ErrG = 32.9892520904541, ErrA = -55.58989715576172, ErrD = -59.28937530517578\n",
      "Epoch = 376, ErrG = 22.925832748413086, ErrA = -53.68057378133138, ErrD = -70.38489532470703\n",
      "Epoch = 378, ErrG = 39.14872169494629, ErrA = -56.77939097086588, ErrD = -69.97228368123372\n",
      "Epoch = 380, ErrG = 37.98346138000488, ErrA = -70.92394383748372, ErrD = -63.739463806152344\n",
      "Epoch = 382, ErrG = 11.71066665649414, ErrA = -49.678052266438804, ErrD = -50.561973571777344\n",
      "Epoch = 384, ErrG = 42.465614318847656, ErrA = -51.97177378336588, ErrD = -66.81608327229817\n",
      "Epoch = 386, ErrG = 34.185874938964844, ErrA = -61.02386220296224, ErrD = -67.53244527180989\n",
      "Epoch = 388, ErrG = 24.00299835205078, ErrA = -66.34642028808594, ErrD = -52.7586415608724\n",
      "Epoch = 390, ErrG = 34.50017547607422, ErrA = -59.19859313964844, ErrD = -61.18268585205078\n",
      "Epoch = 392, ErrG = 27.969257354736328, ErrA = -53.75149281819662, ErrD = -70.12789662679036\n",
      "Epoch = 394, ErrG = 26.38385009765625, ErrA = -52.01428985595703, ErrD = -54.17454274495443\n",
      "Epoch = 396, ErrG = 40.599212646484375, ErrA = -68.54917399088542, ErrD = -63.58603286743164\n",
      "Epoch = 398, ErrG = 32.78520202636719, ErrA = -65.1453119913737, ErrD = -64.6326904296875\n",
      "Epoch = 400, ErrG = 49.09597396850586, ErrA = -53.21214803059896, ErrD = -66.89800135294597\n",
      "Epoch = 402, ErrG = 39.59214973449707, ErrA = -68.57282002766927, ErrD = -63.79826100667318\n",
      "Epoch = 404, ErrG = 36.42768096923828, ErrA = -57.14504750569662, ErrD = -62.870782216389976\n",
      "Epoch = 406, ErrG = 41.13043975830078, ErrA = -66.44118754069011, ErrD = -67.1231206258138\n",
      "Epoch = 408, ErrG = 40.519248962402344, ErrA = -55.72591908772787, ErrD = -63.44806925455729\n",
      "Epoch = 410, ErrG = 8.676883697509766, ErrA = -53.254889170328774, ErrD = -70.04425557454427\n",
      "Epoch = 412, ErrG = 39.73149490356445, ErrA = -60.67809549967448, ErrD = -59.34845733642578\n",
      "Epoch = 414, ErrG = 44.94213104248047, ErrA = -58.84981791178385, ErrD = -62.26978556315104\n",
      "Epoch = 416, ErrG = 44.905171394348145, ErrA = -60.26587168375651, ErrD = -62.14511362711588\n",
      "Epoch = 418, ErrG = 9.405593872070312, ErrA = -53.38958740234375, ErrD = -55.43212127685547\n",
      "Epoch = 420, ErrG = 41.25836372375488, ErrA = -59.92498779296875, ErrD = -65.41701889038086\n",
      "Epoch = 422, ErrG = 53.83705520629883, ErrA = -61.276529947916664, ErrD = -62.611759185791016\n",
      "Epoch = 424, ErrG = 57.17337894439697, ErrA = -52.5743662516276, ErrD = -56.13221232096354\n",
      "Epoch = 426, ErrG = 20.870033264160156, ErrA = -53.882500966389976, ErrD = -68.95259857177734\n",
      "Epoch = 428, ErrG = 43.09904479980469, ErrA = -63.458821614583336, ErrD = -67.11199569702148\n",
      "Epoch = 430, ErrG = 37.879533767700195, ErrA = -51.35175069173177, ErrD = -55.616111755371094\n",
      "Epoch = 432, ErrG = 53.792802810668945, ErrA = -63.26050059000651, ErrD = -60.72510019938151\n",
      "Epoch = 434, ErrG = 49.90922164916992, ErrA = -58.98936971028646, ErrD = -63.53008778889974\n",
      "Epoch = 436, ErrG = 50.72173309326172, ErrA = -58.171234130859375, ErrD = -66.90966033935547\n",
      "Epoch = 438, ErrG = 29.896400451660156, ErrA = -66.06337483723958, ErrD = -72.0915756225586\n",
      "Epoch = 440, ErrG = 57.47335910797119, ErrA = -53.837910970052086, ErrD = -66.69252014160156\n",
      "Epoch = 442, ErrG = 53.14113140106201, ErrA = -59.606160481770836, ErrD = -68.74711990356445\n",
      "Epoch = 444, ErrG = 28.48581314086914, ErrA = -53.85345967610677, ErrD = -69.40182495117188\n",
      "Epoch = 446, ErrG = 54.977848052978516, ErrA = -66.95192972819011, ErrD = -64.35314687093098\n",
      "Epoch = 448, ErrG = 40.995070457458496, ErrA = -67.17684809366862, ErrD = -73.09521993001302\n",
      "Epoch = 450, ErrG = 52.70650577545166, ErrA = -71.90774790445964, ErrD = -63.97581481933594\n",
      "Epoch = 452, ErrG = 38.21393966674805, ErrA = -56.86279042561849, ErrD = -64.89502080281575\n",
      "Epoch = 454, ErrG = 23.884166717529297, ErrA = -62.41895294189453, ErrD = -56.12940979003906\n",
      "Epoch = 456, ErrG = 25.797683715820312, ErrA = -57.72713979085287, ErrD = -63.943461100260414\n",
      "Epoch = 458, ErrG = 15.110187530517578, ErrA = -54.096591313680015, ErrD = -69.43308766682942\n",
      "Epoch = 460, ErrG = 43.30340576171875, ErrA = -56.14399973551432, ErrD = -68.29193878173828\n",
      "Epoch = 462, ErrG = 32.15269470214844, ErrA = -63.09256490071615, ErrD = -56.44354756673177\n",
      "Epoch = 464, ErrG = 52.05646800994873, ErrA = -50.448343912760414, ErrD = -66.50056966145833\n",
      "Epoch = 466, ErrG = 4.228542327880859, ErrA = -52.84986368815104, ErrD = -73.31474494934082\n",
      "Epoch = 468, ErrG = 50.578712463378906, ErrA = -56.29412841796875, ErrD = -65.20470301310222\n",
      "Epoch = 470, ErrG = 34.35968589782715, ErrA = -49.916056315104164, ErrD = -62.08154296875\n",
      "Epoch = 472, ErrG = 33.80355453491211, ErrA = -62.99788284301758, ErrD = -67.3942756652832\n",
      "Epoch = 474, ErrG = 33.84378242492676, ErrA = -58.1270497639974, ErrD = -70.65600077311198\n",
      "Epoch = 476, ErrG = 25.505626678466797, ErrA = -64.29613240559895, ErrD = -63.43807474772135\n",
      "Epoch = 478, ErrG = 44.1737642288208, ErrA = -66.74645105997722, ErrD = -63.94996007283529\n",
      "Epoch = 480, ErrG = 23.51127338409424, ErrA = -61.60963821411133, ErrD = -67.10307184855144\n",
      "Epoch = 482, ErrG = 50.67127990722656, ErrA = -60.29616038004557, ErrD = -68.32680638631184\n",
      "Epoch = 484, ErrG = 39.28990650177002, ErrA = -55.64842224121094, ErrD = -68.92419052124023\n",
      "Epoch = 486, ErrG = 41.45376968383789, ErrA = -49.844401041666664, ErrD = -71.79349772135417\n",
      "Epoch = 488, ErrG = 21.701923370361328, ErrA = -71.4591801961263, ErrD = -57.4811045328776\n",
      "Epoch = 490, ErrG = 24.55376434326172, ErrA = -61.52686309814453, ErrD = -67.131103515625\n",
      "Epoch = 492, ErrG = 61.67786502838135, ErrA = -54.50935363769531, ErrD = -54.06448745727539\n",
      "Epoch = 494, ErrG = 39.68107795715332, ErrA = -60.750317891438804, ErrD = -65.53173573811848\n",
      "Epoch = 496, ErrG = 45.01790142059326, ErrA = -64.17027537027995, ErrD = -65.64413324991862\n",
      "Epoch = 498, ErrG = 35.810279846191406, ErrA = -58.79186248779297, ErrD = -64.05129623413086\n",
      "Epoch = 500, ErrG = 37.89598560333252, ErrA = -62.62899271647135, ErrD = -70.41813151041667\n",
      "Epoch = 502, ErrG = 26.817110061645508, ErrA = -62.03665669759115, ErrD = -66.9297866821289\n",
      "Epoch = 504, ErrG = 9.062042236328125, ErrA = -53.788492838541664, ErrD = -60.494927724202476\n",
      "Epoch = 506, ErrG = 20.60637855529785, ErrA = -59.55596415201823, ErrD = -61.60150655110677\n",
      "Epoch = 508, ErrG = 23.69287872314453, ErrA = -55.12169901529948, ErrD = -56.08136240641276\n",
      "Epoch = 510, ErrG = 41.578102111816406, ErrA = -61.08525085449219, ErrD = -69.65505472819011\n",
      "Epoch = 512, ErrG = 44.543888092041016, ErrA = -62.17799377441406, ErrD = -70.29504903157552\n",
      "Epoch = 514, ErrG = 21.063480377197266, ErrA = -55.73839569091797, ErrD = -65.7655766805013\n",
      "Epoch = 516, ErrG = 34.95582580566406, ErrA = -55.59435272216797, ErrD = -61.46228281656901\n",
      "Epoch = 518, ErrG = 52.33576011657715, ErrA = -57.36321004231771, ErrD = -65.60738754272461\n",
      "Epoch = 520, ErrG = 25.218528747558594, ErrA = -54.542388916015625, ErrD = -66.70675913492839\n",
      "Epoch = 522, ErrG = 8.616954803466797, ErrA = -52.48388671875, ErrD = -66.22439956665039\n",
      "Epoch = 524, ErrG = 39.994110107421875, ErrA = -63.48646545410156, ErrD = -67.94480641682942\n",
      "Epoch = 526, ErrG = 33.35336208343506, ErrA = -62.36002095540365, ErrD = -62.838053385416664\n",
      "Epoch = 528, ErrG = 38.54512977600098, ErrA = -66.10426584879558, ErrD = -68.32180277506511\n",
      "Epoch = 530, ErrG = 52.60305118560791, ErrA = -57.163777669270836, ErrD = -73.31582514444987\n",
      "Epoch = 532, ErrG = 41.37113380432129, ErrA = -64.23981475830078, ErrD = -69.5402119954427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 534, ErrG = 35.67050743103027, ErrA = -64.6280288696289, ErrD = -75.14555549621582\n",
      "Epoch = 536, ErrG = 46.15334701538086, ErrA = -52.71881357828776, ErrD = -65.6470947265625\n",
      "Epoch = 538, ErrG = 28.56289291381836, ErrA = -67.59828821818034, ErrD = -64.95235061645508\n",
      "Epoch = 540, ErrG = 29.25141143798828, ErrA = -51.203712463378906, ErrD = -58.197113037109375\n",
      "Epoch = 542, ErrG = 42.39829158782959, ErrA = -52.20666249593099, ErrD = -70.6221415201823\n",
      "Epoch = 544, ErrG = 0.5973739624023438, ErrA = -60.515010833740234, ErrD = -52.27333068847656\n",
      "Epoch = 546, ErrG = 56.850443840026855, ErrA = -64.28490193684895, ErrD = -68.94095865885417\n",
      "Epoch = 548, ErrG = 48.342369079589844, ErrA = -63.897132873535156, ErrD = -73.07439422607422\n",
      "Epoch = 550, ErrG = 20.176572799682617, ErrA = -54.681190490722656, ErrD = -57.4961903889974\n",
      "Epoch = 552, ErrG = 27.500083923339844, ErrA = -62.00841776529948, ErrD = -61.99379221598307\n",
      "Epoch = 554, ErrG = 41.838890075683594, ErrA = -57.539103190104164, ErrD = -60.26258087158203\n",
      "Epoch = 556, ErrG = 36.87055587768555, ErrA = -62.642189025878906, ErrD = -63.233968098958336\n",
      "Epoch = 558, ErrG = 58.98291563987732, ErrA = -67.23328653971355, ErrD = -63.23949178059896\n",
      "Epoch = 560, ErrG = 27.64870834350586, ErrA = -65.09554799397786, ErrD = -74.21728388468425\n",
      "Epoch = 562, ErrG = 41.137359619140625, ErrA = -55.5008799235026, ErrD = -64.63999811808269\n",
      "Epoch = 564, ErrG = 40.174476623535156, ErrA = -66.86784489949544, ErrD = -67.54863866170247\n",
      "Epoch = 566, ErrG = 43.09079456329346, ErrA = -63.322837829589844, ErrD = -69.93621571858723\n",
      "Epoch = 568, ErrG = 55.08440399169922, ErrA = -65.14248148600261, ErrD = -63.517303466796875\n",
      "Epoch = 570, ErrG = 23.57492446899414, ErrA = -53.06898752848307, ErrD = -71.75655619303386\n",
      "Epoch = 572, ErrG = 52.411720275878906, ErrA = -49.819844563802086, ErrD = -66.27540079752605\n",
      "Epoch = 574, ErrG = 37.042842864990234, ErrA = -61.36553192138672, ErrD = -70.49814860026042\n",
      "Epoch = 576, ErrG = 31.379695892333984, ErrA = -50.54874928792318, ErrD = -70.00310325622559\n",
      "Epoch = 578, ErrG = 41.03609848022461, ErrA = -60.01083628336588, ErrD = -71.87457021077473\n",
      "Epoch = 580, ErrG = 33.574209213256836, ErrA = -62.58209101359049, ErrD = -62.86368306477865\n",
      "Epoch = 582, ErrG = 36.61906623840332, ErrA = -51.31909942626953, ErrD = -56.541884104410805\n",
      "Epoch = 584, ErrG = 58.54026222229004, ErrA = -58.21321105957031, ErrD = -76.05770619710286\n",
      "Epoch = 586, ErrG = 48.56541442871094, ErrA = -54.21184794108073, ErrD = -59.93704160054525\n",
      "Epoch = 588, ErrG = 41.01787185668945, ErrA = -54.37150573730469, ErrD = -70.09254964192708\n",
      "Epoch = 590, ErrG = 38.1064510345459, ErrA = -66.26069895426433, ErrD = -72.41884104410808\n",
      "Epoch = 592, ErrG = 36.614644050598145, ErrA = -57.730673472086586, ErrD = -66.40248489379883\n",
      "Epoch = 594, ErrG = 28.566295623779297, ErrA = -53.2996571858724, ErrD = -73.40149052937825\n",
      "Epoch = 596, ErrG = 24.094173431396484, ErrA = -64.41771443684895, ErrD = -71.27927017211914\n",
      "Epoch = 598, ErrG = 51.440773010253906, ErrA = -60.659637451171875, ErrD = -72.20658334096272\n",
      "Epoch = 600, ErrG = 47.83757257461548, ErrA = -61.03613535563151, ErrD = -68.34225018819173\n",
      "Epoch = 602, ErrG = 30.338237762451172, ErrA = -53.22663370768229, ErrD = -76.15911229451497\n",
      "Epoch = 604, ErrG = 24.647541046142578, ErrA = -67.94074885050456, ErrD = -73.7671464284261\n",
      "Epoch = 606, ErrG = 48.22108459472656, ErrA = -68.68028259277344, ErrD = -68.72540855407715\n",
      "Epoch = 608, ErrG = 35.35359191894531, ErrA = -48.701245625813804, ErrD = -73.84268569946289\n",
      "Epoch = 610, ErrG = 45.98769569396973, ErrA = -63.406262715657554, ErrD = -50.47539202372233\n",
      "Epoch = 612, ErrG = 53.60260581970215, ErrA = -61.17078399658203, ErrD = -65.6535275777181\n",
      "Epoch = 614, ErrG = 31.80813455581665, ErrA = -57.97325642903646, ErrD = -72.0961201985677\n",
      "Epoch = 616, ErrG = 44.51856994628906, ErrA = -59.77678426106771, ErrD = -61.19131088256836\n",
      "Epoch = 618, ErrG = 26.758041381835938, ErrA = -58.15743509928385, ErrD = -58.03276443481445\n",
      "Epoch = 620, ErrG = 17.426517486572266, ErrA = -60.55420684814453, ErrD = -66.11593755086263\n",
      "Epoch = 622, ErrG = 46.37345600128174, ErrA = -54.938130696614586, ErrD = -73.57085800170898\n",
      "Epoch = 624, ErrG = 37.34706211090088, ErrA = -58.83191172281901, ErrD = -72.71742693583171\n",
      "Epoch = 626, ErrG = 47.67892074584961, ErrA = -60.18465932210287, ErrD = -67.47650146484375\n",
      "Epoch = 628, ErrG = 32.135135650634766, ErrA = -71.66409683227539, ErrD = -67.43375905354817\n",
      "Epoch = 630, ErrG = 25.857399940490723, ErrA = -55.796756744384766, ErrD = -70.44128036499023\n",
      "Epoch = 632, ErrG = 32.38648796081543, ErrA = -54.5589599609375, ErrD = -70.13754272460938\n",
      "Epoch = 634, ErrG = 29.953636169433594, ErrA = -65.62869771321614, ErrD = -54.47315470377604\n",
      "Epoch = 636, ErrG = 39.10485076904297, ErrA = -60.3807258605957, ErrD = -75.50116157531738\n",
      "Epoch = 638, ErrG = 38.0344181060791, ErrA = -65.65132141113281, ErrD = -68.29951985677083\n",
      "Epoch = 640, ErrG = 44.60162925720215, ErrA = -56.9787851969401, ErrD = -76.00372886657715\n",
      "Epoch = 642, ErrG = 25.630691528320312, ErrA = -62.791778564453125, ErrD = -72.18746376037598\n",
      "Epoch = 644, ErrG = 35.801937103271484, ErrA = -59.412882486979164, ErrD = -74.13927586873372\n",
      "Epoch = 646, ErrG = 33.10231971740723, ErrA = -62.70067850748698, ErrD = -67.3868802388509\n",
      "Epoch = 648, ErrG = 43.634796142578125, ErrA = -62.098645528157554, ErrD = -69.25359471638997\n",
      "Epoch = 650, ErrG = 53.724491119384766, ErrA = -59.0689442952474, ErrD = -66.22757466634114\n",
      "Epoch = 652, ErrG = 44.420875549316406, ErrA = -58.45557149251302, ErrD = -64.48914082845052\n",
      "Epoch = 654, ErrG = 55.66495180130005, ErrA = -52.225860595703125, ErrD = -66.88744354248047\n",
      "Epoch = 656, ErrG = 43.877394676208496, ErrA = -62.373792012532554, ErrD = -74.33016522725423\n",
      "Epoch = 658, ErrG = 27.257420539855957, ErrA = -61.58019256591797, ErrD = -72.64799563090007\n",
      "Epoch = 660, ErrG = 17.829692840576172, ErrA = -64.27245585123698, ErrD = -53.0283203125\n",
      "Epoch = 662, ErrG = 39.988800048828125, ErrA = -59.79927317301432, ErrD = -67.26321538289388\n",
      "Epoch = 664, ErrG = 41.95494365692139, ErrA = -56.908058166503906, ErrD = -60.66626803080241\n",
      "Epoch = 666, ErrG = 44.69482612609863, ErrA = -63.215169270833336, ErrD = -70.73779805501302\n",
      "Epoch = 668, ErrG = 37.43994617462158, ErrA = -54.86237080891927, ErrD = -64.8044942220052\n",
      "Epoch = 670, ErrG = 46.658180236816406, ErrA = -56.73846689860026, ErrD = -74.03222020467122\n",
      "Epoch = 672, ErrG = 38.28657150268555, ErrA = -72.7698237101237, ErrD = -70.02839533487956\n",
      "Epoch = 674, ErrG = 26.393455505371094, ErrA = -49.06089528401693, ErrD = -58.7732899983724\n",
      "Epoch = 676, ErrG = 55.90865707397461, ErrA = -69.96514002482097, ErrD = -72.7806765238444\n",
      "Epoch = 678, ErrG = 34.79686737060547, ErrA = -64.69188690185547, ErrD = -59.957845052083336\n",
      "Epoch = 680, ErrG = 36.5117826461792, ErrA = -63.20707448323568, ErrD = -74.41229756673177\n",
      "Epoch = 682, ErrG = 30.932147979736328, ErrA = -65.05978266398112, ErrD = -68.97441101074219\n",
      "Epoch = 684, ErrG = 39.56063461303711, ErrA = -58.51560084025065, ErrD = -67.46773846944173\n",
      "Epoch = 686, ErrG = 47.52247714996338, ErrA = -58.97255325317383, ErrD = -72.46952946980794\n",
      "Epoch = 688, ErrG = 34.543694496154785, ErrA = -59.70904413859049, ErrD = -70.99116134643555\n",
      "Epoch = 690, ErrG = 38.748836517333984, ErrA = -56.759053548177086, ErrD = -57.142845153808594\n",
      "Epoch = 692, ErrG = 33.52275085449219, ErrA = -68.07833099365234, ErrD = -64.6651725769043\n",
      "Epoch = 694, ErrG = 39.3627815246582, ErrA = -64.39857864379883, ErrD = -67.77387364705403\n",
      "Epoch = 696, ErrG = 30.177459716796875, ErrA = -70.04319254557292, ErrD = -66.28527069091797\n",
      "Epoch = 698, ErrG = 44.67873764038086, ErrA = -53.09021504720052, ErrD = -73.82306480407715\n",
      "Epoch = 700, ErrG = 52.219940185546875, ErrA = -56.14688364664713, ErrD = -70.73828379313152\n"
     ]
    }
   ],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "margin = 0\n",
    "n_g = 1\n",
    "n_d = 2\n",
    "clip = 0.1\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.RMSprop(netg.parameters(), lr=glr/2)\n",
    "optimD = optim.RMSprop(netd.parameters(), lr=dlr/3)\n",
    "optimA = optim.RMSprop(neta.parameters(), lr=dlr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={},clip={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp, clip))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        if i % n_g==0:\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "    #         label.fill_(real_label)\n",
    "    #         lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD_real1 = -th.mean(output)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "    #         label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "    #         lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD_real2 = -th.mean(output1)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "    #         label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "    #         lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD_fake = th.mean(output2)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            for p in netd.parameters():\n",
    "                p.data.clamp_(-clip, clip)\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "    #         label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "    #         lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA_real1 = -th.mean(output1)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "    #         label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "    #         lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA_real2 = th.mean(output)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "    #         label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "    #         lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA_fake = th.mean(output)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "\n",
    "            for p in neta.parameters():\n",
    "                p.data.clamp_(-clip, clip)\n",
    "\n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossGD = -th.mean(output)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "#             label.fill_(real_label)\n",
    "#             lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossGA = -th.mean(output)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T17:54:50.674179Z",
     "start_time": "2019-06-02T12:25:08.423036Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00002\n",
    "dlr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 10\n",
    "beta1 = 0\n",
    "beta2 = 0.999\n",
    "margin = 0\n",
    "n_g = 0\n",
    "n_d = 5\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        \n",
    "        # update D\n",
    "        if i % n_g==0:\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "    #         label.fill_(real_label)\n",
    "    #         lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD_real1 = -th.mean(output)\n",
    "            lossD_ += lossD_real1\n",
    "            lossD += lossD_real1.item()\n",
    "    #         lossD_real1.backward()\n",
    "\n",
    "    #         label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "    #         lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD_real2 = -th.mean(output1)\n",
    "            lossD_ += lossD_real2\n",
    "            lossD += lossD_real2.item()\n",
    "    #         lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "    #         label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "    #         lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD_fake = th.mean(output2)\n",
    "            lossD_ += lossD_fake\n",
    "            lossD += lossD_fake.item()\n",
    "            gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "    #         lossD_fake.backward()\n",
    "            lossD_ = lossD_/3 + lambda_gp * gradient_penalty\n",
    "            lossD_.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "    #         label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "    #         lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA_real1 = -th.mean(output1)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_ += lossA_real1\n",
    "    #         lossA_real1.backward()\n",
    "\n",
    "    #         label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "    #         lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA_real2 = th.mean(output)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_ += lossA_real2\n",
    "    #         lossA_real2.backward()\n",
    "\n",
    "    #         label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "    #         lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA_fake = th.mean(output)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_ += lossA_fake\n",
    "    #         lossA_fake.backward()\n",
    "            gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3 + lambda_gp * gradient_penalty\n",
    "\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "    \n",
    "            \n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossGD = -th.mean(output)\n",
    "            lossG += lossGD.item()\n",
    "            lossG_ += lossGD\n",
    "#             lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "#             label.fill_(real_label)\n",
    "#             lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossGA = -th.mean(output)\n",
    "            lossG += lossGA.item()\n",
    "            lossG_ += lossGA\n",
    "#             lossGA.backward()\n",
    "            lossG_ = lossG_/2\n",
    "            lossG_.backward(retain_graph=True)\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN (hing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T00:07:22.217162Z",
     "start_time": "2019-06-05T16:58:50.881140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "\n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 10\n",
    "n_g = 2\n",
    "n_d = 1\n",
    "\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            d_out_assreal,dr1 = netd(ass_label)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_assreal\n",
    "            lossD += d_loss_assreal.item()\n",
    "\n",
    "            d_out_noassreal,dr2 = netd(noass_label)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_noassreal\n",
    "            lossD += d_loss_noassreal.item()\n",
    "\n",
    "            fake, gf1 = netg(img)\n",
    "            d_out_fake, df1 = netd(fake.detach())  #需要 detach 因為不希望更新fake的參數\n",
    "            d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "            lossD_ += d_loss_fake\n",
    "            lossD += d_loss_fake.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "            lossD_ = lossD_/3\n",
    "            lossD_.backward()\n",
    "            optimD.step()\n",
    "\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked, gf1 = netg(img)\n",
    "            faked = th.cat((img, faked.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "            d_out_assreal,dr1 = neta(assd)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "            lossA += d_loss_assreal.item()\n",
    "            lossA_ += d_loss_assreal\n",
    "\n",
    "            d_out_noassreal,dr2 = neta(noassd)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "            lossA_ += d_loss_noassreal\n",
    "            lossA += d_loss_noassreal.item()\n",
    "\n",
    "            d_out_faked, df3 = neta(faked)\n",
    "            d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "            lossA_ += d_loss_faked\n",
    "            lossA += d_loss_faked.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "\n",
    "            \n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake,_= netg(img)\n",
    "            g_out_fake,_ = netd(fake)\n",
    "            g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "            lossG += g_loss_fake.item()\n",
    "            lossG_ += g_loss_fake\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            g_out_faked,_ = neta(faked)\n",
    "            g_loss_faked = - g_out_faked.mean()\n",
    "            lossG += g_loss_faked.item()\n",
    "            lossG_ += g_loss_faked\n",
    "\n",
    "            lossG_ = lossG_/2\n",
    "            lossG_.backward(retain_graph=True) ##其實這裡也不需要retain graph 因為他只 backward 一次；\n",
    "            #如果爾後有要再backward，第一次就需要retain graph\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN (WGAN-GP) 刪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T00:07:22.217162Z",
     "start_time": "2019-06-05T16:58:50.881140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "# lr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 0\n",
    "target = '090'\n",
    "lambda_gp = 10\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, dlr, glr, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        \n",
    "        \n",
    "        # update D\n",
    "        lossD = 0\n",
    "        lossD_ = 0\n",
    "        optimD.zero_grad()\n",
    "        d_out_assreal,dr1 = netd(ass_label)\n",
    "        d_loss_assreal = -th.mean(d_out_assreal)\n",
    "\n",
    "        lossD_ += d_loss_assreal\n",
    "        lossD += d_loss_assreal.item()\n",
    "\n",
    "        d_out_noassreal,dr2 = netd(noass_label)\n",
    "        d_loss_noassreal = -th.mean(d_out_noassreal)\n",
    "\n",
    "        lossD_ += d_loss_noassreal\n",
    "        lossD += d_loss_noassreal.item()\n",
    "\n",
    "        fake, gf1 = netg(img)\n",
    "        d_out_fake, df1 = netd(fake.detach())  #需要 detach 因為不希望更新fake的參數\n",
    "        d_loss_fake = th.mean(d_out_fake)\n",
    "\n",
    "        lossD_ += d_loss_fake\n",
    "        lossD += d_loss_fake.item()\n",
    "        gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "        lossD_ = lossD_/3 + lambda_gp * gradient_penalty\n",
    "#         lossD_ = lossD_/3\n",
    "        lossD_.backward()\n",
    "        optimD.step()\n",
    "        \n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        lossA_ = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked, gf1 = netg(img)\n",
    "        faked = th.cat((img, faked.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "        d_out_assreal,dr1 = neta(assd)\n",
    "        d_loss_assreal = -th.mean(d_out_assreal)\n",
    "        lossA += d_loss_assreal.item()\n",
    "        lossA_ += d_loss_assreal\n",
    "\n",
    "        d_out_noassreal,dr2 = neta(noassd)\n",
    "        d_loss_noassreal = th.mean(d_out_noassreal)\n",
    "\n",
    "        lossA_ += d_loss_noassreal\n",
    "        lossA += d_loss_noassreal.item()\n",
    "        \n",
    "        d_out_faked, df3 = neta(faked)\n",
    "        d_loss_faked = th.mean(d_out_faked)\n",
    "\n",
    "        lossA_ += d_loss_faked\n",
    "        lossA += d_loss_faked.item()\n",
    "        gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "        lossA_ = lossA_/3 + lambda_gp * gradient_penalty\n",
    "#         lossA_ = lossA_/3\n",
    "        lossA_.backward()\n",
    "        optimA.step()\n",
    "\n",
    "            \n",
    "        # update G\n",
    "#         if i % n_critic == 0:\n",
    "        lossG = 0\n",
    "        lossG_ = 0\n",
    "        optimG.zero_grad()\n",
    "        fake,_= netg(img)\n",
    "        g_out_fake,_ = netd(fake)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "        lossG += g_loss_fake.item()\n",
    "        lossG_ += g_loss_fake\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        g_out_faked,_ = neta(faked)\n",
    "        g_loss_faked = - g_out_faked.mean()\n",
    "        lossG += g_loss_faked.item()\n",
    "        lossG_ += g_loss_faked\n",
    "        \n",
    "        lossG_ = lossG_/2\n",
    "        lossG_.backward(retain_graph=True) ##其實這裡也不需要retain graph 因為他只 backward 一次；\n",
    "        #如果爾後有要再backward，第一次就需要retain graph\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN and triplet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-14T06:10:06.319Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 5\n",
    "n_g = 2\n",
    "n_d = 1\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "\n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            d_out_assreal,dr1 = netd(ass_label)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_assreal\n",
    "            lossD += d_loss_assreal.item()\n",
    "\n",
    "            d_out_noassreal,dr2 = netd(noass_label)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_noassreal\n",
    "            lossD += d_loss_noassreal.item()\n",
    "\n",
    "            fake, code = netg(img)\n",
    "            d_out_fake, df1 = netd(fake.detach())\n",
    "            d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "            lossD_ += d_loss_fake\n",
    "            lossD += d_loss_fake.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "            lossD_ = lossD_/3\n",
    "            lossD_.backward()\n",
    "            optimD.step()\n",
    "\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked, code = netg(img)\n",
    "            faked = th.cat((img, faked.detach()), 1)\n",
    "\n",
    "            d_out_assreal,dr1 = neta(assd)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "            lossA += d_loss_assreal.item()\n",
    "            lossA_ += d_loss_assreal\n",
    "\n",
    "            d_out_noassreal,dr2 = neta(noassd)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "            lossA_ += d_loss_noassreal\n",
    "            lossA += d_loss_noassreal.item()\n",
    "\n",
    "            d_out_faked, df3 = neta(faked)\n",
    "            d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "            lossA_ += d_loss_faked\n",
    "            lossA += d_loss_faked.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "\n",
    "            \n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake, A= netg(img)\n",
    "            g_out_fake,_ = netd(fake)\n",
    "            g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "            lossG += g_loss_fake.item()\n",
    "            lossG_ += g_loss_fake\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            g_out_faked,_ = neta(faked)\n",
    "            g_loss_faked = - g_out_faked.mean()\n",
    "            lossG += g_loss_faked.item()\n",
    "            lossG_ += g_loss_faked\n",
    "\n",
    "            # constrain on generator\n",
    "            fake_ass, P = netg(ass_img)\n",
    "            fake_noass, N = netg(noass_img)\n",
    "            lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "            lossG_ += lossTriplet\n",
    "            lossG += lossTriplet.item()\n",
    "    #         lossTriplet.backward()\n",
    "\n",
    "            lossG_ = lossG_/3\n",
    "            lossG_.backward(retain_graph=True)\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrTri = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/3,lossTriplet.item(), lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/3)<low_loss:  \n",
    "        low_loss = lossG/3\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN and triplet (onlineloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T23:19:14.248633Z",
     "start_time": "2019-08-14T06:36:41.424970Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 2.2715400755405426, ErrTri = 5.083058834075928, ErrA = 0.6132369836171468, ErrD = 0.42663437128067017, Gattn=-0.004093634895980358, Dattn=0.001592523418366909, Aattn=-0.00026734417770057917\n",
      "Epoch = 4, ErrG = 1.7833725412686665, ErrTri = 3.355182647705078, ErrA = 0.6522229413191477, ErrD = 0.2876933229466279, Gattn=-0.007606056518852711, Dattn=0.002421888057142496, Aattn=-0.0007175184437073767\n",
      "Epoch = 6, ErrG = 1.9610540866851807, ErrTri = 3.2841928005218506, ErrA = 0.45963972186048824, ErrD = 0.16932998845974603, Gattn=-0.00994974933564663, Dattn=0.005251366179436445, Aattn=-0.0009563870844431221\n",
      "Epoch = 8, ErrG = 1.4270671606063843, ErrTri = 4.645321846008301, ErrA = 0.5926398995021979, ErrD = 0.7014000614484152, Gattn=-0.01099950261414051, Dattn=0.007787586655467749, Aattn=-0.0012496927520260215\n",
      "Epoch = 10, ErrG = 1.543796221415202, ErrTri = 2.5261430740356445, ErrA = 0.5080581406752268, ErrD = 0.30035173892974854, Gattn=-0.012077202089130878, Dattn=0.012305780313909054, Aattn=-0.00128466438036412\n",
      "Epoch = 12, ErrG = 1.7697088917096455, ErrTri = 3.805628538131714, ErrA = 0.49086254338423413, ErrD = 0.2221374325454235, Gattn=-0.012591016478836536, Dattn=0.015234588645398617, Aattn=-0.00194125238340348\n",
      "Epoch = 14, ErrG = 1.104662338892619, ErrTri = 1.6856032609939575, ErrA = 0.5005549751222134, ErrD = 0.2888052761554718, Gattn=-0.012911651283502579, Dattn=0.01714904233813286, Aattn=-0.002860965672880411\n",
      "Epoch = 16, ErrG = 1.97878893216451, ErrTri = 2.7269628047943115, ErrA = 0.3414329377313455, ErrD = 0.2978650648146868, Gattn=-0.013122317381203175, Dattn=0.018656151369214058, Aattn=-0.004118777345865965\n",
      "Epoch = 18, ErrG = 1.4065099557240803, ErrTri = 2.1376070976257324, ErrA = 0.36079642300804454, ErrD = 0.08096045255661011, Gattn=-0.013334950432181358, Dattn=0.019822437316179276, Aattn=-0.005914159119129181\n",
      "Epoch = 20, ErrG = 1.3092095851898193, ErrTri = 1.7701442241668701, ErrA = 0.5943408459424973, ErrD = 0.3100143373012543, Gattn=-0.013652624562382698, Dattn=0.02110111340880394, Aattn=-0.007232921198010445\n",
      "Epoch = 22, ErrG = 1.3150549332300823, ErrTri = 1.5688968896865845, ErrA = 0.4804811179637909, ErrD = 0.19056323915719986, Gattn=-0.013762210495769978, Dattn=0.0219731442630291, Aattn=-0.009699796326458454\n",
      "Epoch = 24, ErrG = 0.8498990734418234, ErrTri = 1.9841344356536865, ErrA = 0.5075375884771347, ErrD = 0.5705382327238718, Gattn=-0.014048108831048012, Dattn=0.02418413758277893, Aattn=-0.010834275744855404\n",
      "Epoch = 26, ErrG = 0.557301382223765, ErrTri = 1.1957471370697021, ErrA = 0.5401498644302288, ErrD = 0.5722872366507848, Gattn=-0.014156290329992771, Dattn=0.024990161880850792, Aattn=-0.014040886424481869\n",
      "Epoch = 28, ErrG = 0.5793416897455851, ErrTri = 1.343164324760437, ErrA = 0.44649993379910785, ErrD = 0.34247079491615295, Gattn=-0.014226405881345272, Dattn=0.02570798061788082, Aattn=-0.018422678112983704\n",
      "Epoch = 30, ErrG = 0.7511728803316752, ErrTri = 1.151909351348877, ErrA = 0.3636628035455942, ErrD = 0.6560888290405273, Gattn=-0.01431040745228529, Dattn=0.026352861896157265, Aattn=-0.022672129794955254\n",
      "Epoch = 32, ErrG = 1.420160969098409, ErrTri = 2.7578468322753906, ErrA = 0.48338694373766583, ErrD = 0.340662216146787, Gattn=-0.014411158859729767, Dattn=0.027043331414461136, Aattn=-0.027297023683786392\n",
      "Epoch = 34, ErrG = 1.374942938486735, ErrTri = 2.119649887084961, ErrA = 0.403875599304835, ErrD = 0.3519297738869985, Gattn=-0.014473499730229378, Dattn=0.027831105515360832, Aattn=-0.031126298010349274\n",
      "Epoch = 36, ErrG = 0.7557784914970398, ErrTri = 1.5045619010925293, ErrA = 0.3501877337694168, ErrD = 0.5182226486504078, Gattn=-0.014585960656404495, Dattn=0.0283876471221447, Aattn=-0.03379673510789871\n",
      "Epoch = 38, ErrG = 0.8006824056307474, ErrTri = 1.2320375442504883, ErrA = 0.34020843108495075, ErrD = 0.42215760548909503, Gattn=-0.01462472416460514, Dattn=0.029138434678316116, Aattn=-0.036125242710113525\n",
      "Epoch = 40, ErrG = 1.0373308459917705, ErrTri = 1.506937026977539, ErrA = 0.39611854155858356, ErrD = 0.33928883261978626, Gattn=-0.014661592431366444, Dattn=0.029913412407040596, Aattn=-0.037797149270772934\n",
      "Epoch = 42, ErrG = 1.2005917231241863, ErrTri = 1.3543875217437744, ErrA = 0.5555209529896578, ErrD = 0.5603416363398234, Gattn=-0.01472871471196413, Dattn=0.030541472136974335, Aattn=-0.03920825943350792\n",
      "Epoch = 44, ErrG = 1.374739408493042, ErrTri = 1.0097604990005493, ErrA = 0.3613599936167399, ErrD = 0.21670731281240782, Gattn=-0.014760744757950306, Dattn=0.03129313886165619, Aattn=-0.04046304523944855\n",
      "Epoch = 46, ErrG = 0.7443103529512882, ErrTri = 1.2623645067214966, ErrA = 0.39468519886334735, ErrD = 0.33693955714503926, Gattn=-0.014803997240960598, Dattn=0.032011888921260834, Aattn=-0.04018842801451683\n",
      "Epoch = 48, ErrG = 0.7714298665523529, ErrTri = 1.2990612983703613, ErrA = 0.4470579115053018, ErrD = 0.3326249619325002, Gattn=-0.014760484918951988, Dattn=0.03292534127831459, Aattn=-0.04046672582626343\n",
      "Epoch = 50, ErrG = 1.2728465000788372, ErrTri = 1.3275513648986816, ErrA = 0.39092234273751575, ErrD = 0.24520209431648254, Gattn=-0.014715905301272869, Dattn=0.03380582109093666, Aattn=-0.04193722456693649\n",
      "Epoch = 52, ErrG = 0.9295827547709147, ErrTri = 0.908836841583252, ErrA = 0.4985231359799703, ErrD = 0.22196205394963422, Gattn=-0.014658029191195965, Dattn=0.03459654003381729, Aattn=-0.043493036180734634\n",
      "Epoch = 54, ErrG = 0.3277144432067871, ErrTri = 1.082836627960205, ErrA = 0.6684496651093165, ErrD = 0.6955581381917, Gattn=-0.014967733062803745, Dattn=0.03441764414310455, Aattn=-0.043620381504297256\n",
      "Epoch = 56, ErrG = 0.39376624425252277, ErrTri = 1.1172734498977661, ErrA = 0.6700271504620711, ErrD = 0.6819193263848623, Gattn=-0.015259325504302979, Dattn=0.03409421816468239, Aattn=-0.044338442385196686\n",
      "Epoch = 58, ErrG = 0.20009928941726685, ErrTri = 0.7898173332214355, ErrA = 0.6645360241333643, ErrD = 0.6746065318584442, Gattn=-0.015390989370644093, Dattn=0.03417036682367325, Aattn=-0.04487418755888939\n",
      "Epoch = 60, ErrG = 0.32970281442006427, ErrTri = 1.0160781145095825, ErrA = 0.6682419540981451, ErrD = 0.6674956530332565, Gattn=-0.015505027957260609, Dattn=0.034389931708574295, Aattn=-0.04541739076375961\n",
      "Epoch = 62, ErrG = 0.30157562096913654, ErrTri = 0.8996591567993164, ErrA = 0.6625726968050003, ErrD = 0.6655733324587345, Gattn=-0.015608176589012146, Dattn=0.03493129834532738, Aattn=-0.04592736065387726\n",
      "Epoch = 64, ErrG = 0.21882830063501993, ErrTri = 0.7579072713851929, ErrA = 0.6586519194145998, ErrD = 0.6569057106971741, Gattn=-0.015672123059630394, Dattn=0.035875823348760605, Aattn=-0.046711694449186325\n",
      "Epoch = 66, ErrG = 0.17864391207695007, ErrTri = 0.3846442401409149, ErrA = 0.6302086170762777, ErrD = 0.6344319637864828, Gattn=-0.015675563365221024, Dattn=0.03768102824687958, Aattn=-0.04798946529626846\n",
      "Epoch = 68, ErrG = 0.054340640703837075, ErrTri = 0.599214494228363, ErrA = 0.6492720128347477, ErrD = 0.6484383145968119, Gattn=-0.015672681853175163, Dattn=0.0404432937502861, Aattn=-0.04932662099599838\n",
      "Epoch = 70, ErrG = 0.5448504090309143, ErrTri = 1.5324223041534424, ErrA = 0.6673624217510223, ErrD = 0.652901311715444, Gattn=-0.0156463123857975, Dattn=0.04466031491756439, Aattn=-0.05071572586894035\n",
      "Epoch = 72, ErrG = 0.42646825313568115, ErrTri = 1.090388536453247, ErrA = 0.6452656866361698, ErrD = 0.5745788117249807, Gattn=-0.015612912364304066, Dattn=0.049299273639917374, Aattn=-0.05195194110274315\n",
      "Epoch = 74, ErrG = 0.5774262795845667, ErrTri = 1.0233244895935059, ErrA = 0.6728042364120483, ErrD = 0.5660516967376074, Gattn=-0.015575423836708069, Dattn=0.05269971117377281, Aattn=-0.05365803465247154\n",
      "Epoch = 76, ErrG = 0.4500746826330821, ErrTri = 0.7655702829360962, ErrA = 0.6650720996161302, ErrD = 0.48123831550280255, Gattn=-0.01553872786462307, Dattn=0.05456489697098732, Aattn=-0.05451228469610214\n",
      "Epoch = 78, ErrG = 0.32213375469048816, ErrTri = 0.8336507678031921, ErrA = 0.5902708973735571, ErrD = 0.5193424572547277, Gattn=-0.015499774366617203, Dattn=0.05565783381462097, Aattn=-0.05524015799164772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 80, ErrG = 0.16324423253536224, ErrTri = 0.1723148375749588, ErrA = 0.6422685086727142, ErrD = 0.7343462308247884, Gattn=-0.015465529635548592, Dattn=0.056657616049051285, Aattn=-0.056079816073179245\n",
      "Epoch = 82, ErrG = 0.14485337336858115, ErrTri = 0.376237154006958, ErrA = 0.6128157911201318, ErrD = 0.7411962455759445, Gattn=-0.015439232811331749, Dattn=0.057298894971609116, Aattn=-0.056913718581199646\n",
      "Epoch = 84, ErrG = 0.6435860842466354, ErrTri = 1.2766661643981934, ErrA = 0.5652037287751833, ErrD = 0.5232811619838079, Gattn=-0.015394429676234722, Dattn=0.058205462992191315, Aattn=-0.05740742012858391\n",
      "Epoch = 86, ErrG = 0.22223674257596335, ErrTri = 0.17306575179100037, ErrA = 0.642295648654302, ErrD = 0.44923944274584454, Gattn=-0.015399002470076084, Dattn=0.058931659907102585, Aattn=-0.05772387981414795\n",
      "Epoch = 88, ErrG = 0.09850436449050903, ErrTri = 0.8105394244194031, ErrA = 0.5753927466770014, ErrD = 0.47322752078374225, Gattn=-0.01538153737783432, Dattn=0.05951492860913277, Aattn=-0.05818653479218483\n",
      "Epoch = 90, ErrG = 0.14123672246932983, ErrTri = 0.5408245325088501, ErrA = 0.6353301039586464, ErrD = 0.6877944674342871, Gattn=-0.015368267893791199, Dattn=0.05999474227428436, Aattn=-0.058539509773254395\n",
      "Epoch = 92, ErrG = 0.8051532904307047, ErrTri = 0.615996778011322, ErrA = 0.6265609289209048, ErrD = 0.4891430449982484, Gattn=-0.015363280661404133, Dattn=0.060760896652936935, Aattn=-0.05875391885638237\n",
      "Epoch = 94, ErrG = 0.28590712944666546, ErrTri = 0.6029624938964844, ErrA = 0.6576341539621353, ErrD = 0.536126712958018, Gattn=-0.015336364507675171, Dattn=0.06151002645492554, Aattn=-0.05911986902356148\n",
      "Epoch = 96, ErrG = 0.2445660432179769, ErrTri = 0.5623753666877747, ErrA = 0.6371873393654823, ErrD = 0.5611653352777163, Gattn=-0.015337477438151836, Dattn=0.06186012551188469, Aattn=-0.05972364544868469\n",
      "Epoch = 98, ErrG = 0.26113007465998334, ErrTri = 0.41186028718948364, ErrA = 0.5814671417077383, ErrD = 0.4712649683157603, Gattn=-0.01531907171010971, Dattn=0.06262600421905518, Aattn=-0.060132965445518494\n",
      "Epoch = 100, ErrG = -0.042803339660167694, ErrTri = 0.5484031438827515, ErrA = 0.6427290886640549, ErrD = 0.7615688803295294, Gattn=-0.01530054397881031, Dattn=0.06311657279729843, Aattn=-0.06042017042636871\n",
      "Epoch = 102, ErrG = 0.19579566766818365, ErrTri = 0.5798083543777466, ErrA = 0.5907939535876116, ErrD = 0.6453137372930845, Gattn=-0.015298035927116871, Dattn=0.06374257802963257, Aattn=-0.06081516295671463\n",
      "Epoch = 104, ErrG = 0.2870841821034749, ErrTri = 0.44368112087249756, ErrA = 0.6708178023497263, ErrD = 0.5112595558166504, Gattn=-0.0152925755828619, Dattn=0.06440182030200958, Aattn=-0.061145178973674774\n",
      "Epoch = 106, ErrG = 0.0763171414534251, ErrTri = 0.48309746384620667, ErrA = 0.6082671669622263, ErrD = 0.6586891710758209, Gattn=-0.015284717082977295, Dattn=0.06501597166061401, Aattn=-0.06166459619998932\n",
      "Epoch = 108, ErrG = -0.07045011719067891, ErrTri = 0.5668495893478394, ErrA = 0.5404824124028286, ErrD = 0.5694275883336862, Gattn=-0.015262805856764317, Dattn=0.06552331894636154, Aattn=-0.062087900936603546\n",
      "Epoch = 110, ErrG = 0.7154130736986796, ErrTri = 0.3476652204990387, ErrA = 0.62029347072045, ErrD = 0.4722959976643324, Gattn=-0.015256333164870739, Dattn=0.06644340604543686, Aattn=-0.06242986023426056\n",
      "Epoch = 112, ErrG = 0.14254555106163025, ErrTri = 0.7265312075614929, ErrA = 0.6421108245849609, ErrD = 0.6537996406356493, Gattn=-0.015271162614226341, Dattn=0.06697826087474823, Aattn=-0.06283211708068848\n",
      "Epoch = 114, ErrG = 0.12779133518536887, ErrTri = 0.389839231967926, ErrA = 0.5448601730167866, ErrD = 0.5838657114654779, Gattn=-0.01527754683047533, Dattn=0.0676736980676651, Aattn=-0.06320428103208542\n",
      "Epoch = 116, ErrG = 0.3850387632846832, ErrTri = 0.8660838603973389, ErrA = 0.6157282541195551, ErrD = 0.5361028040448824, Gattn=-0.01525563932955265, Dattn=0.06818436086177826, Aattn=-0.06353943049907684\n",
      "Epoch = 118, ErrG = 0.4566236734390259, ErrTri = 1.1684951782226562, ErrA = 0.616627869506677, ErrD = 0.5115981300671896, Gattn=-0.015272841788828373, Dattn=0.06868978589773178, Aattn=-0.06375385820865631\n",
      "Epoch = 120, ErrG = 0.3099495718876521, ErrTri = 0.4496859312057495, ErrA = 0.5413453181584676, ErrD = 0.5863323373099169, Gattn=-0.015282973647117615, Dattn=0.0693930834531784, Aattn=-0.06424372643232346\n",
      "Epoch = 122, ErrG = 0.11058348417282104, ErrTri = 0.4965706467628479, ErrA = 0.6771234075228373, ErrD = 0.5320541659990946, Gattn=-0.015289991162717342, Dattn=0.06997384130954742, Aattn=-0.0646408274769783\n",
      "Epoch = 124, ErrG = 0.17585885028044382, ErrTri = 0.14162079989910126, ErrA = 0.5991226236025492, ErrD = 0.6442650159200033, Gattn=-0.015275455079972744, Dattn=0.07056449353694916, Aattn=-0.0649995282292366\n",
      "Epoch = 126, ErrG = 0.0161019762357076, ErrTri = 0.31228697299957275, ErrA = 0.579600527882576, ErrD = 0.5321324119965235, Gattn=-0.015273915603756905, Dattn=0.07124682515859604, Aattn=-0.06529872864484787\n",
      "Epoch = 128, ErrG = 0.5096640189488729, ErrTri = 0.5555487871170044, ErrA = 0.5533192666868368, ErrD = 0.31953819406529266, Gattn=-0.015265176072716713, Dattn=0.07199272513389587, Aattn=-0.06568332761526108\n",
      "Epoch = 130, ErrG = 0.1854250133037567, ErrTri = 0.49481120705604553, ErrA = 0.6193217411637306, ErrD = 0.5399714708328247, Gattn=-0.015278161503374577, Dattn=0.07246231287717819, Aattn=-0.06584491580724716\n",
      "Epoch = 132, ErrG = -0.15731302897135416, ErrTri = 0.3077930212020874, ErrA = 0.6374190604935089, ErrD = 0.7081065773963928, Gattn=-0.01526277232915163, Dattn=0.07318872213363647, Aattn=-0.0662211999297142\n",
      "Epoch = 134, ErrG = 0.1372621456782023, ErrTri = 0.7578186392784119, ErrA = 0.604576456050078, ErrD = 0.46949176987012226, Gattn=-0.015255472622811794, Dattn=0.0736939013004303, Aattn=-0.06656741350889206\n",
      "Epoch = 136, ErrG = 0.21499621868133545, ErrTri = 0.6235836744308472, ErrA = 0.5855174797276655, ErrD = 0.5929060777028402, Gattn=-0.015273505821824074, Dattn=0.07428060472011566, Aattn=-0.06693481653928757\n",
      "Epoch = 138, ErrG = 0.5886767394840717, ErrTri = 0.6559474468231201, ErrA = 0.6027825723091761, ErrD = 0.5730953104794025, Gattn=-0.015261566266417503, Dattn=0.07488489151000977, Aattn=-0.0674310177564621\n",
      "Epoch = 140, ErrG = -0.10873975356419881, ErrTri = 0.30155882239341736, ErrA = 0.5806208793073893, ErrD = 0.6281997958819071, Gattn=-0.015269880183041096, Dattn=0.07539818435907364, Aattn=-0.0677768737077713\n",
      "Epoch = 142, ErrG = 0.5375747481981913, ErrTri = 0.2746420204639435, ErrA = 0.5600285728772482, ErrD = 0.4952175555129846, Gattn=-0.015257085673511028, Dattn=0.0759941041469574, Aattn=-0.06834153085947037\n",
      "Epoch = 144, ErrG = 0.11595913767814636, ErrTri = 0.30325719714164734, ErrA = 0.614875229075551, ErrD = 0.6075024654467901, Gattn=-0.015269547700881958, Dattn=0.07652945071458817, Aattn=-0.06870396435260773\n",
      "Epoch = 146, ErrG = 0.6362463335196177, ErrTri = 0.39897802472114563, ErrA = 0.7386334339777628, ErrD = 0.538054566209515, Gattn=-0.01527584157884121, Dattn=0.07706545293331146, Aattn=-0.06917440891265869\n",
      "Epoch = 148, ErrG = 0.3857189789414406, ErrTri = 0.5170737504959106, ErrA = 0.5881721042096615, ErrD = 0.5721307601779699, Gattn=-0.015265176072716713, Dattn=0.07763446122407913, Aattn=-0.06959331780672073\n",
      "Epoch = 150, ErrG = 0.6294700503349304, ErrTri = 0.3067023754119873, ErrA = 0.49591173231601715, ErrD = 0.4589670275648435, Gattn=-0.015249458141624928, Dattn=0.07833177596330643, Aattn=-0.06997577100992203\n",
      "Epoch = 152, ErrG = 0.6302967965602875, ErrTri = 0.2555418312549591, ErrA = 0.5430759893109401, ErrD = 0.40806538984179497, Gattn=-0.01526019535958767, Dattn=0.07892882823944092, Aattn=-0.07043353468179703\n",
      "Epoch = 154, ErrG = 0.3297751744588216, ErrTri = 0.4000018239021301, ErrA = 0.5140053456028303, ErrD = 0.5615311569223801, Gattn=-0.015258925966918468, Dattn=0.07937051355838776, Aattn=-0.07083610445261002\n",
      "Epoch = 156, ErrG = 0.5995687792698542, ErrTri = 0.17134015262126923, ErrA = 0.6274638076623281, ErrD = 0.5126518631974856, Gattn=-0.015246540307998657, Dattn=0.07998911291360855, Aattn=-0.07126554846763611\n",
      "Epoch = 158, ErrG = 0.7237183650334676, ErrTri = 0.4569516181945801, ErrA = 0.48851581787069637, ErrD = 0.3570431023836136, Gattn=-0.015230816788971424, Dattn=0.08058872073888779, Aattn=-0.07192740589380264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 160, ErrG = 0.2165762037038803, ErrTri = 0.1756746619939804, ErrA = 0.5081679473320643, ErrD = 0.47634710371494293, Gattn=-0.0152118019759655, Dattn=0.08104931563138962, Aattn=-0.07209422439336777\n",
      "Epoch = 162, ErrG = 0.2731326222419739, ErrTri = 0.4268786907196045, ErrA = 0.51544588804245, ErrD = 0.6217548524339994, Gattn=-0.015214385464787483, Dattn=0.0815313458442688, Aattn=-0.07256826013326645\n",
      "Epoch = 164, ErrG = 0.45817799121141434, ErrTri = 0.37459129095077515, ErrA = 0.6018440673748652, ErrD = 0.6496713428447644, Gattn=-0.015200850553810596, Dattn=0.08200043439865112, Aattn=-0.0729425698518753\n",
      "Epoch = 166, ErrG = 0.04504639903704325, ErrTri = 0.30640488862991333, ErrA = 0.5552511215209961, ErrD = 0.5583118001619974, Gattn=-0.015203678049147129, Dattn=0.08249927312135696, Aattn=-0.07338415831327438\n",
      "Epoch = 168, ErrG = 0.6910771330197653, ErrTri = 0.2950499653816223, ErrA = 0.578738946467638, ErrD = 0.31170251220464706, Gattn=-0.015208196826279163, Dattn=0.08314571529626846, Aattn=-0.07367577403783798\n",
      "Epoch = 170, ErrG = 0.3878878057003021, ErrTri = 0.2530393898487091, ErrA = 0.5836740763237079, ErrD = 0.37766435742378235, Gattn=-0.015211396850645542, Dattn=0.08354408293962479, Aattn=-0.07401009649038315\n",
      "Epoch = 172, ErrG = 0.27112911144892377, ErrTri = 0.6575837731361389, ErrA = 0.5789895181854566, ErrD = 0.559065580368042, Gattn=-0.015210931189358234, Dattn=0.08408916741609573, Aattn=-0.07453534007072449\n",
      "Epoch = 174, ErrG = 0.11861933519442876, ErrTri = 0.12301317602396011, ErrA = 0.5284921762843927, ErrD = 0.37898536523183185, Gattn=-0.015201077796518803, Dattn=0.0845772996544838, Aattn=-0.07473385334014893\n",
      "Epoch = 176, ErrG = -0.009825398524602255, ErrTri = 0.3795609176158905, ErrA = 0.520849738890926, ErrD = 0.6690792838732401, Gattn=-0.01521455217152834, Dattn=0.08506723493337631, Aattn=-0.0751839131116867\n",
      "Epoch = 178, ErrG = 0.3002997773389022, ErrTri = 0.3381330966949463, ErrA = 0.47315245556334656, ErrD = 0.5870775766670704, Gattn=-0.015207997523248196, Dattn=0.0855690985918045, Aattn=-0.07571126520633698\n",
      "Epoch = 180, ErrG = 0.8340575248003006, ErrTri = 0.21832869946956635, ErrA = 0.6040003796418508, ErrD = 0.3543731775134802, Gattn=-0.015211271122097969, Dattn=0.08621516078710556, Aattn=-0.07612812519073486\n",
      "Epoch = 182, ErrG = 0.033567299445470176, ErrTri = 0.6420638561248779, ErrA = 0.5306653299679359, ErrD = 0.4090968767801921, Gattn=-0.01520334742963314, Dattn=0.0865599662065506, Aattn=-0.07660076022148132\n",
      "Epoch = 184, ErrG = -0.11857303480307262, ErrTri = 0.4094715118408203, ErrA = 0.5246886356423298, ErrD = 0.6534458051125208, Gattn=-0.015201828442513943, Dattn=0.08700889348983765, Aattn=-0.0771939605474472\n",
      "Epoch = 186, ErrG = 0.5844931999842325, ErrTri = 0.27696889638900757, ErrA = 0.6250879913568497, ErrD = 0.3751033867398898, Gattn=-0.01520330086350441, Dattn=0.08746983110904694, Aattn=-0.07743547111749649\n",
      "Epoch = 188, ErrG = -0.033707390228907265, ErrTri = 0.44042065739631653, ErrA = 0.593727570027113, ErrD = 0.9661289875706037, Gattn=-0.01521291583776474, Dattn=0.08776798844337463, Aattn=-0.07797432690858841\n",
      "Epoch = 190, ErrG = 0.6589421878258387, ErrTri = 0.21124674379825592, ErrA = 0.5430294921000799, ErrD = 0.2886561577518781, Gattn=-0.015219191089272499, Dattn=0.08822882175445557, Aattn=-0.07842978835105896\n",
      "Epoch = 192, ErrG = 0.36355816076199216, ErrTri = 0.24428510665893555, ErrA = 0.5788418004910151, ErrD = 0.5897358947743973, Gattn=-0.01521120872348547, Dattn=0.08879412710666656, Aattn=-0.07877184450626373\n",
      "Epoch = 194, ErrG = 0.5890447994073232, ErrTri = 0.22608759999275208, ErrA = 0.5762416074673334, ErrD = 0.5044537534316381, Gattn=-0.015192471444606781, Dattn=0.08924958854913712, Aattn=-0.07924860715866089\n",
      "Epoch = 196, ErrG = 0.22018962601820627, ErrTri = 0.05336551368236542, ErrA = 0.5093347690999508, ErrD = 0.5558730270713568, Gattn=-0.015193345956504345, Dattn=0.08974073827266693, Aattn=-0.0796557143330574\n",
      "Epoch = 198, ErrG = 0.3121645425756772, ErrTri = 0.28954583406448364, ErrA = 0.5744829699397087, ErrD = 0.6305847565333048, Gattn=-0.015165216289460659, Dattn=0.0901949554681778, Aattn=-0.08013856410980225\n",
      "Epoch = 200, ErrG = 0.0784485936164856, ErrTri = 0.4306063652038574, ErrA = 0.5484879165887833, ErrD = 0.7049727439880371, Gattn=-0.015160585753619671, Dattn=0.09064513444900513, Aattn=-0.08069786429405212\n",
      "Epoch = 202, ErrG = 0.42875627242028713, ErrTri = 0.39116573333740234, ErrA = 0.4732629458109538, ErrD = 0.42761648694674176, Gattn=-0.015197483822703362, Dattn=0.09109567850828171, Aattn=-0.0811542496085167\n",
      "Epoch = 204, ErrG = 0.049827367067337036, ErrTri = 0.1961662471294403, ErrA = 0.6994186143080393, ErrD = 0.3771415054798126, Gattn=-0.015182938426733017, Dattn=0.09149618446826935, Aattn=-0.08161309361457825\n",
      "Epoch = 206, ErrG = 0.6667334934075674, ErrTri = 0.2830545902252197, ErrA = 0.5020355420807997, ErrD = 0.4248722642660141, Gattn=-0.015188141725957394, Dattn=0.09211412817239761, Aattn=-0.08206741511821747\n",
      "Epoch = 208, ErrG = 0.6082857052485148, ErrTri = 0.3163592219352722, ErrA = 0.5226360702266296, ErrD = 0.19365367541710535, Gattn=-0.015175565145909786, Dattn=0.09264129400253296, Aattn=-0.08252518624067307\n",
      "Epoch = 210, ErrG = -0.02944043775399526, ErrTri = 0.17636138200759888, ErrA = 0.5609461714824041, ErrD = 0.3977404336134593, Gattn=-0.015142751857638359, Dattn=0.09302167594432831, Aattn=-0.08284369856119156\n",
      "Epoch = 212, ErrG = 0.562248299519221, ErrTri = 0.22266855835914612, ErrA = 0.49680841465791065, ErrD = 0.43175166348616284, Gattn=-0.015150944702327251, Dattn=0.09348191320896149, Aattn=-0.08343382179737091\n",
      "Epoch = 214, ErrG = 0.6006235480308533, ErrTri = 0.5059645175933838, ErrA = 0.4662244189530611, ErrD = 0.2365887283037106, Gattn=-0.01513030007481575, Dattn=0.09389462321996689, Aattn=-0.083931565284729\n",
      "Epoch = 216, ErrG = 0.3590761621793111, ErrTri = 0.2139693796634674, ErrA = 0.4703623453776042, ErrD = 0.4376467913389206, Gattn=-0.015129106119275093, Dattn=0.09431300312280655, Aattn=-0.08431027084589005\n",
      "Epoch = 218, ErrG = 0.4509394367535909, ErrTri = 0.337044894695282, ErrA = 0.41622755738596123, ErrD = 0.5552435715993246, Gattn=-0.015127984806895256, Dattn=0.09472253918647766, Aattn=-0.0849052295088768\n",
      "Epoch = 220, ErrG = 0.4583948105573654, ErrTri = 0.21627391874790192, ErrA = 0.48891234397888184, ErrD = 0.401474899922808, Gattn=-0.015111674554646015, Dattn=0.09503916651010513, Aattn=-0.08524683117866516\n",
      "Epoch = 222, ErrG = 0.36887140572071075, ErrTri = 0.2825430929660797, ErrA = 0.606881865610679, ErrD = 0.5399080887436867, Gattn=-0.015103694051504135, Dattn=0.09543667733669281, Aattn=-0.08566171675920486\n",
      "Epoch = 224, ErrG = 0.3832309941450755, ErrTri = 0.285992294549942, ErrA = 0.4291118582089742, ErrD = 0.27480971813201904, Gattn=-0.015118058770895004, Dattn=0.09582249075174332, Aattn=-0.08621907979249954\n",
      "Epoch = 226, ErrG = 0.009099334478378296, ErrTri = 0.3523395359516144, ErrA = 0.514743234962225, ErrD = 0.7338621318340302, Gattn=-0.015113495290279388, Dattn=0.09618818759918213, Aattn=-0.08680175244808197\n",
      "Epoch = 228, ErrG = 0.30653010805447894, ErrTri = 0.2386711835861206, ErrA = 0.3906905862192313, ErrD = 0.4970056563615799, Gattn=-0.015108678489923477, Dattn=0.09670231491327286, Aattn=-0.08720777928829193\n",
      "Epoch = 230, ErrG = 0.23106606801350912, ErrTri = 0.29570767283439636, ErrA = 0.5476596554120382, ErrD = 0.4728366533915202, Gattn=-0.015111143700778484, Dattn=0.09708714485168457, Aattn=-0.08752667158842087\n",
      "Epoch = 232, ErrG = 0.31025831401348114, ErrTri = 0.27725309133529663, ErrA = 0.5501071910063425, ErrD = 0.5078900257746378, Gattn=-0.015089758671820164, Dattn=0.09760154783725739, Aattn=-0.08786259591579437\n",
      "Epoch = 234, ErrG = 0.25371860588590306, ErrTri = 0.05481475964188576, ErrA = 0.42090739620228607, ErrD = 0.5334909148514271, Gattn=-0.015075623989105225, Dattn=0.09809771925210953, Aattn=-0.08856309205293655\n",
      "Epoch = 236, ErrG = 0.5030658940474192, ErrTri = 0.1811472475528717, ErrA = 0.4951425790786743, ErrD = 0.37944118678569794, Gattn=-0.015051905997097492, Dattn=0.09850277751684189, Aattn=-0.08910799026489258\n",
      "Epoch = 238, ErrG = 0.19624072313308716, ErrTri = 0.6682636737823486, ErrA = 0.5263769427935282, ErrD = 0.6879835923512777, Gattn=-0.01506212167441845, Dattn=0.09890423715114594, Aattn=-0.08952382206916809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 240, ErrG = 0.4526013682285945, ErrTri = 0.19783402979373932, ErrA = 0.48766593138376874, ErrD = 0.3891867697238922, Gattn=-0.015054885298013687, Dattn=0.09935171902179718, Aattn=-0.08996959030628204\n",
      "Epoch = 242, ErrG = 0.3864154815673828, ErrTri = 0.17907527089118958, ErrA = 0.41329756875832874, ErrD = 0.4193260173002879, Gattn=-0.01504947617650032, Dattn=0.09979476034641266, Aattn=-0.09050522744655609\n",
      "Epoch = 244, ErrG = 0.6113575994968414, ErrTri = 0.31043198704719543, ErrA = 0.4071834360559781, ErrD = 0.38404718848566216, Gattn=-0.015036088414490223, Dattn=0.10009735822677612, Aattn=-0.0911499634385109\n",
      "Epoch = 246, ErrG = 0.26896525422732037, ErrTri = 0.2737775146961212, ErrA = 0.48321080952882767, ErrD = 0.5130998392899832, Gattn=-0.015044884756207466, Dattn=0.1004670038819313, Aattn=-0.09167250245809555\n",
      "Epoch = 248, ErrG = 0.6412517428398132, ErrTri = 0.25145840644836426, ErrA = 0.4366607088595629, ErrD = 0.25966260582208633, Gattn=-0.015025623142719269, Dattn=0.10087203234434128, Aattn=-0.09228617697954178\n",
      "Epoch = 250, ErrG = 0.48261748751004535, ErrTri = 0.2638503611087799, ErrA = 0.47253093495965004, ErrD = 0.4744698653618495, Gattn=-0.015052595175802708, Dattn=0.10121824592351913, Aattn=-0.09257518500089645\n",
      "Epoch = 252, ErrG = 0.7586210072040558, ErrTri = 0.3510245382785797, ErrA = 0.4776059339443843, ErrD = 0.34530814612905186, Gattn=-0.015052474103868008, Dattn=0.10150196403265, Aattn=-0.09307417273521423\n",
      "Epoch = 254, ErrG = 0.6389037718375524, ErrTri = 0.1204858273267746, ErrA = 0.4947371358672778, ErrD = 0.2859447201093038, Gattn=-0.015038066543638706, Dattn=0.1019989401102066, Aattn=-0.09358438104391098\n",
      "Epoch = 256, ErrG = 0.4134906530380249, ErrTri = 0.2807484269142151, ErrA = 0.444407194852829, ErrD = 0.5451458245515823, Gattn=-0.0150367496535182, Dattn=0.10241764783859253, Aattn=-0.09418133646249771\n",
      "Epoch = 258, ErrG = 0.3743303219477336, ErrTri = 0.3814789652824402, ErrA = 0.5293588836987814, ErrD = 0.2311360388994217, Gattn=-0.01501214224845171, Dattn=0.1026814803481102, Aattn=-0.09452534466981888\n",
      "Epoch = 260, ErrG = 0.5407503545284271, ErrTri = 0.21853920817375183, ErrA = 0.4733918917675813, ErrD = 0.3400971119602521, Gattn=-0.015016664750874043, Dattn=0.10306235402822495, Aattn=-0.0951576977968216\n",
      "Epoch = 262, ErrG = 0.1639313797156016, ErrTri = 0.13514140248298645, ErrA = 0.44883765652775764, ErrD = 0.33013903101285297, Gattn=-0.014998274855315685, Dattn=0.10340186953544617, Aattn=-0.09547901898622513\n",
      "Epoch = 264, ErrG = 0.7855120301246643, ErrTri = 0.617293655872345, ErrA = 0.43302805721759796, ErrD = 0.21951501816511154, Gattn=-0.014989304356276989, Dattn=0.10388936847448349, Aattn=-0.09597697854042053\n",
      "Epoch = 266, ErrG = 0.20696693658828735, ErrTri = 0.4671129584312439, ErrA = 0.45611810746292275, ErrD = 0.2954145570596059, Gattn=-0.015003000386059284, Dattn=0.10425077378749847, Aattn=-0.09651106595993042\n",
      "Epoch = 268, ErrG = 0.37041130661964417, ErrTri = 0.15851441025733948, ErrA = 0.4718743562698364, ErrD = 0.45507105191548664, Gattn=-0.0149917621165514, Dattn=0.10459646582603455, Aattn=-0.09708020091056824\n",
      "Epoch = 270, ErrG = 0.29050404330094654, ErrTri = 0.0418282113969326, ErrA = 0.4918182337035735, ErrD = 0.6346585750579834, Gattn=-0.014964781701564789, Dattn=0.10497849434614182, Aattn=-0.09733492136001587\n",
      "Epoch = 272, ErrG = 0.25670116146405536, ErrTri = 0.38783568143844604, ErrA = 0.39714494595925015, ErrD = 0.587774912516276, Gattn=-0.014971341006457806, Dattn=0.10531850159168243, Aattn=-0.09787527471780777\n",
      "Epoch = 274, ErrG = 0.605052242676417, ErrTri = 0.2228754460811615, ErrA = 0.4381414291759332, ErrD = 0.21886046230793, Gattn=-0.014969815500080585, Dattn=0.1058373674750328, Aattn=-0.09849753975868225\n",
      "Epoch = 276, ErrG = 0.4325306961933772, ErrTri = 0.08436892926692963, ErrA = 0.3941553433736165, ErrD = 0.3201964894930522, Gattn=-0.014937941916286945, Dattn=0.10617508739233017, Aattn=-0.09891613572835922\n",
      "Epoch = 278, ErrG = 0.40500951806704205, ErrTri = 0.3655478358268738, ErrA = 0.46595472407837707, ErrD = 0.2629926751057307, Gattn=-0.01494157686829567, Dattn=0.10647002607584, Aattn=-0.09935016930103302\n",
      "Epoch = 280, ErrG = 0.7775154908498129, ErrTri = 0.758746862411499, ErrA = 0.41875438143809635, ErrD = 0.23690501227974892, Gattn=-0.014950188808143139, Dattn=0.10684333741664886, Aattn=-0.10008402913808823\n",
      "Epoch = 282, ErrG = 0.6026170055071512, ErrTri = 0.3230366110801697, ErrA = 0.33122300542891026, ErrD = 0.5224952244510254, Gattn=-0.014955657534301281, Dattn=0.10719949007034302, Aattn=-0.10057097673416138\n",
      "Epoch = 284, ErrG = 0.4378369450569153, ErrTri = 0.22570788860321045, ErrA = 0.3911429674675067, ErrD = 0.4899453322092692, Gattn=-0.014947300776839256, Dattn=0.10755819082260132, Aattn=-0.10103053599596024\n",
      "Epoch = 286, ErrG = 0.8153281112511953, ErrTri = 0.1264025866985321, ErrA = 0.4180629104375839, ErrD = 0.23681311681866646, Gattn=-0.014951423741877079, Dattn=0.10788193345069885, Aattn=-0.10145159065723419\n",
      "Epoch = 288, ErrG = 0.6411609848340353, ErrTri = 0.15303486585617065, ErrA = 0.4681711519757907, ErrD = 0.45043304314215976, Gattn=-0.01494139339774847, Dattn=0.10829155147075653, Aattn=-0.1020137369632721\n",
      "Epoch = 290, ErrG = 0.5808127721150717, ErrTri = 0.48649826645851135, ErrA = 0.3767798990011215, ErrD = 0.16482313722372055, Gattn=-0.014953486621379852, Dattn=0.10880192369222641, Aattn=-0.10255202651023865\n",
      "Epoch = 292, ErrG = 0.19905337442954382, ErrTri = 0.11191188544034958, ErrA = 0.3531009803215663, ErrD = 0.43141619364420575, Gattn=-0.014943620190024376, Dattn=0.10893670469522476, Aattn=-0.10307494550943375\n",
      "Epoch = 294, ErrG = 0.6305370926856995, ErrTri = 0.18784719705581665, ErrA = 0.3728289467593034, ErrD = 0.25429315368334454, Gattn=-0.014946249313652515, Dattn=0.10930855572223663, Aattn=-0.10359419882297516\n",
      "Epoch = 296, ErrG = 0.3736014465490977, ErrTri = 0.3740798830986023, ErrA = 0.5057399167368809, ErrD = 0.5429826869318882, Gattn=-0.014937134459614754, Dattn=0.10958419740200043, Aattn=-0.10408930480480194\n",
      "Epoch = 298, ErrG = 0.3368820908168952, ErrTri = 0.1721561700105667, ErrA = 0.4934017416089773, ErrD = 0.31689303119977313, Gattn=-0.014957764185965061, Dattn=0.10991214215755463, Aattn=-0.10468783229589462\n",
      "Epoch = 300, ErrG = 0.40381500621636707, ErrTri = 0.2311444729566574, ErrA = 0.368978684147199, ErrD = 0.33391528328259784, Gattn=-0.014942382462322712, Dattn=0.11036445200443268, Aattn=-0.10529512166976929\n",
      "Epoch = 302, ErrG = 0.13409705211718878, ErrTri = 0.1310923993587494, ErrA = 0.36000421829521656, ErrD = 0.47931621347864467, Gattn=-0.014942050911486149, Dattn=0.11070768535137177, Aattn=-0.10584605485200882\n",
      "Epoch = 304, ErrG = 0.13881926238536835, ErrTri = 0.2064177542924881, ErrA = 0.3556593768298626, ErrD = 0.23733113209406534, Gattn=-0.014934561215341091, Dattn=0.11117479205131531, Aattn=-0.10651417821645737\n",
      "Epoch = 306, ErrG = 0.4506920576095581, ErrTri = 0.3952537178993225, ErrA = 0.4788310502966245, ErrD = 0.26244845738013584, Gattn=-0.014921367168426514, Dattn=0.11159393191337585, Aattn=-0.10710349678993225\n",
      "Epoch = 308, ErrG = 0.49313461283842724, ErrTri = 0.31813859939575195, ErrA = 0.3893357714017232, ErrD = 0.19573046267032623, Gattn=-0.014934750273823738, Dattn=0.11189691722393036, Aattn=-0.10767272114753723\n",
      "Epoch = 310, ErrG = 0.7803638974825541, ErrTri = 0.1574668288230896, ErrA = 0.36125995218753815, ErrD = 0.1546468542267879, Gattn=-0.0149369603022933, Dattn=0.11226467043161392, Aattn=-0.10800065845251083\n",
      "Epoch = 312, ErrG = 0.06855390469233195, ErrTri = 0.26485785841941833, ErrA = 0.4069599149127801, ErrD = 0.5214830935001373, Gattn=-0.014910486526787281, Dattn=0.11259683221578598, Aattn=-0.10863205790519714\n",
      "Epoch = 314, ErrG = 0.1791094740231832, ErrTri = 0.134037047624588, ErrA = 0.29223932325839996, ErrD = 0.4875699579715729, Gattn=-0.014935702085494995, Dattn=0.11286740750074387, Aattn=-0.10922832787036896\n",
      "Epoch = 316, ErrG = 0.4502614140510559, ErrTri = 0.15763384103775024, ErrA = 0.4097696716586749, ErrD = 0.16149732967217764, Gattn=-0.014921051450073719, Dattn=0.11334900557994843, Aattn=-0.10957250744104385\n",
      "Epoch = 318, ErrG = 0.43751169244448346, ErrTri = 0.21071428060531616, ErrA = 0.412623293697834, ErrD = 0.3760947783788045, Gattn=-0.014904582872986794, Dattn=0.11366233974695206, Aattn=-0.1102510318160057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 320, ErrG = 0.7262199819087982, ErrTri = 0.29892340302467346, ErrA = 0.4301841954390208, ErrD = 0.15722828917205334, Gattn=-0.014904887415468693, Dattn=0.11397851258516312, Aattn=-0.11090515553951263\n",
      "Epoch = 322, ErrG = 0.4557248502969742, ErrTri = 0.04662661254405975, ErrA = 0.33638131618499756, ErrD = 0.21228575458129248, Gattn=-0.01490264106541872, Dattn=0.11437119543552399, Aattn=-0.11152851581573486\n",
      "Epoch = 324, ErrG = 0.511737714211146, ErrTri = 0.27237382531166077, ErrA = 0.428065021832784, ErrD = 0.1517817129691442, Gattn=-0.014896749518811703, Dattn=0.11459377408027649, Aattn=-0.11210143566131592\n",
      "Epoch = 326, ErrG = 0.6331769227981567, ErrTri = 0.08537405729293823, ErrA = 0.4065566708644231, ErrD = 0.38505323727925617, Gattn=-0.01490033883601427, Dattn=0.11491291970014572, Aattn=-0.11247614026069641\n",
      "Epoch = 328, ErrG = 0.3078423887491226, ErrTri = 0.2863078713417053, ErrA = 0.4195273605485757, ErrD = 0.30084332823753357, Gattn=-0.014885512180626392, Dattn=0.11526453495025635, Aattn=-0.11315722018480301\n",
      "Epoch = 330, ErrG = 0.44603336602449417, ErrTri = 0.0661681517958641, ErrA = 0.4629932443300883, ErrD = 0.5087408224741617, Gattn=-0.01487011555582285, Dattn=0.1155119314789772, Aattn=-0.11385640501976013\n",
      "Epoch = 332, ErrG = 0.6809193988641103, ErrTri = 0.24385759234428406, ErrA = 0.3886796732743581, ErrD = 0.3554885784784953, Gattn=-0.014873499982059002, Dattn=0.11585068702697754, Aattn=-0.11450300365686417\n",
      "Epoch = 334, ErrG = 0.3397548894087474, ErrTri = 0.46446752548217773, ErrA = 0.5568772802750269, ErrD = 0.6737236082553864, Gattn=-0.014895584434270859, Dattn=0.11609305441379547, Aattn=-0.11490008980035782\n",
      "Epoch = 336, ErrG = 0.5600215196609497, ErrTri = 0.11843621730804443, ErrA = 0.42380783955256146, ErrD = 0.4195723409454028, Gattn=-0.01488289050757885, Dattn=0.11657688021659851, Aattn=-0.11570326238870621\n",
      "Epoch = 338, ErrG = 0.47909221053123474, ErrTri = 0.1390046775341034, ErrA = 0.2846626912554105, ErrD = 0.2215802123149236, Gattn=-0.014875084161758423, Dattn=0.11678002774715424, Aattn=-0.11635614931583405\n",
      "Epoch = 340, ErrG = 0.470632404088974, ErrTri = 0.24613967537879944, ErrA = 0.41252819697062176, ErrD = 0.2461464653412501, Gattn=-0.014868217520415783, Dattn=0.11723010241985321, Aattn=-0.11671766638755798\n",
      "Epoch = 342, ErrG = 0.27705540259679157, ErrTri = 0.1833338439464569, ErrA = 0.4286391039689382, ErrD = 0.11515802641709645, Gattn=-0.014849360100924969, Dattn=0.11761265993118286, Aattn=-0.11735770851373672\n",
      "Epoch = 344, ErrG = 0.25756394614775974, ErrTri = 0.14018085598945618, ErrA = 0.3554795781771342, ErrD = 0.312069038550059, Gattn=-0.014845998026430607, Dattn=0.11780980229377747, Aattn=-0.11770670861005783\n",
      "Epoch = 346, ErrG = 0.46183881163597107, ErrTri = 0.2567111551761627, ErrA = 0.4511531243721644, ErrD = 0.22399080793062845, Gattn=-0.014856379479169846, Dattn=0.1182604730129242, Aattn=-0.11824589222669601\n",
      "Epoch = 348, ErrG = 0.7046916087468466, ErrTri = 0.26339900493621826, ErrA = 0.48958762486775714, ErrD = 0.1323162093758583, Gattn=-0.014864376746118069, Dattn=0.11862218379974365, Aattn=-0.11909458041191101\n",
      "Epoch = 350, ErrG = 0.18434271216392517, ErrTri = 0.06919878721237183, ErrA = 0.38476590005060035, ErrD = 0.2498493194580078, Gattn=-0.014876525849103928, Dattn=0.11894107609987259, Aattn=-0.1195327639579773\n",
      "Epoch = 352, ErrG = 0.7424730112155279, ErrTri = 0.07009364664554596, ErrA = 0.3792620512346427, ErrD = 0.22319261357188225, Gattn=-0.014861715026199818, Dattn=0.11930881440639496, Aattn=-0.1204039603471756\n",
      "Epoch = 354, ErrG = 0.040642028053601585, ErrTri = 0.07484014332294464, ErrA = 0.2909161721666654, ErrD = 0.632386843363444, Gattn=-0.014853554777801037, Dattn=0.11959739029407501, Aattn=-0.12112902849912643\n",
      "Epoch = 356, ErrG = 0.6410961200793585, ErrTri = 0.09864784777164459, ErrA = 0.3341667304436366, ErrD = 0.29346148173014325, Gattn=-0.014856578782200813, Dattn=0.11996416747570038, Aattn=-0.12189111858606339\n",
      "Epoch = 358, ErrG = 0.4402515689531962, ErrTri = 0.2240358591079712, ErrA = 0.405641367038091, ErrD = 0.23578304052352905, Gattn=-0.014847577549517155, Dattn=0.1202114000916481, Aattn=-0.12241664528846741\n",
      "Epoch = 360, ErrG = 0.8494717528422674, ErrTri = 0.2283141165971756, ErrA = 0.44075843195120495, ErrD = 0.19591053389012814, Gattn=-0.014826756902039051, Dattn=0.12072444707155228, Aattn=-0.1229187473654747\n",
      "Epoch = 362, ErrG = 0.4925321042537689, ErrTri = 0.14402422308921814, ErrA = 0.3992598758389552, ErrD = 0.460994432369868, Gattn=-0.01485315803438425, Dattn=0.1209508404135704, Aattn=-0.12335003167390823\n",
      "Epoch = 364, ErrG = 0.19857206443945566, ErrTri = 0.19529834389686584, ErrA = 0.44370943307876587, ErrD = 0.3075067748626073, Gattn=-0.014866206794977188, Dattn=0.1212262213230133, Aattn=-0.12399667501449585\n",
      "Epoch = 366, ErrG = 0.6143347124258677, ErrTri = 0.30467385053634644, ErrA = 0.3467752995590369, ErrD = 0.18468838930130005, Gattn=-0.01486351527273655, Dattn=0.12156518548727036, Aattn=-0.12500505149364471\n",
      "Epoch = 368, ErrG = 0.6921275233229002, ErrTri = 0.12464766949415207, ErrA = 0.3770819467802842, ErrD = 0.18491312488913536, Gattn=-0.014869472943246365, Dattn=0.12185731530189514, Aattn=-0.12556888163089752\n",
      "Epoch = 370, ErrG = 0.41654550035794574, ErrTri = 0.2583586871623993, ErrA = 0.5476712385813395, ErrD = 0.24267111221949259, Gattn=-0.014860170893371105, Dattn=0.12209274619817734, Aattn=-0.12634530663490295\n",
      "Epoch = 372, ErrG = 0.7455229808886846, ErrTri = 0.14312757551670074, ErrA = 0.3870541950066884, ErrD = 0.21235501766204834, Gattn=-0.014843963086605072, Dattn=0.12232407927513123, Aattn=-0.12685109674930573\n",
      "Epoch = 374, ErrG = 0.6529216170310974, ErrTri = 0.1523415446281433, ErrA = 0.38755778471628827, ErrD = 0.20597275098164877, Gattn=-0.014861098490655422, Dattn=0.12262074649333954, Aattn=-0.12770003080368042\n",
      "Epoch = 376, ErrG = 0.5396913985411326, ErrTri = 0.16022399067878723, ErrA = 0.4083375856280327, ErrD = 0.203790827964743, Gattn=-0.01487475074827671, Dattn=0.1228967010974884, Aattn=-0.1283850222826004\n",
      "Epoch = 378, ErrG = 0.6455484206477801, ErrTri = 0.11748819798231125, ErrA = 0.36075841697553795, ErrD = 0.2519786171615124, Gattn=-0.014887028373777866, Dattn=0.12319469451904297, Aattn=-0.12905091047286987\n",
      "Epoch = 380, ErrG = 0.32238983114560443, ErrTri = 0.38863781094551086, ErrA = 0.39807486658294994, ErrD = 0.4127977366248767, Gattn=-0.014869648031890392, Dattn=0.12347640097141266, Aattn=-0.1297231763601303\n",
      "Epoch = 382, ErrG = 0.6247592295209566, ErrTri = 0.054422833025455475, ErrA = 0.38486620783805847, ErrD = 0.19777171313762665, Gattn=-0.014840204268693924, Dattn=0.12373974174261093, Aattn=-0.13100089132785797\n",
      "Epoch = 384, ErrG = 0.5263419250647227, ErrTri = 0.16524997353553772, ErrA = 0.4798702746629715, ErrD = 0.2500828132033348, Gattn=-0.014852725900709629, Dattn=0.1240999773144722, Aattn=-0.1315770298242569\n",
      "Epoch = 386, ErrG = 0.4814299965898196, ErrTri = 0.2246684730052948, ErrA = 0.437685688957572, ErrD = 0.2928337852160136, Gattn=-0.014809153974056244, Dattn=0.12428142875432968, Aattn=-0.13233157992362976\n",
      "Epoch = 388, ErrG = 0.4986508364478747, ErrTri = 0.08034413307905197, ErrA = 0.3438923855622609, ErrD = 0.24588640530904135, Gattn=-0.014826114289462566, Dattn=0.12462655454874039, Aattn=-0.13304001092910767\n",
      "Epoch = 390, ErrG = 0.5551326324542364, ErrTri = 0.11342234909534454, ErrA = 0.5475434685746828, ErrD = 0.17180275917053223, Gattn=-0.01483237836509943, Dattn=0.1250230073928833, Aattn=-0.1339792162179947\n",
      "Epoch = 392, ErrG = 0.6060028870900472, ErrTri = 0.06892961263656616, ErrA = 0.32693876201907796, ErrD = 0.12831128388643265, Gattn=-0.014838467352092266, Dattn=0.12532906234264374, Aattn=-0.13494716584682465\n",
      "Epoch = 394, ErrG = 0.5819498300552368, ErrTri = 0.23048627376556396, ErrA = 0.4029829303423564, ErrD = 0.32385051250457764, Gattn=-0.01482485979795456, Dattn=0.12560181319713593, Aattn=-0.1357724517583847\n",
      "Epoch = 396, ErrG = 0.6796167294184366, ErrTri = 0.1445828676223755, ErrA = 0.2492322170486053, ErrD = 0.1911602821201086, Gattn=-0.014831199310719967, Dattn=0.12591370940208435, Aattn=-0.1364944726228714\n",
      "Epoch = 398, ErrG = 0.18111497660477957, ErrTri = 0.10459114611148834, ErrA = 0.3856304883956909, ErrD = 0.2881692349910736, Gattn=-0.014848004095256329, Dattn=0.12624064087867737, Aattn=-0.13726264238357544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 400, ErrG = 0.6671606798966726, ErrTri = 0.32419314980506897, ErrA = 0.3439147596557935, ErrD = 0.21877022087574005, Gattn=-0.014835789799690247, Dattn=0.12651307880878448, Aattn=-0.13783110678195953\n",
      "Epoch = 402, ErrG = 0.6959218035141627, ErrTri = 0.18467874825000763, ErrA = 0.3573266689976056, ErrD = 0.11654679415126641, Gattn=-0.014822975732386112, Dattn=0.1268615424633026, Aattn=-0.13814117014408112\n",
      "Epoch = 404, ErrG = 0.6553886582454046, ErrTri = 0.16939111053943634, ErrA = 0.44069134443998337, ErrD = 0.27583343784014386, Gattn=-0.014820008538663387, Dattn=0.12716928124427795, Aattn=-0.13852089643478394\n",
      "Epoch = 406, ErrG = 0.1907974829276403, ErrTri = 0.07312677800655365, ErrA = 0.35742249588171643, ErrD = 0.2782003978888194, Gattn=-0.014832843095064163, Dattn=0.12737083435058594, Aattn=-0.13938060402870178\n",
      "Epoch = 408, ErrG = 0.4375511705875397, ErrTri = 0.1487484872341156, ErrA = 0.3895813276370366, ErrD = 0.25210554525256157, Gattn=-0.014794943854212761, Dattn=0.1277206987142563, Aattn=-0.14014935493469238\n",
      "Epoch = 410, ErrG = 0.7204877436161041, ErrTri = 0.28800758719444275, ErrA = 0.3203467130661011, ErrD = 0.18159657965103784, Gattn=-0.01481494028121233, Dattn=0.12814746797084808, Aattn=-0.1407860815525055\n",
      "Epoch = 412, ErrG = 0.4604981591304143, ErrTri = 0.22502440214157104, ErrA = 0.363225806504488, ErrD = 0.22869154810905457, Gattn=-0.014822093769907951, Dattn=0.12833715975284576, Aattn=-0.14142443239688873\n",
      "Epoch = 414, ErrG = 0.5736695900559425, ErrTri = 0.11001073569059372, ErrA = 0.37762152093152207, ErrD = 0.22811957945426306, Gattn=-0.014827354811131954, Dattn=0.1285819113254547, Aattn=-0.14239300787448883\n",
      "Epoch = 416, ErrG = 0.5877277255058289, ErrTri = 0.15981823205947876, ErrA = 0.3270745774110158, ErrD = 0.21686567179858685, Gattn=-0.014793102629482746, Dattn=0.1289353370666504, Aattn=-0.14327484369277954\n",
      "Epoch = 418, ErrG = 0.4295980992416541, ErrTri = 0.04383246973156929, ErrA = 0.4317577003190915, ErrD = 0.21660386646787325, Gattn=-0.014815936796367168, Dattn=0.12904925644397736, Aattn=-0.14354567229747772\n",
      "Epoch = 420, ErrG = 0.6772554429868857, ErrTri = 0.05559328570961952, ErrA = 0.45676413799325627, ErrD = 0.16997743646303812, Gattn=-0.01479407213628292, Dattn=0.12937943637371063, Aattn=-0.14416341483592987\n",
      "Epoch = 422, ErrG = 0.8178632458051046, ErrTri = 0.23784369230270386, ErrA = 0.3924258314073086, ErrD = 0.23065834492444992, Gattn=-0.01479062344878912, Dattn=0.12968146800994873, Aattn=-0.1452201008796692\n",
      "Epoch = 424, ErrG = 0.6657066270709038, ErrTri = 0.09656379371881485, ErrA = 0.4609235202272733, ErrD = 0.2615652109185855, Gattn=-0.014806056395173073, Dattn=0.1300889402627945, Aattn=-0.1458585113286972\n",
      "Epoch = 426, ErrG = 0.6430028975009918, ErrTri = 0.24727436900138855, ErrA = 0.3811192587018013, ErrD = 0.16058805584907532, Gattn=-0.014793844893574715, Dattn=0.1303425133228302, Aattn=-0.14678172767162323\n",
      "Epoch = 428, ErrG = 0.29087577760219574, ErrTri = 0.5242977738380432, ErrA = 0.36040491610765457, ErrD = 0.2691972504059474, Gattn=-0.014816422015428543, Dattn=0.13050757348537445, Aattn=-0.14759793877601624\n",
      "Epoch = 430, ErrG = 0.2777874320745468, ErrTri = 0.09833662211894989, ErrA = 0.3451037605603536, ErrD = 0.35602906346321106, Gattn=-0.014834648929536343, Dattn=0.13083846867084503, Aattn=-0.14828652143478394\n",
      "Epoch = 432, ErrG = 0.5726108339925607, ErrTri = 0.06136422976851463, ErrA = 0.3239329556624095, ErrD = 0.14504099699358144, Gattn=-0.014829249121248722, Dattn=0.13123762607574463, Aattn=-0.14887863397598267\n",
      "Epoch = 434, ErrG = 0.6361827154954275, ErrTri = 0.15864405035972595, ErrA = 0.5097105503082275, ErrD = 0.20274924238522848, Gattn=-0.014797814190387726, Dattn=0.1313883662223816, Aattn=-0.14969930052757263\n",
      "Epoch = 436, ErrG = 0.6441032600899538, ErrTri = 0.021063242107629776, ErrA = 0.3818913822372754, ErrD = 0.07119986539085706, Gattn=-0.01480662077665329, Dattn=0.13159964978694916, Aattn=-0.15045522153377533\n",
      "Epoch = 438, ErrG = 0.5537063429752985, ErrTri = 0.07405082881450653, ErrA = 0.4836381475130717, ErrD = 0.2178053011496862, Gattn=-0.014799579977989197, Dattn=0.1319211721420288, Aattn=-0.15130649507045746\n",
      "Epoch = 440, ErrG = 0.7077229072650274, ErrTri = 0.07865186035633087, ErrA = 0.4744529724121094, ErrD = 0.11051304638385773, Gattn=-0.014815223403275013, Dattn=0.13214710354804993, Aattn=-0.15208293497562408\n",
      "Epoch = 442, ErrG = 0.5949727197488149, ErrTri = 0.2263736128807068, ErrA = 0.3238107127447923, ErrD = 0.11625233044226964, Gattn=-0.014820670709013939, Dattn=0.13276110589504242, Aattn=-0.1530637890100479\n",
      "Epoch = 444, ErrG = 0.6871130665143331, ErrTri = 0.08494293689727783, ErrA = 0.4267599533001582, ErrD = 0.13908623779813448, Gattn=-0.014808069914579391, Dattn=0.1329258680343628, Aattn=-0.15358100831508636\n",
      "Epoch = 446, ErrG = 0.6450032492478689, ErrTri = 0.3776048421859741, ErrA = 0.4204624990622203, ErrD = 0.21134328842163086, Gattn=-0.014796528033912182, Dattn=0.13320909440517426, Aattn=-0.1546662598848343\n",
      "Epoch = 448, ErrG = 0.5113866080840429, ErrTri = 0.15776453912258148, ErrA = 0.3472094349563122, ErrD = 0.3109631339708964, Gattn=-0.014787361025810242, Dattn=0.13342908024787903, Aattn=-0.15551893413066864\n",
      "Epoch = 450, ErrG = 0.5222617834806442, ErrTri = 0.17795510590076447, ErrA = 0.40664328696827096, ErrD = 0.1302198568979899, Gattn=-0.014801541343331337, Dattn=0.133620485663414, Aattn=-0.1564401090145111\n",
      "Epoch = 452, ErrG = 0.7540074934562048, ErrTri = 0.13652156293392181, ErrA = 0.4160105139017105, ErrD = 0.13470870380600294, Gattn=-0.01480124332010746, Dattn=0.13384521007537842, Aattn=-0.15701262652873993\n",
      "Epoch = 454, ErrG = 0.6846236288547516, ErrTri = 0.18319085240364075, ErrA = 0.3696380766729514, ErrD = 0.11623318990071614, Gattn=-0.01479995809495449, Dattn=0.13415998220443726, Aattn=-0.1576920449733734\n",
      "Epoch = 456, ErrG = 0.5889964153369268, ErrTri = 0.031263723969459534, ErrA = 0.3415297716856003, ErrD = 0.1982838430752357, Gattn=-0.014815574511885643, Dattn=0.13452664017677307, Aattn=-0.15827864408493042\n",
      "Epoch = 458, ErrG = 0.5523594866196314, ErrTri = 0.23133240640163422, ErrA = 0.2662488942344983, ErrD = 0.02958652873833974, Gattn=-0.014814361929893494, Dattn=0.13480010628700256, Aattn=-0.1592468023300171\n",
      "Epoch = 460, ErrG = 0.4422055035829544, ErrTri = 0.17969880998134613, ErrA = 0.3489132281392813, ErrD = 0.21572631349166235, Gattn=-0.014844829216599464, Dattn=0.1349896490573883, Aattn=-0.16037973761558533\n",
      "Epoch = 462, ErrG = 0.7611702183882395, ErrTri = 0.1716732680797577, ErrA = 0.34648917491237324, ErrD = 0.12948455723623434, Gattn=-0.014815893955528736, Dattn=0.1351863443851471, Aattn=-0.16137473285198212\n",
      "Epoch = 464, ErrG = 0.3681056648492813, ErrTri = 0.1926819533109665, ErrA = 0.42152758687734604, ErrD = 0.2861977592110634, Gattn=-0.01482038851827383, Dattn=0.13543492555618286, Aattn=-0.16206206381320953\n",
      "Epoch = 466, ErrG = 0.5660867244005203, ErrTri = 0.2307472676038742, ErrA = 0.4099421699841817, ErrD = 0.19616974145174026, Gattn=-0.014839000068604946, Dattn=0.13563330471515656, Aattn=-0.1625387966632843\n",
      "Epoch = 468, ErrG = 0.7141154954830805, ErrTri = 0.15797410905361176, ErrA = 0.23206483324368796, ErrD = 0.10013869156440099, Gattn=-0.014814244583249092, Dattn=0.13577581942081451, Aattn=-0.16343125700950623\n",
      "Epoch = 470, ErrG = 0.7210980157057444, ErrTri = 0.060801416635513306, ErrA = 0.4532891313234965, ErrD = 0.19174253505965075, Gattn=-0.014832830056548119, Dattn=0.1360008865594864, Aattn=-0.16450652480125427\n",
      "Epoch = 472, ErrG = 0.5500670373439789, ErrTri = 0.11446359753608704, ErrA = 0.37649422883987427, ErrD = 0.2752572347720464, Gattn=-0.014849747531116009, Dattn=0.13657455146312714, Aattn=-0.16563007235527039\n",
      "Epoch = 474, ErrG = 0.7190877124667168, ErrTri = 0.09631232172250748, ErrA = 0.3290838624040286, ErrD = 0.20423556491732597, Gattn=-0.014842482283711433, Dattn=0.13703210651874542, Aattn=-0.16614700853824615\n",
      "Epoch = 476, ErrG = 0.7295167843500773, ErrTri = 0.3085547089576721, ErrA = 0.38533852497736615, ErrD = 0.2333036263783773, Gattn=-0.014828270301222801, Dattn=0.13713711500167847, Aattn=-0.16698738932609558\n",
      "Epoch = 478, ErrG = 0.7028365532557169, ErrTri = 0.08907198905944824, ErrA = 0.27718952981134254, ErrD = 0.17115522858997187, Gattn=-0.014847079291939735, Dattn=0.13746139407157898, Aattn=-0.16758447885513306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 480, ErrG = 0.726226852585872, ErrTri = 0.0472123809158802, ErrA = 0.47799859444300336, ErrD = 0.12064676235119502, Gattn=-0.014843268319964409, Dattn=0.1376672387123108, Aattn=-0.16839942336082458\n",
      "Epoch = 482, ErrG = 0.4924769476056099, ErrTri = 0.08704926818609238, ErrA = 0.3435625309745471, ErrD = 0.3399594575166702, Gattn=-0.014844181947410107, Dattn=0.1378173977136612, Aattn=-0.16893552243709564\n",
      "Epoch = 484, ErrG = 0.6846865378320217, ErrTri = 0.059720564633607864, ErrA = 0.40098026146491367, ErrD = 0.1631354739268621, Gattn=-0.014818742871284485, Dattn=0.1379549652338028, Aattn=-0.16942249238491058\n",
      "Epoch = 486, ErrG = 0.6026637877027193, ErrTri = 0.040529765188694, ErrA = 0.42076122015714645, ErrD = 0.25067611535390216, Gattn=-0.014828508719801903, Dattn=0.1383891999721527, Aattn=-0.1703626662492752\n",
      "Epoch = 488, ErrG = 0.7364134192466736, ErrTri = 0.06254643201828003, ErrA = 0.4094451268513997, ErrD = 0.16428804397583008, Gattn=-0.014821958728134632, Dattn=0.1385522186756134, Aattn=-0.17075622081756592\n",
      "Epoch = 490, ErrG = 0.541773776213328, ErrTri = 0.07344686985015869, ErrA = 0.3738692564268907, ErrD = 0.1847509170571963, Gattn=-0.014834134839475155, Dattn=0.13884232938289642, Aattn=-0.17173868417739868\n",
      "Epoch = 492, ErrG = 0.4752020711700122, ErrTri = 0.12261810153722763, ErrA = 0.3232564466694991, ErrD = 0.241266131401062, Gattn=-0.014848493039608002, Dattn=0.1390438675880432, Aattn=-0.17239569127559662\n",
      "Epoch = 494, ErrG = 0.6066335588693619, ErrTri = 0.1429470330476761, ErrA = 0.390739065905412, ErrD = 0.042111883560816445, Gattn=-0.014827573671936989, Dattn=0.13939593732357025, Aattn=-0.1733292192220688\n",
      "Epoch = 496, ErrG = 0.4924192229906718, ErrTri = 0.14707159996032715, ErrA = 0.355132086823384, ErrD = 0.16998051355282465, Gattn=-0.014836317859590054, Dattn=0.1396225541830063, Aattn=-0.17426392436027527\n",
      "Epoch = 498, ErrG = 0.8962918917338053, ErrTri = 0.27976346015930176, ErrA = 0.3033713499704997, ErrD = 0.20631574653089046, Gattn=-0.014848037622869015, Dattn=0.1398579180240631, Aattn=-0.17517225444316864\n",
      "Epoch = 500, ErrG = 0.19246206680933634, ErrTri = 0.18525022268295288, ErrA = 0.4356480638186137, ErrD = 0.18484964470068613, Gattn=-0.014846857637166977, Dattn=0.1402554214000702, Aattn=-0.17516152560710907\n",
      "Epoch = 502, ErrG = 0.6226896643638611, ErrTri = 0.1450992226600647, ErrA = 0.3032473623752594, ErrD = 0.19387003779411316, Gattn=-0.014833418652415276, Dattn=0.1405029594898224, Aattn=-0.1758572906255722\n",
      "Epoch = 504, ErrG = 0.5690297273298105, ErrTri = 0.004670139402151108, ErrA = 0.35892746845881146, ErrD = 0.03253977683683237, Gattn=-0.014840728603303432, Dattn=0.14065055549144745, Aattn=-0.1763974279165268\n",
      "Epoch = 506, ErrG = 0.6951980988184611, ErrTri = 0.15754258632659912, ErrA = 0.2971954979002476, ErrD = 0.04565116701026758, Gattn=-0.01486437488347292, Dattn=0.14075325429439545, Aattn=-0.1773381233215332\n",
      "Epoch = 508, ErrG = 0.8449660837650299, ErrTri = 0.4210076630115509, ErrA = 0.2906111925840378, ErrD = 0.15522127350171408, Gattn=-0.01487930677831173, Dattn=0.14092716574668884, Aattn=-0.17771925032138824\n",
      "Epoch = 510, ErrG = 0.5964536219835281, ErrTri = 0.15812529623508453, ErrA = 0.23938706517219543, ErrD = 0.19025606413682303, Gattn=-0.01486786175519228, Dattn=0.1411319226026535, Aattn=-0.17867246270179749\n",
      "Epoch = 512, ErrG = 0.5961102445920309, ErrTri = 0.015029728412628174, ErrA = 0.4187489052613576, ErrD = 0.26354863742987317, Gattn=-0.014887196011841297, Dattn=0.14131148159503937, Aattn=-0.1794452667236328\n",
      "Epoch = 514, ErrG = 0.599522665143013, ErrTri = 0.03079141676425934, ErrA = 0.3228001023332278, ErrD = 0.17859226651489735, Gattn=-0.014852853491902351, Dattn=0.1416502594947815, Aattn=-0.1804891973733902\n",
      "Epoch = 516, ErrG = 0.5731978776554266, ErrTri = 0.03442864492535591, ErrA = 0.32007567087809247, ErrD = 0.1591193526983261, Gattn=-0.0148474657908082, Dattn=0.14170578122138977, Aattn=-0.18108120560646057\n",
      "Epoch = 518, ErrG = 0.6294770886500677, ErrTri = 0.10838253796100616, ErrA = 0.26765522360801697, ErrD = 0.0521460697054863, Gattn=-0.014852738939225674, Dattn=0.14183315634727478, Aattn=-0.18199096620082855\n",
      "Epoch = 520, ErrG = 0.8183295975128809, ErrTri = 0.14575405418872833, ErrA = 0.47880613058805466, ErrD = 0.03860011945168177, Gattn=-0.014840790070593357, Dattn=0.14214400947093964, Aattn=-0.1827193796634674\n",
      "Epoch = 522, ErrG = 0.4104350631435712, ErrTri = 0.10966692119836807, ErrA = 0.4194040670990944, ErrD = 0.2277441347638766, Gattn=-0.014814083464443684, Dattn=0.1423797607421875, Aattn=-0.183572456240654\n",
      "Epoch = 524, ErrG = 0.5475980180005232, ErrTri = 0.020968984812498093, ErrA = 0.2991084506114324, ErrD = 0.05920400222142538, Gattn=-0.014803480356931686, Dattn=0.14283092319965363, Aattn=-0.18486900627613068\n",
      "Epoch = 526, ErrG = 0.6405766134460767, ErrTri = 0.09473792463541031, ErrA = 0.3214390731106202, ErrD = 0.10527884587645531, Gattn=-0.014833050779998302, Dattn=0.14299678802490234, Aattn=-0.1849021017551422\n",
      "Epoch = 528, ErrG = 0.5946986178557078, ErrTri = 0.13750359416007996, ErrA = 0.3023754457632701, ErrD = 0.3340112368265788, Gattn=-0.014814413152635098, Dattn=0.1431833654642105, Aattn=-0.18566252291202545\n",
      "Epoch = 530, ErrG = 0.5682512521743774, ErrTri = 0.1449645757675171, ErrA = 0.3480072543025017, ErrD = 0.19011236727237701, Gattn=-0.014827121049165726, Dattn=0.14355742931365967, Aattn=-0.18650498986244202\n",
      "Epoch = 532, ErrG = 0.5182639559110006, ErrTri = 0.13542050123214722, ErrA = 0.278940378377835, ErrD = 0.14195951695243517, Gattn=-0.01481157261878252, Dattn=0.14384616911411285, Aattn=-0.18744239211082458\n",
      "Epoch = 534, ErrG = 0.7029721140861511, ErrTri = 0.13507169485092163, ErrA = 0.3434235801299413, ErrD = 0.13402890165646872, Gattn=-0.014817962422966957, Dattn=0.14385570585727692, Aattn=-0.18802377581596375\n",
      "Epoch = 536, ErrG = 0.7439818382263184, ErrTri = 0.0, ErrA = 0.3642723858356476, ErrD = 0.10405779692033927, Gattn=-0.014811378903687, Dattn=0.14405696094036102, Aattn=-0.18866512179374695\n",
      "Epoch = 538, ErrG = 0.5382748345534006, ErrTri = 0.1463894546031952, ErrA = 0.3169758419195811, ErrD = 0.18096671253442764, Gattn=-0.014783100225031376, Dattn=0.14418502151966095, Aattn=-0.18926095962524414\n",
      "Epoch = 540, ErrG = 0.738214353720347, ErrTri = 0.15209412574768066, ErrA = 0.277153621117274, ErrD = 0.09539663170774777, Gattn=-0.014776160940527916, Dattn=0.14464107155799866, Aattn=-0.18998615443706512\n",
      "Epoch = 542, ErrG = 0.5079103211561838, ErrTri = 0.1319810450077057, ErrA = 0.3905496597290039, ErrD = 0.15321889022986093, Gattn=-0.014754803851246834, Dattn=0.14485280215740204, Aattn=-0.19081749022006989\n",
      "Epoch = 544, ErrG = 0.6214174330234528, ErrTri = 0.06470951437950134, ErrA = 0.30909185608228046, ErrD = 0.03417715057730675, Gattn=-0.01477966271340847, Dattn=0.1450687050819397, Aattn=-0.19146579504013062\n",
      "Epoch = 546, ErrG = 0.7192495316267014, ErrTri = 0.13930954039096832, ErrA = 0.23888799051443735, ErrD = 0.1753097859521707, Gattn=-0.014797888696193695, Dattn=0.14536742866039276, Aattn=-0.19198490679264069\n",
      "Epoch = 548, ErrG = 0.7635088538130125, ErrTri = 0.030538015067577362, ErrA = 0.24286390592654547, ErrD = 0.051707020650307335, Gattn=-0.014784788712859154, Dattn=0.14542518556118011, Aattn=-0.19286400079727173\n",
      "Epoch = 550, ErrG = 0.8889840046564738, ErrTri = 0.09212732315063477, ErrA = 0.15760701894760132, ErrD = 0.04697930129865805, Gattn=-0.014743243344128132, Dattn=0.14569935202598572, Aattn=-0.19298632442951202\n",
      "Epoch = 552, ErrG = 0.6160068164269129, ErrTri = 0.20042653381824493, ErrA = 0.3468674619992574, ErrD = 0.2272958035270373, Gattn=-0.01479751244187355, Dattn=0.14585739374160767, Aattn=-0.19432063400745392\n",
      "Epoch = 554, ErrG = 0.5286895620326201, ErrTri = 0.04331585392355919, ErrA = 0.2905699933568637, ErrD = 0.16743473211924234, Gattn=-0.014808259904384613, Dattn=0.14604376256465912, Aattn=-0.19524706900119781\n",
      "Epoch = 556, ErrG = 0.8795551036794981, ErrTri = 0.09362279623746872, ErrA = 0.21906373339394727, ErrD = 0.04326734940210978, Gattn=-0.014803418889641762, Dattn=0.1463831216096878, Aattn=-0.19626985490322113\n",
      "Epoch = 558, ErrG = 0.6132011587421099, ErrTri = 0.07880251854658127, ErrA = 0.49889466042319935, ErrD = 0.1208094817896684, Gattn=-0.014794985763728619, Dattn=0.14650379121303558, Aattn=-0.1968526989221573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 560, ErrG = 0.9181796908378601, ErrTri = 0.3365482687950134, ErrA = 0.28590088337659836, ErrD = 0.15627321725090346, Gattn=-0.014788860455155373, Dattn=0.14669159054756165, Aattn=-0.19761358201503754\n",
      "Epoch = 562, ErrG = 0.7749171828230222, ErrTri = 0.08283042162656784, ErrA = 0.43818465868632, ErrD = 0.19554249321420988, Gattn=-0.014783713966608047, Dattn=0.14681266248226166, Aattn=-0.19808261096477509\n",
      "Epoch = 564, ErrG = 0.7691735823949178, ErrTri = 0.3236265182495117, ErrA = 0.25681896321475506, ErrD = 0.20386691888173422, Gattn=-0.014772050082683563, Dattn=0.14706161618232727, Aattn=-0.1991758942604065\n",
      "Epoch = 566, ErrG = 0.8823995192845663, ErrTri = 0.32675981521606445, ErrA = 0.27666106820106506, ErrD = 0.09451251104474068, Gattn=-0.014788221567869186, Dattn=0.14744187891483307, Aattn=-0.19968156516551971\n",
      "Epoch = 568, ErrG = 0.7342492217818896, ErrTri = 0.1038106307387352, ErrA = 0.33737077315648395, ErrD = 0.04258691271146139, Gattn=-0.014806964434683323, Dattn=0.14758655428886414, Aattn=-0.20104052126407623\n",
      "Epoch = 570, ErrG = 0.5528999318679174, ErrTri = 0.10421635210514069, ErrA = 0.32061170289913815, ErrD = 0.15450207516551018, Gattn=-0.014799728989601135, Dattn=0.14786982536315918, Aattn=-0.20181012153625488\n",
      "Epoch = 572, ErrG = 0.9341740310192108, ErrTri = 0.2839435636997223, ErrA = 0.29792817619939643, ErrD = 0.058969354877869286, Gattn=-0.014799045398831367, Dattn=0.14787715673446655, Aattn=-0.20215463638305664\n",
      "Epoch = 574, ErrG = 0.6098601743578911, ErrTri = 0.03753659874200821, ErrA = 0.20366278290748596, ErrD = 0.2090014566977819, Gattn=-0.014808489941060543, Dattn=0.1480010747909546, Aattn=-0.20308056473731995\n",
      "Epoch = 576, ErrG = 0.5796553368369738, ErrTri = 0.006407342851161957, ErrA = 0.3337187512467305, ErrD = 0.04160399176180363, Gattn=-0.014780335128307343, Dattn=0.1482771337032318, Aattn=-0.20363348722457886\n",
      "Epoch = 578, ErrG = 0.737912674744924, ErrTri = 0.09660446643829346, ErrA = 0.30060898264249164, ErrD = 0.07226020594437917, Gattn=-0.014773672446608543, Dattn=0.14845392107963562, Aattn=-0.20442844927310944\n",
      "Epoch = 580, ErrG = 0.5209301014741262, ErrTri = 0.0, ErrA = 0.26260533432165784, ErrD = 0.2531009515126546, Gattn=-0.014754736796021461, Dattn=0.14855623245239258, Aattn=-0.20493386685848236\n",
      "Epoch = 582, ErrG = 0.6918869564930598, ErrTri = 0.06814305484294891, ErrA = 0.373465729256471, ErrD = 0.042970401545365654, Gattn=-0.014745766296982765, Dattn=0.14889420568943024, Aattn=-0.20541590452194214\n",
      "Epoch = 584, ErrG = 0.5230630785226822, ErrTri = 0.09907625615596771, ErrA = 0.26777163582543534, ErrD = 0.24574355532725653, Gattn=-0.014748072251677513, Dattn=0.14915764331817627, Aattn=-0.20580939948558807\n",
      "Epoch = 586, ErrG = 0.7333869238694509, ErrTri = 0.09912219643592834, ErrA = 0.3459380120038986, ErrD = 0.16866017753879228, Gattn=-0.01473722979426384, Dattn=0.14941607415676117, Aattn=-0.20622211694717407\n",
      "Epoch = 588, ErrG = 0.6817634527881941, ErrTri = 0.00844532996416092, ErrA = 0.2987445592880249, ErrD = 0.07933402247726917, Gattn=-0.014737830497324467, Dattn=0.1497584730386734, Aattn=-0.20694009959697723\n",
      "Epoch = 590, ErrG = 0.7660778313875198, ErrTri = 0.11472760140895844, ErrA = 0.2606934607028961, ErrD = 0.08316386553148429, Gattn=-0.014713260345160961, Dattn=0.14985933899879456, Aattn=-0.20764435827732086\n",
      "Epoch = 592, ErrG = 0.5915915643175443, ErrTri = 0.09832300990819931, ErrA = 0.2554792066415151, ErrD = 0.19928041100502014, Gattn=-0.014687999151647091, Dattn=0.15007321536540985, Aattn=-0.20835164189338684\n",
      "Epoch = 594, ErrG = 0.6314224451780319, ErrTri = 0.08892466127872467, ErrA = 0.3784717569748561, ErrD = 0.07417011260986328, Gattn=-0.01468984130769968, Dattn=0.15025588870048523, Aattn=-0.20921590924263\n",
      "Epoch = 596, ErrG = 0.5503692751129469, ErrTri = 0.01313702017068863, ErrA = 0.27780041098594666, ErrD = 0.16983604431152344, Gattn=-0.014709056355059147, Dattn=0.15031084418296814, Aattn=-0.2101990431547165\n",
      "Epoch = 598, ErrG = 0.6524753918250402, ErrTri = 0.042572006583213806, ErrA = 0.30974969267845154, ErrD = 0.228433887163798, Gattn=-0.014693656004965305, Dattn=0.15059073269367218, Aattn=-0.21046751737594604\n",
      "Epoch = 600, ErrG = 0.7254558578133583, ErrTri = 0.03549080342054367, ErrA = 0.3292674372593562, ErrD = 0.05213440271715323, Gattn=-0.014710069634020329, Dattn=0.15060177445411682, Aattn=-0.2116311639547348\n",
      "Epoch = 602, ErrG = 0.7139330158631007, ErrTri = 0.13169576227664948, ErrA = 0.3301660493016243, ErrD = 0.12004985846579075, Gattn=-0.01472275797277689, Dattn=0.150729700922966, Aattn=-0.21191401779651642\n",
      "Epoch = 604, ErrG = 0.7576697170734406, ErrTri = 0.052495986223220825, ErrA = 0.35688644212981063, ErrD = 0.07417701184749603, Gattn=-0.014727766625583172, Dattn=0.15118123590946198, Aattn=-0.21273194253444672\n",
      "Epoch = 606, ErrG = 0.9018940056363741, ErrTri = 0.09051976352930069, ErrA = 0.24366537357370058, ErrD = 0.15976596996188164, Gattn=-0.014716148376464844, Dattn=0.15127837657928467, Aattn=-0.21370452642440796\n",
      "Epoch = 608, ErrG = 0.7137724856535593, ErrTri = 0.04173579812049866, ErrA = 0.34393391013145447, ErrD = 0.06565952859818935, Gattn=-0.014750818721950054, Dattn=0.1516185849905014, Aattn=-0.21434803307056427\n",
      "Epoch = 610, ErrG = 0.4774254038929939, ErrTri = 0.11696066707372665, ErrA = 0.37112417817115784, ErrD = 0.3275158603986104, Gattn=-0.01474823709577322, Dattn=0.15135182440280914, Aattn=-0.21459458768367767\n",
      "Epoch = 612, ErrG = 0.8010621865590414, ErrTri = 0.136957049369812, ErrA = 0.3265340067446232, ErrD = 0.24186105777819952, Gattn=-0.014723870903253555, Dattn=0.1515696495771408, Aattn=-0.21498633921146393\n",
      "Epoch = 614, ErrG = 0.5835094302892685, ErrTri = 0.14382393658161163, ErrA = 0.3631419738133748, ErrD = 0.03879411766926447, Gattn=-0.014720574952661991, Dattn=0.15197008848190308, Aattn=-0.2160715013742447\n",
      "Epoch = 616, ErrG = 0.5683552573124567, ErrTri = 0.07010190188884735, ErrA = 0.2980245153109233, ErrD = 0.061495352536439896, Gattn=-0.014732562936842442, Dattn=0.15213730931282043, Aattn=-0.21697881817817688\n",
      "Epoch = 618, ErrG = 0.672465999921163, ErrTri = 0.2463395595550537, ErrA = 0.3387491703033447, ErrD = 0.10044808685779572, Gattn=-0.014733252115547657, Dattn=0.15224583446979523, Aattn=-0.21787559986114502\n",
      "Epoch = 620, ErrG = 0.589611088236173, ErrTri = 0.05097721517086029, ErrA = 0.34335530425111455, ErrD = 0.2462179958820343, Gattn=-0.014759046025574207, Dattn=0.15250128507614136, Aattn=-0.2182168811559677\n",
      "Epoch = 622, ErrG = 0.7261445571978887, ErrTri = 0.11267717182636261, ErrA = 0.25498486558596295, ErrD = 0.1891295462846756, Gattn=-0.014773663133382797, Dattn=0.15291152894496918, Aattn=-0.21834996342658997\n",
      "Epoch = 624, ErrG = 0.7473438406984011, ErrTri = 0.020050473511219025, ErrA = 0.24363518754641214, ErrD = 0.14063612620035806, Gattn=-0.014733387157320976, Dattn=0.1530728042125702, Aattn=-0.2190047949552536\n",
      "Epoch = 626, ErrG = 0.7570752277970314, ErrTri = 0.10188489407300949, ErrA = 0.1699873904387156, ErrD = 0.13612796117862067, Gattn=-0.014749795198440552, Dattn=0.15334904193878174, Aattn=-0.21925167739391327\n",
      "Epoch = 628, ErrG = 0.6702909916639328, ErrTri = 0.08405961096286774, ErrA = 0.1663733869791031, ErrD = 0.14745368932684264, Gattn=-0.014709255658090115, Dattn=0.15354874730110168, Aattn=-0.22002680599689484\n",
      "Epoch = 630, ErrG = 0.6579278906186422, ErrTri = 0.11865413188934326, ErrA = 0.31176561675965786, ErrD = 0.18341670433680216, Gattn=-0.014721090905368328, Dattn=0.1537514477968216, Aattn=-0.220575213432312\n",
      "Epoch = 632, ErrG = 0.7328087240457535, ErrTri = 0.13017205893993378, ErrA = 0.3628287787238757, ErrD = 0.09404032615323861, Gattn=-0.014726134017109871, Dattn=0.15384556353092194, Aattn=-0.22124169766902924\n",
      "Epoch = 634, ErrG = 0.656184816112121, ErrTri = 0.02654416486620903, ErrA = 0.26497067014376324, ErrD = 0.1088754932085673, Gattn=-0.014747853390872478, Dattn=0.1539466381072998, Aattn=-0.22186197340488434\n",
      "Epoch = 636, ErrG = 0.719895268479983, ErrTri = 0.14221908152103424, ErrA = 0.4049235663066308, ErrD = 0.1324234859397014, Gattn=-0.014685953967273235, Dattn=0.15408456325531006, Aattn=-0.22217565774917603\n",
      "Epoch = 638, ErrG = 0.7733008737365404, ErrTri = 0.05523737519979477, ErrA = 0.38940109809239704, ErrD = 0.03433751376966635, Gattn=-0.014720828272402287, Dattn=0.15416646003723145, Aattn=-0.22331948578357697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 640, ErrG = 0.5829573273658752, ErrTri = 0.12776216864585876, ErrA = 0.34545545776685077, ErrD = 0.06914480465153854, Gattn=-0.014727042056620121, Dattn=0.1544439047574997, Aattn=-0.2237456887960434\n",
      "Epoch = 642, ErrG = 0.609822690486908, ErrTri = 0.29725295305252075, ErrA = 0.2481230596701304, ErrD = 0.08848354034125805, Gattn=-0.014725122600793839, Dattn=0.15474635362625122, Aattn=-0.22378361225128174\n",
      "Epoch = 644, ErrG = 0.7339262713988622, ErrTri = 0.1621600240468979, ErrA = 0.34866116878887016, ErrD = 0.068463580061992, Gattn=-0.014705088920891285, Dattn=0.15490077435970306, Aattn=-0.22417311370372772\n",
      "Epoch = 646, ErrG = 0.660824162264665, ErrTri = 0.049027152359485626, ErrA = 0.37681002418200177, ErrD = 0.09153017650047938, Gattn=-0.014694875106215477, Dattn=0.15498563647270203, Aattn=-0.22491084039211273\n",
      "Epoch = 648, ErrG = 0.7591326534748077, ErrTri = 0.2632124722003937, ErrA = 0.24088914692401886, ErrD = 0.1717893679936727, Gattn=-0.014687495306134224, Dattn=0.1553063541650772, Aattn=-0.22600145637989044\n",
      "Epoch = 650, ErrG = 0.7012259562810262, ErrTri = 0.04966020584106445, ErrA = 0.3029428521792094, ErrD = 0.13167345089217028, Gattn=-0.014687720686197281, Dattn=0.15548712015151978, Aattn=-0.22631733119487762\n",
      "Epoch = 652, ErrG = 0.8120445075134436, ErrTri = 0.008348483592271805, ErrA = 0.23553761839866638, ErrD = 0.014876165116826693, Gattn=-0.014700070023536682, Dattn=0.15546981990337372, Aattn=-0.22693805396556854\n",
      "Epoch = 654, ErrG = 0.7927167961994807, ErrTri = 0.09508518874645233, ErrA = 0.3072536364197731, ErrD = 0.0365172295520703, Gattn=-0.01472624484449625, Dattn=0.1556861698627472, Aattn=-0.2272038459777832\n",
      "Epoch = 656, ErrG = 0.6729695772131284, ErrTri = 0.03606473654508591, ErrA = 0.3072631477067868, ErrD = 0.10204901297887166, Gattn=-0.014720132574439049, Dattn=0.15579847991466522, Aattn=-0.22804394364356995\n",
      "Epoch = 658, ErrG = 0.6854338298241297, ErrTri = 0.16832704842090607, ErrA = 0.33261063198248547, ErrD = 0.06118183955550194, Gattn=-0.014747900888323784, Dattn=0.15599137544631958, Aattn=-0.22860339283943176\n",
      "Epoch = 660, ErrG = 0.6506131241718928, ErrTri = 0.14977829158306122, ErrA = 0.27526163558165234, ErrD = 0.2040907939275106, Gattn=-0.014740129932761192, Dattn=0.1562504917383194, Aattn=-0.2294275015592575\n",
      "Epoch = 662, ErrG = 0.7115924259026846, ErrTri = 0.09361359477043152, ErrA = 0.26381860425074893, ErrD = 0.09068248855570953, Gattn=-0.014746957458555698, Dattn=0.15636585652828217, Aattn=-0.2298346757888794\n",
      "Epoch = 664, ErrG = 0.6277097513278326, ErrTri = 0.017343595623970032, ErrA = 0.34284068768223125, ErrD = 0.139300266901652, Gattn=-0.01472253818064928, Dattn=0.1564469039440155, Aattn=-0.2301653027534485\n",
      "Epoch = 666, ErrG = 0.3630266884962718, ErrTri = 0.012708961963653564, ErrA = 0.2707155446211497, ErrD = 0.14448527991771698, Gattn=-0.014738475903868675, Dattn=0.15669964253902435, Aattn=-0.2303394079208374\n",
      "Epoch = 668, ErrG = 0.617159765213728, ErrTri = 0.01130247488617897, ErrA = 0.22287136626740298, ErrD = 0.13065984100103378, Gattn=-0.01473977044224739, Dattn=0.15674251317977905, Aattn=-0.23080511391162872\n",
      "Epoch = 670, ErrG = 0.4276300271352132, ErrTri = 0.02754664421081543, ErrA = 0.24862263972560564, ErrD = 0.45185891538858414, Gattn=-0.014745804481208324, Dattn=0.15689818561077118, Aattn=-0.23158498108386993\n",
      "Epoch = 672, ErrG = 0.7747242997090021, ErrTri = 0.06614486873149872, ErrA = 0.3054104559123516, ErrD = 0.04800275961558024, Gattn=-0.014692609198391438, Dattn=0.1572403907775879, Aattn=-0.23211829364299774\n",
      "Epoch = 674, ErrG = 0.6103001609444618, ErrTri = 0.03833942860364914, ErrA = 0.22980630646149316, ErrD = 0.1738477610051632, Gattn=-0.014665926806628704, Dattn=0.15732890367507935, Aattn=-0.232698455452919\n",
      "Epoch = 676, ErrG = 0.5664230038722357, ErrTri = 0.11129321157932281, ErrA = 0.2950315165023009, ErrD = 0.26512907445430756, Gattn=-0.014672454446554184, Dattn=0.15740236639976501, Aattn=-0.2335156947374344\n",
      "Epoch = 678, ErrG = 0.8213804960250854, ErrTri = 0.09420812129974365, ErrA = 0.22843206922213236, ErrD = 0.12185775240262349, Gattn=-0.014667024835944176, Dattn=0.15768752992153168, Aattn=-0.23379367589950562\n",
      "Epoch = 680, ErrG = 0.87873292217652, ErrTri = 0.11748767644166946, ErrA = 0.43875763192772865, ErrD = 0.13406906028588614, Gattn=-0.01469048485159874, Dattn=0.15784206986427307, Aattn=-0.2345346212387085\n",
      "Epoch = 682, ErrG = 0.6450147827466329, ErrTri = 0.08285635709762573, ErrA = 0.34050921847422916, ErrD = 0.06033439810077349, Gattn=-0.014682875946164131, Dattn=0.15788112580776215, Aattn=-0.2352103590965271\n",
      "Epoch = 684, ErrG = 0.9109688053528467, ErrTri = 0.1291418820619583, ErrA = 0.22807149092356363, ErrD = 0.06934501727422078, Gattn=-0.014733540825545788, Dattn=0.1579747200012207, Aattn=-0.23558774590492249\n",
      "Epoch = 686, ErrG = 0.6176709408561388, ErrTri = 0.031142018735408783, ErrA = 0.2265857607126236, ErrD = 0.06657429474095504, Gattn=-0.014699840918183327, Dattn=0.1583060920238495, Aattn=-0.23557747900485992\n",
      "Epoch = 688, ErrG = 0.9478573600451151, ErrTri = 0.13181394338607788, ErrA = 0.2855338429411252, ErrD = 0.09655330268045266, Gattn=-0.01468910463154316, Dattn=0.15833337604999542, Aattn=-0.2362545281648636\n",
      "Epoch = 690, ErrG = 0.5868748327096304, ErrTri = 0.134842187166214, ErrA = 0.3009958068529765, ErrD = 0.18063918501138687, Gattn=-0.014695870690047741, Dattn=0.15853101015090942, Aattn=-0.2374802976846695\n",
      "Epoch = 692, ErrG = 0.6687882194916407, ErrTri = 0.031169727444648743, ErrA = 0.2778311601529519, ErrD = 0.07143644181390603, Gattn=-0.014685072004795074, Dattn=0.15878207981586456, Aattn=-0.23781250417232513\n",
      "Epoch = 694, ErrG = 0.5493540714184443, ErrTri = 0.10979114472866058, ErrA = 0.3241262038548787, ErrD = 0.2560832351446152, Gattn=-0.014717456884682178, Dattn=0.1589636206626892, Aattn=-0.2380930632352829\n",
      "Epoch = 696, ErrG = 0.7494272912542025, ErrTri = 0.030937589704990387, ErrA = 0.37883397688468295, ErrD = 0.09700734664996465, Gattn=-0.014703652821481228, Dattn=0.15911884605884552, Aattn=-0.23858410120010376\n",
      "Epoch = 698, ErrG = 0.327255563189586, ErrTri = 0.01998801901936531, ErrA = 0.29792919258276623, ErrD = 0.22981940706570944, Gattn=-0.014694309793412685, Dattn=0.1592905968427658, Aattn=-0.2392827421426773\n",
      "Epoch = 700, ErrG = 0.611391693353653, ErrTri = 0.05899885296821594, ErrA = 0.34326061606407166, ErrD = 0.16003320614496866, Gattn=-0.014703246764838696, Dattn=0.15949265658855438, Aattn=-0.23967762291431427\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 10\n",
    "n_g = 2\n",
    "n_d = 1\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_d = {}, n_g={} target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, batchSize, beta1, beta2, n_d, n_g, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, noass_img, img, ass_img, label_neg, label_anc, label_pos) in enumerate(train_loader):\n",
    "        \n",
    "#         com_img = th.cat((noass_img, img, ass_img), 0)\n",
    "#         com_label = th.cat(( label_neg, label_anc, label_pos), 0)\n",
    "#         com_img = com_img.to(device).to(th.float32)\n",
    "#         com_label = com_label.to(device).to(th.float32)\n",
    "# #         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "\n",
    "        if i % n_g ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            d_out_assreal,dr1 = netd(ass_label)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_assreal\n",
    "            lossD += d_loss_assreal.item()\n",
    "\n",
    "            d_out_noassreal,dr2 = netd(noass_label)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_noassreal\n",
    "            lossD += d_loss_noassreal.item()\n",
    "\n",
    "            fake, code = netg(img)\n",
    "            d_out_fake, df1 = netd(fake.detach())\n",
    "            d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "            lossD_ += d_loss_fake\n",
    "            lossD += d_loss_fake.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "            lossD_ = lossD_/3\n",
    "            lossD_.backward()\n",
    "            optimD.step()\n",
    "\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked, code = netg(img)\n",
    "            faked = th.cat((img, faked.detach()), 1)\n",
    "\n",
    "            d_out_assreal,dr1 = neta(assd)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "            lossA += d_loss_assreal.item()\n",
    "            lossA_ += d_loss_assreal\n",
    "\n",
    "            d_out_noassreal,dr2 = neta(noassd)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "            lossA_ += d_loss_noassreal\n",
    "            lossA += d_loss_noassreal.item()\n",
    "\n",
    "            d_out_faked, df3 = neta(faked)\n",
    "            d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "            lossA_ += d_loss_faked\n",
    "            lossA += d_loss_faked.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "\n",
    "\n",
    "            \n",
    "        # update G\n",
    "        if i % n_d == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake, A= netg(img)\n",
    "            g_out_fake,_ = netd(fake)\n",
    "            g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "            lossG += g_loss_fake.item()\n",
    "            lossG_ += g_loss_fake\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            g_out_faked,_ = neta(faked)\n",
    "            g_loss_faked = - g_out_faked.mean()\n",
    "            lossG += g_loss_faked.item()\n",
    "            lossG_ += g_loss_faked\n",
    "\n",
    "    #         # constrain on encoder\n",
    "    #         fake_ass, P = netg(ass_img)\n",
    "    #         fake_noass, N = netg(noass_img)\n",
    "    #         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "    #         lossG_ += lossTriplet\n",
    "    #         lossG += lossTriplet.item()\n",
    "    # #         lossTriplet.backward()\n",
    "\n",
    "            ## new tripletloss\n",
    "            fake_ass, P = netg(ass_img)\n",
    "            fake_noass, N = netg(noass_img)\n",
    "            loss_fn = TripletLoss(margin)\n",
    "            lossTriplet = loss_fn(A, P, N)\n",
    "            lossG += lossTriplet.item()\n",
    "            lossG_ += lossTriplet\n",
    "            \n",
    "            ## new onlinetripletloss(semi-hard/ hard)\n",
    "#             __, com = netg(com_img)\n",
    "#             loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "#             lossTriplet,len_triplet = loss_fn(com, com_label)\n",
    "#             lossG += lossTriplet.item()\n",
    "#             lossG_ += lossTriplet\n",
    "\n",
    "\n",
    "            lossG_ = lossG_/3\n",
    "            lossG_.backward(retain_graph=True)\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrTri = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/3,lossTriplet.item(), lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/3)<low_loss:  \n",
    "        low_loss = lossG/3\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_ting_cv]",
   "language": "python",
   "name": "conda-env-py36_ting_cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
