{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-06T16:40:47.694805Z",
     "start_time": "2019-07-06T16:40:47.209628Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from onlineTripletloss import *\n",
    "from selector import *\n",
    "from model_SAGAN1_1 import NetG, NetD, NetA\n",
    "# from model_SAGAN2_Triplet import NetG, NetD, NetA\n",
    "# from model_WGANGP import NetG, NetD, NetA\n",
    "# from model_WGAN import NetG, NetD, NetA\n",
    "# from model_siGAN import NetG, NetD, NetA\n",
    "# from data_set import CASIABDataset\n",
    "from dataset2Loader_newtriplet import CASIABDataset\n",
    "# from dataset2Loader_triplet import CASIABDataset\n",
    "import torch.optim as optim\n",
    "import visdom\n",
    "from torchvision.utils import make_grid\n",
    "# Data_Dir = '../GaitRecognition/DatasetB_GEI_64x64_allseq/'\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "Model_Name = 'Model_64x64_TripletSAGAN_90_trial8'\n",
    "Model_dir = './Transform_Model/'+ Model_Name\n",
    "if not os.path.isdir(Model_dir):\n",
    "    os.mkdir(Model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T11:51:23.878764Z",
     "start_time": "2019-05-17T11:51:22.490886Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "import os\n",
    "\n",
    "for r, d, files in os.walk(Data_Dir):\n",
    "    print(r)\n",
    "    print(len(d))\n",
    "    print(len(files))\n",
    "    \n",
    "# cpt = sum([len(files) for r, d, files in os.walk(Data_Dir)])\n",
    "# cpt = sum([len(d) for r, d, files in os.walk(Data_Dir)])\n",
    "# print(cpt)\n",
    "# list = os.listdir(Data_Dir) # dir is your directory path\n",
    "# number_files = len(list)\n",
    "# print(number_files)\n",
    "\n",
    "# import fnmatch\n",
    "# print(len(fnmatch.filter(os.listdir(Data_Dir), '*.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T06:02:12.747164Z",
     "start_time": "2019-05-27T06:02:12.676816Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "ass_label, noass_label, img = dataset.getbatch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T08:08:38.785029Z",
     "start_time": "2019-06-16T08:08:38.768214Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(tensor, gain=1.)\n",
    "#         init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 128\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print('Training starts')\n",
    "while iteration < 30000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    # update D\n",
    "    lossD = 0\n",
    "    optimD.zero_grad()\n",
    "    output = netd(ass_label)\n",
    "    label.fill_(real_label)\n",
    "    lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "    lossD += lossD_real1.item()\n",
    "    lossD_real1.backward()\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output1 = netd(noass_label)\n",
    "    lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "    lossD += lossD_real2.item()\n",
    "    lossD_real2.backward()\n",
    "\n",
    "    fake = netg(img).detach()\n",
    "    label.fill_(fake_label)\n",
    "    output2 = netd(fake)\n",
    "    lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "    lossD += lossD_fake.item()\n",
    "    lossD_fake.backward()\n",
    "\n",
    "    optimD.step()\n",
    "    \n",
    "    # update A\n",
    "    lossA = 0\n",
    "    optimA.zero_grad()\n",
    "    assd = th.cat((img, ass_label), 1)\n",
    "    noassd = th.cat((img, noass_label), 1)\n",
    "    fake = netg(img).detach()\n",
    "    faked = th.cat((img, fake), 1)\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output1 = neta(assd)\n",
    "    lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "    lossA += lossA_real1.item()\n",
    "    lossA_real1.backward()\n",
    "\n",
    "    label.fill_(fake_label)\n",
    "    output = neta(noassd)\n",
    "    lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "    lossA += lossA_real2.item()\n",
    "    lossA_real2.backward()\n",
    "\n",
    "    label.fill_(fake_label)\n",
    "    output = neta(faked)\n",
    "    lossA_fake = F.binary_cross_entropy(output, label)\n",
    "    lossA += lossA_fake.item()\n",
    "    lossA_fake.backward()\n",
    "    \n",
    "    optimA.step()\n",
    "    \n",
    "    # update G\n",
    "    lossG = 0\n",
    "    optimG.zero_grad()\n",
    "    fake = netg(img)\n",
    "    output = netd(fake)\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    lossGD = F.binary_cross_entropy(output, label)\n",
    "    lossG += lossGD.item()\n",
    "    lossGD.backward(retain_graph=True)\n",
    "\n",
    "    faked = th.cat((img, fake), 1)\n",
    "    output = neta(faked)\n",
    "    label.fill_(real_label)\n",
    "    lossGA = F.binary_cross_entropy(output, label)\n",
    "    lossG += lossGA.item()\n",
    "    lossGA.backward()\n",
    "    \n",
    "    optimG.step()\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration % 20 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            fake = netg(img) 25\n",
    "            netg.train() #切換回去\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 20).cpu().numpy()\n",
    "        if win1 is None:\n",
    "            win1 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train'))\n",
    "        else:\n",
    "            vis.image(display, win=win1)\n",
    "    if iteration % 1000 == 0 or iteration==500:\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)\n",
    "\n",
    "    if iteration % 100==0 or iteration==10 :\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration, iteration,\n",
    "                                        iteration]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration,\n",
    "                                  iteration]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "            \n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            iteration, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('iter = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            iteration, lossG/2, lossA/3, lossD/3\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T05:25:59.661560Z",
     "start_time": "2019-05-27T05:25:59.620596Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=False)\n",
    "train_loader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-16T08:46:23.327475Z",
     "start_time": "2019-06-16T08:23:19.736325Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, target = {} \\n'.format(\n",
    "            epoches, lr, batchSize, target))\n",
    "\n",
    "print('Training starts')\n",
    "low_loss = 10\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, ass_img, img, noass_img) in enumerate(train_loader): \n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "#         ass_img = ass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "#         noass_img = noass_img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "        label.fill_(real_label)\n",
    "        lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "        lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "        label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "        lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "\n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "\n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:  \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "    \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update k times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T12:08:32.658055Z",
     "start_time": "2019-06-15T08:18:03.792818Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "g_k = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, g_k = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, g_k, target))\n",
    "\n",
    "low_loss = 10\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % g_k ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake = netg(img).detach()\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake)\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_img), 1)\n",
    "            noassd = th.cat((img, noass_img), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "#         if i % k ==0: \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model changed +Dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T09:39:59.973452Z",
     "start_time": "2019-06-17T01:57:16.530081Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netp = NetP(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netp.children())[0].children(),\n",
    "    list(neta.children())[0].children(),\n",
    "    list(netd.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netp = netp.to(device)\n",
    "neta = neta.to(device)\n",
    "netd = netd.to(device)\n",
    "netg.train()\n",
    "netp.train()\n",
    "neta.train()\n",
    "netd.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimP = optim.Adam(netp.parameters(), lr=lr/3)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, target = {} \\n'.format(\n",
    "            epoches, lr, batchSize, target))\n",
    "\n",
    "print('Training starts')\n",
    "low_loss = 10\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, ass_img, img, noass_img) in enumerate(train_loader): \n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        \n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "        label.fill_(real_label)\n",
    "        lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "        lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "        label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "        lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "\n",
    "\n",
    "        # update P\n",
    "        lossP = 0\n",
    "        optimP.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_img), 1)\n",
    "        noassd = th.cat((img, noass_img), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossP_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossP += lossP_real1.item()/2\n",
    "        lossP_real1 = lossP_real1/2\n",
    "        lossP_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossP_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossP += lossP_real2.item()/2\n",
    "        lossP_real2 = lossP_real2/2\n",
    "        lossP_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossP_fake = F.binary_cross_entropy(output, label)\n",
    "        lossP += lossP_fake.item()/2\n",
    "        lossP_fake = lossP_fake/2\n",
    "        lossP_fake.backward()\n",
    "\n",
    "        optimP.step()\n",
    "    \n",
    "\n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        fake = netg(img).detach()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "        lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "\n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        \n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward(retain_graph=True)\n",
    "        \n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = netp(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGP = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGP.item()/2\n",
    "        lossGP = lossGP/2\n",
    "        lossGP.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch, epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3, lossP/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD', 'lossP']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch, epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3, lossP/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:  \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict(),\n",
    "            'netP': netp.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "    \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict(),\n",
    "            'netP': netp.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, ErrP = {}  \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, lossP/3\n",
    "        ))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model only D_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T05:21:59.261901Z",
     "start_time": "2019-06-23T02:19:01.856865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 0.8942790031433105, ErrA = 0.5469881097475687\n",
      "Epoch = 4, ErrG = 1.2637784779071808, ErrA = 0.546068067351977\n",
      "Epoch = 6, ErrG = 1.4745312631130219, ErrA = 0.2442850669225057\n",
      "Epoch = 8, ErrG = 0.7030260860919952, ErrA = 0.5812898476918539\n",
      "Epoch = 10, ErrG = 0.6319204270839691, ErrA = 0.5462305198113123\n",
      "Epoch = 12, ErrG = 0.7229312062263489, ErrA = 0.5907560388247172\n",
      "Epoch = 14, ErrG = 0.6560254096984863, ErrA = 0.5953078120946884\n",
      "Epoch = 16, ErrG = 0.596514493227005, ErrA = 0.5941924850145975\n",
      "Epoch = 18, ErrG = 0.7509839236736298, ErrA = 0.5790304243564606\n",
      "Epoch = 20, ErrG = 0.7436962127685547, ErrA = 0.5637222131093343\n",
      "Epoch = 22, ErrG = 0.7619479894638062, ErrA = 0.5524072647094727\n",
      "Epoch = 24, ErrG = 0.7799927294254303, ErrA = 0.5675116032361984\n",
      "Epoch = 26, ErrG = 0.7570993900299072, ErrA = 0.5430000573396683\n",
      "Epoch = 28, ErrG = 0.6806648671627045, ErrA = 0.5911605507135391\n",
      "Epoch = 30, ErrG = 0.7085911929607391, ErrA = 0.5635207792123159\n",
      "Epoch = 32, ErrG = 0.7398755848407745, ErrA = 0.542946790655454\n",
      "Epoch = 34, ErrG = 0.6987771689891815, ErrA = 0.5245436653494835\n",
      "Epoch = 36, ErrG = 0.7142378389835358, ErrA = 0.5692398597796758\n",
      "Epoch = 38, ErrG = 0.7021530866622925, ErrA = 0.5006640180945396\n",
      "Epoch = 40, ErrG = 0.6831426620483398, ErrA = 0.5278080105781555\n",
      "Epoch = 42, ErrG = 0.7346322536468506, ErrA = 0.5483258465925852\n",
      "Epoch = 44, ErrG = 0.7123729288578033, ErrA = 0.5212108840545019\n",
      "Epoch = 46, ErrG = 0.7028100192546844, ErrA = 0.4995379410684109\n",
      "Epoch = 48, ErrG = 0.7533432245254517, ErrA = 0.5220620507995287\n",
      "Epoch = 50, ErrG = 0.7461298704147339, ErrA = 0.5350130001703898\n",
      "Epoch = 52, ErrG = 0.7754039764404297, ErrA = 0.49853498737017315\n",
      "Epoch = 54, ErrG = 0.7037776708602905, ErrA = 0.5569594502449036\n",
      "Epoch = 56, ErrG = 0.7385750114917755, ErrA = 0.5235102847218513\n",
      "Epoch = 58, ErrG = 0.7446320056915283, ErrA = 0.5143130719661713\n",
      "Epoch = 60, ErrG = 0.7606864273548126, ErrA = 0.4862695907553037\n",
      "Epoch = 62, ErrG = 0.7524447441101074, ErrA = 0.4886733914415042\n",
      "Epoch = 64, ErrG = 0.7789376080036163, ErrA = 0.5159297784169515\n",
      "Epoch = 66, ErrG = 0.7068325281143188, ErrA = 0.5026514927546183\n",
      "Epoch = 68, ErrG = 0.7491750717163086, ErrA = 0.48465976615746814\n",
      "Epoch = 70, ErrG = 0.6959052979946136, ErrA = 0.4887603024641673\n",
      "Epoch = 72, ErrG = 0.7552242279052734, ErrA = 0.48123402272661525\n",
      "Epoch = 74, ErrG = 0.7767785787582397, ErrA = 0.48337166383862495\n",
      "Epoch = 76, ErrG = 0.7066345512866974, ErrA = 0.4943077315886815\n",
      "Epoch = 78, ErrG = 0.7221456170082092, ErrA = 0.49115220457315445\n",
      "Epoch = 80, ErrG = 0.7737798690795898, ErrA = 0.49439525107542676\n",
      "Epoch = 82, ErrG = 0.7249805927276611, ErrA = 0.513443112373352\n",
      "Epoch = 84, ErrG = 0.6759329438209534, ErrA = 0.47693638131022453\n",
      "Epoch = 86, ErrG = 0.6800636351108551, ErrA = 0.49612883292138577\n",
      "Epoch = 88, ErrG = 0.7434355318546295, ErrA = 0.48449163387219113\n",
      "Epoch = 90, ErrG = 0.7718946933746338, ErrA = 0.4642128699148695\n",
      "Epoch = 92, ErrG = 0.7085524201393127, ErrA = 0.481226892520984\n",
      "Epoch = 94, ErrG = 0.7638988792896271, ErrA = 0.48685218890508014\n",
      "Epoch = 96, ErrG = 0.7420380711555481, ErrA = 0.47724030663569766\n",
      "Epoch = 98, ErrG = 0.7099126279354095, ErrA = 0.4783617841700713\n",
      "Epoch = 100, ErrG = 0.7764213383197784, ErrA = 0.4978024363517761\n",
      "Epoch = 102, ErrG = 0.7599453628063202, ErrA = 0.4906090075771014\n",
      "Epoch = 104, ErrG = 0.7223043143749237, ErrA = 0.4777823459977905\n",
      "Epoch = 106, ErrG = 0.7203013896942139, ErrA = 0.4673133132358392\n",
      "Epoch = 108, ErrG = 0.7951952219009399, ErrA = 0.4689557043214639\n",
      "Epoch = 110, ErrG = 0.696612685918808, ErrA = 0.4648334525991231\n",
      "Epoch = 112, ErrG = 0.7020181119441986, ErrA = 0.47102371603250504\n",
      "Epoch = 114, ErrG = 0.7256565690040588, ErrA = 0.47190982786317665\n",
      "Epoch = 116, ErrG = 0.718024730682373, ErrA = 0.4922071173787117\n",
      "Epoch = 118, ErrG = 0.8049629926681519, ErrA = 0.50795445839564\n",
      "Epoch = 120, ErrG = 0.7344598174095154, ErrA = 0.4636683070178454\n",
      "Epoch = 122, ErrG = 0.7459047436714172, ErrA = 0.47168290925522643\n",
      "Epoch = 124, ErrG = 0.7072094678878784, ErrA = 0.4708359173188607\n",
      "Epoch = 126, ErrG = 0.6943674087524414, ErrA = 0.47195245573918027\n",
      "Epoch = 128, ErrG = 0.7528819739818573, ErrA = 0.4602197891411682\n",
      "Epoch = 130, ErrG = 0.7768630683422089, ErrA = 0.46391321276314557\n",
      "Epoch = 132, ErrG = 0.6462016105651855, ErrA = 0.47284077837442356\n",
      "Epoch = 134, ErrG = 0.7016910314559937, ErrA = 0.4720935244889309\n",
      "Epoch = 136, ErrG = 0.7087399065494537, ErrA = 0.5087097734212875\n",
      "Epoch = 138, ErrG = 0.8095375299453735, ErrA = 0.47194045533736545\n",
      "Epoch = 140, ErrG = 0.7511487305164337, ErrA = 0.4675005165239175\n",
      "Epoch = 142, ErrG = 0.7348714470863342, ErrA = 0.45044909495239455\n",
      "Epoch = 144, ErrG = 0.8436956405639648, ErrA = 0.47382272422934574\n",
      "Epoch = 146, ErrG = 0.7169331312179565, ErrA = 0.46781251517434913\n",
      "Epoch = 148, ErrG = 0.6974722743034363, ErrA = 0.46431401643591624\n",
      "Epoch = 150, ErrG = 0.7351536154747009, ErrA = 0.45773912019406754\n",
      "Epoch = 152, ErrG = 0.7113821804523468, ErrA = 0.4791920619706313\n",
      "Epoch = 154, ErrG = 0.7099238634109497, ErrA = 0.46784106455743313\n",
      "Epoch = 156, ErrG = 0.7200300097465515, ErrA = 0.47287812394400436\n",
      "Epoch = 158, ErrG = 0.7663300037384033, ErrA = 0.4704851185282071\n",
      "Epoch = 160, ErrG = 0.7025600969791412, ErrA = 0.47673642992352444\n",
      "Epoch = 162, ErrG = 0.7106462717056274, ErrA = 0.4559363564476371\n",
      "Epoch = 164, ErrG = 0.7305064797401428, ErrA = 0.46391087491065264\n",
      "Epoch = 166, ErrG = 0.7158514261245728, ErrA = 0.47113780366877717\n",
      "Epoch = 168, ErrG = 0.7458221912384033, ErrA = 0.4802388573686282\n",
      "Epoch = 170, ErrG = 0.7345131039619446, ErrA = 0.4784995423008998\n",
      "Epoch = 172, ErrG = 0.7271683216094971, ErrA = 0.44282429199665785\n",
      "Epoch = 174, ErrG = 0.722036212682724, ErrA = 0.47663698842128116\n",
      "Epoch = 176, ErrG = 0.8012456893920898, ErrA = 0.4699000334367156\n",
      "Epoch = 178, ErrG = 0.8026721477508545, ErrA = 0.4730791311400632\n",
      "Epoch = 180, ErrG = 0.733057975769043, ErrA = 0.47403441307445365\n",
      "Epoch = 182, ErrG = 0.7420240044593811, ErrA = 0.4503744567433993\n",
      "Epoch = 184, ErrG = 0.7402363419532776, ErrA = 0.4693846357986331\n",
      "Epoch = 186, ErrG = 0.8053992688655853, ErrA = 0.4561877951491624\n",
      "Epoch = 188, ErrG = 0.7273290753364563, ErrA = 0.4763423658441752\n",
      "Epoch = 190, ErrG = 0.7182208299636841, ErrA = 0.4699595896527171\n",
      "Epoch = 192, ErrG = 0.7149357497692108, ErrA = 0.4698480541507403\n",
      "Epoch = 194, ErrG = 0.7069529592990875, ErrA = 0.4399093482643366\n",
      "Epoch = 196, ErrG = 0.7312692701816559, ErrA = 0.4694050482939929\n",
      "Epoch = 198, ErrG = 0.7102847099304199, ErrA = 0.47710530281377334\n",
      "Epoch = 200, ErrG = 0.7239364683628082, ErrA = 0.4741324484348297\n",
      "Epoch = 202, ErrG = 0.6863627433776855, ErrA = 0.4666913408630838\n",
      "Epoch = 204, ErrG = 0.710493803024292, ErrA = 0.48051125307877857\n",
      "Epoch = 206, ErrG = 0.7055504620075226, ErrA = 0.4639119856680433\n",
      "Epoch = 208, ErrG = 0.7073525190353394, ErrA = 0.474591055419296\n",
      "Epoch = 210, ErrG = 0.772272527217865, ErrA = 0.4620121866464615\n",
      "Epoch = 212, ErrG = 0.7467249035835266, ErrA = 0.45906886146015796\n",
      "Epoch = 214, ErrG = 0.7155855000019073, ErrA = 0.4391966595236833\n",
      "Epoch = 216, ErrG = 0.7388149201869965, ErrA = 0.47361465108891326\n",
      "Epoch = 218, ErrG = 0.720830887556076, ErrA = 0.47472430144747096\n",
      "Epoch = 220, ErrG = 0.7492870390415192, ErrA = 0.46381861021897447\n",
      "Epoch = 222, ErrG = 0.7446886003017426, ErrA = 0.4615009583843251\n",
      "Epoch = 224, ErrG = 0.7631554901599884, ErrA = 0.46222577802836895\n",
      "Epoch = 226, ErrG = 0.6880629062652588, ErrA = 0.4703026202041656\n",
      "Epoch = 228, ErrG = 0.725965142250061, ErrA = 0.4691572740363578\n",
      "Epoch = 230, ErrG = 0.7154177129268646, ErrA = 0.46736999104420346\n",
      "Epoch = 232, ErrG = 0.7143507897853851, ErrA = 0.46925746123694506\n",
      "Epoch = 234, ErrG = 0.7197546362876892, ErrA = 0.45741439424455166\n",
      "Epoch = 236, ErrG = 0.7291060388088226, ErrA = 0.47701941058039665\n",
      "Epoch = 238, ErrG = 0.7332943677902222, ErrA = 0.3981915108937149\n",
      "Epoch = 240, ErrG = 0.7070888578891754, ErrA = 0.47804110931853455\n",
      "Epoch = 242, ErrG = 0.6959750354290009, ErrA = 0.4651560053850214\n",
      "Epoch = 244, ErrG = 0.7066155076026917, ErrA = 0.5001346683129668\n",
      "Epoch = 246, ErrG = 0.7010942101478577, ErrA = 0.4090407614130527\n",
      "Epoch = 248, ErrG = 0.7253052890300751, ErrA = 0.45764716862079996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 250, ErrG = 0.6963056921958923, ErrA = 0.46742964078051347\n",
      "Epoch = 252, ErrG = 0.7100014090538025, ErrA = 0.47177554422523826\n",
      "Epoch = 254, ErrG = 0.7693454921245575, ErrA = 0.48319031205028296\n",
      "Epoch = 256, ErrG = 0.7318943738937378, ErrA = 0.464450641341197\n",
      "Epoch = 258, ErrG = 0.7589799463748932, ErrA = 0.4585082537184159\n",
      "Epoch = 260, ErrG = 0.7342425584793091, ErrA = 0.46409560057024163\n",
      "Epoch = 262, ErrG = 0.7421980202198029, ErrA = 0.4666421595029533\n",
      "Epoch = 264, ErrG = 0.7296665608882904, ErrA = 0.48516935110092163\n",
      "Epoch = 266, ErrG = 0.7399673163890839, ErrA = 0.4635310867646088\n",
      "Epoch = 268, ErrG = 0.749874085187912, ErrA = 0.4334274607244879\n",
      "Epoch = 270, ErrG = 0.7268602848052979, ErrA = 0.4545082812352727\n",
      "Epoch = 272, ErrG = 0.7455301582813263, ErrA = 0.4670855162354807\n",
      "Epoch = 274, ErrG = 0.7072040438652039, ErrA = 0.4976085623105367\n",
      "Epoch = 276, ErrG = 0.7105807065963745, ErrA = 0.45866520221655566\n",
      "Epoch = 278, ErrG = 0.7309572100639343, ErrA = 0.4670256379370888\n",
      "Epoch = 280, ErrG = 0.6950600445270538, ErrA = 0.46326190295318764\n",
      "Epoch = 282, ErrG = 0.7438164055347443, ErrA = 0.46232210503270227\n",
      "Epoch = 284, ErrG = 0.7365607619285583, ErrA = 0.44282000969784957\n",
      "Epoch = 286, ErrG = 0.7116782665252686, ErrA = 0.45035981573164463\n",
      "Epoch = 288, ErrG = 0.7273527681827545, ErrA = 0.46450059255585074\n",
      "Epoch = 290, ErrG = 0.746793806552887, ErrA = 0.5019739344716072\n",
      "Epoch = 292, ErrG = 0.6707629561424255, ErrA = 0.4694994427651788\n",
      "Epoch = 294, ErrG = 0.7615537047386169, ErrA = 0.449320646400641\n",
      "Epoch = 296, ErrG = 0.7386289238929749, ErrA = 0.4688020000467077\n",
      "Epoch = 298, ErrG = 0.7580278515815735, ErrA = 0.4733425183221698\n",
      "Epoch = 300, ErrG = 0.7734198272228241, ErrA = 0.4752567233517766\n",
      "Epoch = 302, ErrG = 0.7106615304946899, ErrA = 0.4630706449970603\n",
      "Epoch = 304, ErrG = 0.8025050759315491, ErrA = 0.4826606586575508\n",
      "Epoch = 306, ErrG = 0.7815476059913635, ErrA = 0.48100518466283876\n",
      "Epoch = 308, ErrG = 0.7361432611942291, ErrA = 0.46106116130249575\n",
      "Epoch = 310, ErrG = 0.7738372087478638, ErrA = 0.4597351908062895\n",
      "Epoch = 312, ErrG = 0.7131433486938477, ErrA = 0.4382735924300505\n",
      "Epoch = 314, ErrG = 0.6857998371124268, ErrA = 0.4723316893602411\n",
      "Epoch = 316, ErrG = 0.723857194185257, ErrA = 0.4644397307032098\n",
      "Epoch = 318, ErrG = 0.7337216734886169, ErrA = 0.4382989287454014\n",
      "Epoch = 320, ErrG = 0.7290322482585907, ErrA = 0.4253724485170096\n",
      "Epoch = 322, ErrG = 0.7633560597896576, ErrA = 0.4681811919435859\n",
      "Epoch = 324, ErrG = 0.7348904013633728, ErrA = 0.46678357586885494\n",
      "Epoch = 326, ErrG = 0.749595046043396, ErrA = 0.43782693438697606\n",
      "Epoch = 328, ErrG = 0.6835860013961792, ErrA = 0.46677357827623683\n",
      "Epoch = 330, ErrG = 0.7776897847652435, ErrA = 0.4746040837684025\n",
      "Epoch = 332, ErrG = 0.7658129036426544, ErrA = 0.43822479240285855\n",
      "Epoch = 334, ErrG = 0.7567821145057678, ErrA = 0.4389078989624977\n",
      "Epoch = 336, ErrG = 0.7711968719959259, ErrA = 0.4620218553948992\n",
      "Epoch = 338, ErrG = 0.7806148827075958, ErrA = 0.47197788798560697\n",
      "Epoch = 340, ErrG = 0.7396496832370758, ErrA = 0.4668086639915903\n",
      "Epoch = 342, ErrG = 0.7437993884086609, ErrA = 0.46170433758137125\n",
      "Epoch = 344, ErrG = 0.7890837788581848, ErrA = 0.46584031730890274\n",
      "Epoch = 346, ErrG = 0.7809082269668579, ErrA = 0.4024994002344708\n",
      "Epoch = 348, ErrG = 0.7290099561214447, ErrA = 0.46901934923759353\n",
      "Epoch = 350, ErrG = 0.730837494134903, ErrA = 0.47435524330164\n",
      "Epoch = 352, ErrG = 0.6971488893032074, ErrA = 0.4604781827268501\n",
      "Epoch = 354, ErrG = 0.7140481173992157, ErrA = 0.4577838469995186\n",
      "Epoch = 356, ErrG = 0.7556702196598053, ErrA = 0.46313342814877007\n",
      "Epoch = 358, ErrG = 0.7762778103351593, ErrA = 0.45982841089911136\n",
      "Epoch = 360, ErrG = 0.7799193859100342, ErrA = 0.36825169731552404\n",
      "Epoch = 362, ErrG = 0.7392828464508057, ErrA = 0.468597327824682\n",
      "Epoch = 364, ErrG = 0.7959271669387817, ErrA = 0.4164326994990309\n",
      "Epoch = 366, ErrG = 0.7533955872058868, ErrA = 0.4670864967920352\n",
      "Epoch = 368, ErrG = 0.7799168825149536, ErrA = 0.4083760548771049\n",
      "Epoch = 370, ErrG = 0.6895423233509064, ErrA = 0.4507229400138992\n",
      "Epoch = 372, ErrG = 0.7157674729824066, ErrA = 0.46593861972602707\n",
      "Epoch = 374, ErrG = 0.7469688653945923, ErrA = 0.4685390457937804\n",
      "Epoch = 376, ErrG = 0.7629754543304443, ErrA = 0.455523499675716\n",
      "Epoch = 378, ErrG = 0.6944185197353363, ErrA = 0.4634507862695803\n",
      "Epoch = 380, ErrG = 0.711383730173111, ErrA = 0.4551642480461548\n",
      "Epoch = 382, ErrG = 0.7801523804664612, ErrA = 0.4650300453746847\n",
      "Epoch = 384, ErrG = 0.6638545095920563, ErrA = 0.4550419535468488\n",
      "Epoch = 386, ErrG = 0.7710936367511749, ErrA = 0.43364473797070485\n",
      "Epoch = 388, ErrG = 0.5624325275421143, ErrA = 0.45751644333358854\n",
      "Epoch = 390, ErrG = 0.7951369881629944, ErrA = 0.4687055942292015\n",
      "Epoch = 392, ErrG = 0.7994692027568817, ErrA = 0.4120073635422159\n",
      "Epoch = 394, ErrG = 0.6970470249652863, ErrA = 0.46356608051185805\n",
      "Epoch = 396, ErrG = 0.7805444002151489, ErrA = 0.3173921656173964\n",
      "Epoch = 398, ErrG = 0.7211248874664307, ErrA = 0.4407205011229962\n",
      "Epoch = 400, ErrG = 0.7231706976890564, ErrA = 0.4630381059832871\n",
      "Epoch = 402, ErrG = 0.8396570384502411, ErrA = 0.3955756123177707\n",
      "Epoch = 404, ErrG = 0.7466380298137665, ErrA = 0.36429636932249804\n",
      "Epoch = 406, ErrG = 0.7099136114120483, ErrA = 0.463014690176351\n",
      "Epoch = 408, ErrG = 0.689493864774704, ErrA = 0.4699123399720217\n",
      "Epoch = 410, ErrG = 0.7829514741897583, ErrA = 0.4663007315248251\n",
      "Epoch = 412, ErrG = 0.776607096195221, ErrA = 0.4202809411799535\n",
      "Epoch = 414, ErrG = 0.7661403119564056, ErrA = 0.39049534127116203\n",
      "Epoch = 416, ErrG = 0.7624140381813049, ErrA = 0.46241266539921827\n",
      "Epoch = 418, ErrG = 0.7180585265159607, ErrA = 0.46025182547358173\n",
      "Epoch = 420, ErrG = 0.8523218035697937, ErrA = 0.46419745999931666\n",
      "Epoch = 422, ErrG = 0.8099254965782166, ErrA = 0.40281165670603514\n",
      "Epoch = 424, ErrG = 0.7658357620239258, ErrA = 0.46380508815248805\n",
      "Epoch = 426, ErrG = 0.7402676939964294, ErrA = 0.45892095705494285\n",
      "Epoch = 428, ErrG = 0.793531745672226, ErrA = 0.45821206502538797\n",
      "Epoch = 430, ErrG = 0.7468352615833282, ErrA = 0.45875944435829297\n",
      "Epoch = 432, ErrG = 0.7842081785202026, ErrA = 0.4533255178442535\n",
      "Epoch = 434, ErrG = 0.6568473875522614, ErrA = 0.4241505636212726\n",
      "Epoch = 436, ErrG = 0.8184404373168945, ErrA = 0.46835145230094594\n",
      "Epoch = 438, ErrG = 0.7490629255771637, ErrA = 0.45978151087183505\n",
      "Epoch = 440, ErrG = 0.7161268293857574, ErrA = 0.3779887482523918\n",
      "Epoch = 442, ErrG = 0.731623500585556, ErrA = 0.46975712839048356\n",
      "Epoch = 444, ErrG = 0.7261549234390259, ErrA = 0.4604114852118073\n",
      "Epoch = 446, ErrG = 0.7160816192626953, ErrA = 0.40437656470264\n",
      "Epoch = 448, ErrG = 0.8277570307254791, ErrA = 0.5473129532377546\n",
      "Epoch = 450, ErrG = 0.7154689729213715, ErrA = 0.46002886977415375\n",
      "Epoch = 452, ErrG = 0.790570467710495, ErrA = 0.41651523947560537\n",
      "Epoch = 454, ErrG = 0.8395888209342957, ErrA = 0.4299057892446096\n",
      "Epoch = 456, ErrG = 0.7685035467147827, ErrA = 0.38265929829018813\n",
      "Epoch = 458, ErrG = 0.698228657245636, ErrA = 0.4712299112191734\n",
      "Epoch = 460, ErrG = 0.7654122412204742, ErrA = 0.46672989532817155\n",
      "Epoch = 462, ErrG = 0.7381218373775482, ErrA = 0.40098776909386896\n",
      "Epoch = 464, ErrG = 0.7517709136009216, ErrA = 0.4608190053453048\n",
      "Epoch = 466, ErrG = 0.7984527945518494, ErrA = 0.45003608129142475\n",
      "Epoch = 468, ErrG = 0.7352225482463837, ErrA = 0.46364299828807515\n",
      "Epoch = 470, ErrG = 0.730607271194458, ErrA = 0.4591426809007923\n",
      "Epoch = 472, ErrG = 0.7526934146881104, ErrA = 0.4494787631932316\n",
      "Epoch = 474, ErrG = 0.7710942924022675, ErrA = 0.44990555770345964\n",
      "Epoch = 476, ErrG = 0.7487759590148926, ErrA = 0.4536408471952503\n",
      "Epoch = 478, ErrG = 0.7742005586624146, ErrA = 0.4559031070869726\n",
      "Epoch = 480, ErrG = 0.7870703339576721, ErrA = 0.33270895383369253\n",
      "Epoch = 482, ErrG = 0.7096162736415863, ErrA = 0.45906971850975725\n",
      "Epoch = 484, ErrG = 0.8119874596595764, ErrA = 0.4458889648485638\n",
      "Epoch = 486, ErrG = 0.8288512527942657, ErrA = 0.49421749797572073\n",
      "Epoch = 488, ErrG = 0.7683495581150055, ErrA = 0.4710556954960339\n",
      "Epoch = 490, ErrG = 0.7661537230014801, ErrA = 0.46698062190262135\n",
      "Epoch = 492, ErrG = 0.8454202115535736, ErrA = 0.34678871432940167\n",
      "Epoch = 494, ErrG = 0.8176691234111786, ErrA = 0.47424114899088937\n",
      "Epoch = 496, ErrG = 0.7424041032791138, ErrA = 0.3130500581270705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 498, ErrG = 0.8722212314605713, ErrA = 0.4581546305174318\n",
      "Epoch = 500, ErrG = 0.7491079866886139, ErrA = 0.45177597298364464\n",
      "Epoch = 502, ErrG = 0.7745728194713593, ErrA = 0.431646080124968\n",
      "Epoch = 504, ErrG = 0.7889595925807953, ErrA = 0.46082764471066184\n",
      "Epoch = 506, ErrG = 0.7366111278533936, ErrA = 0.46207964653149247\n",
      "Epoch = 508, ErrG = 0.7318088412284851, ErrA = 0.35628407522259903\n",
      "Epoch = 510, ErrG = 0.8470337688922882, ErrA = 0.3935772370386985\n",
      "Epoch = 512, ErrG = 0.8028042912483215, ErrA = 0.45536067930515856\n",
      "Epoch = 514, ErrG = 0.7802965939044952, ErrA = 0.47379907468954724\n",
      "Epoch = 516, ErrG = 0.7577114105224609, ErrA = 0.4666667666460853\n",
      "Epoch = 518, ErrG = 0.7378373742103577, ErrA = 0.458883986226283\n",
      "Epoch = 520, ErrG = 0.777031272649765, ErrA = 0.45996388941421174\n",
      "Epoch = 522, ErrG = 0.7456507086753845, ErrA = 0.46248103469163954\n",
      "Epoch = 524, ErrG = 0.8133042454719543, ErrA = 0.46582059919213253\n",
      "Epoch = 526, ErrG = 0.8049535155296326, ErrA = 0.46748004326218506\n",
      "Epoch = 528, ErrG = 0.7485942840576172, ErrA = 0.45065508422218653\n",
      "Epoch = 530, ErrG = 0.7484121322631836, ErrA = 0.43755465872042504\n",
      "Epoch = 532, ErrG = 0.7659844160079956, ErrA = 0.4632237796516468\n",
      "Epoch = 534, ErrG = 0.7850546836853027, ErrA = 0.44714602842577733\n",
      "Epoch = 536, ErrG = 0.7520697712898254, ErrA = 0.4459493150970957\n",
      "Epoch = 538, ErrG = 0.7961528301239014, ErrA = 0.45559454833952867\n",
      "Epoch = 540, ErrG = 0.72419074177742, ErrA = 0.44519902889927226\n",
      "Epoch = 542, ErrG = 0.7977952659130096, ErrA = 0.3922552315731688\n",
      "Epoch = 544, ErrG = 0.8835775554180145, ErrA = 0.4615288015144567\n",
      "Epoch = 546, ErrG = 0.864838033914566, ErrA = 0.46772436033158254\n",
      "Epoch = 548, ErrG = 0.8129344880580902, ErrA = 0.43783565645086736\n",
      "Epoch = 550, ErrG = 0.7771709263324738, ErrA = 0.44275577645748854\n",
      "Epoch = 552, ErrG = 0.8010993003845215, ErrA = 0.4469550286109249\n",
      "Epoch = 554, ErrG = 0.7397554218769073, ErrA = 0.44970027685243014\n",
      "Epoch = 556, ErrG = 0.825665146112442, ErrA = 0.455331025388053\n",
      "Epoch = 558, ErrG = 0.8332692682743073, ErrA = 0.45553577330429107\n",
      "Epoch = 560, ErrG = 0.7128021419048309, ErrA = 0.45348773050742847\n",
      "Epoch = 562, ErrG = 0.81263267993927, ErrA = 0.3457119280161957\n",
      "Epoch = 564, ErrG = 0.7965181469917297, ErrA = 0.48579289750099025\n",
      "Epoch = 566, ErrG = 0.8238600194454193, ErrA = 0.42443418958767626\n",
      "Epoch = 568, ErrG = 0.7589401602745056, ErrA = 0.45088076915514347\n",
      "Epoch = 570, ErrG = 0.724471390247345, ErrA = 0.44381464389152825\n",
      "Epoch = 572, ErrG = 0.7770543396472931, ErrA = 0.44816923754600185\n",
      "Epoch = 574, ErrG = 0.7333681583404541, ErrA = 0.42415697385634604\n",
      "Epoch = 576, ErrG = 0.7271437346935272, ErrA = 0.3213086551889622\n",
      "Epoch = 578, ErrG = 0.6447990238666534, ErrA = 0.4042922037576015\n",
      "Epoch = 580, ErrG = 0.8347355127334595, ErrA = 0.5198097412164012\n",
      "Epoch = 582, ErrG = 0.856288492679596, ErrA = 0.5347386587721606\n",
      "Epoch = 584, ErrG = 0.85208860039711, ErrA = 0.4493682078512696\n",
      "Epoch = 586, ErrG = 0.8614064455032349, ErrA = 0.45599471128662117\n",
      "Epoch = 588, ErrG = 0.7946730256080627, ErrA = 0.4511354830804824\n",
      "Epoch = 590, ErrG = 0.9478136897087097, ErrA = 0.4465028701324627\n",
      "Epoch = 592, ErrG = 0.8772792518138885, ErrA = 0.2579459532474478\n",
      "Epoch = 594, ErrG = 0.7635049223899841, ErrA = 0.4433007495633016\n",
      "Epoch = 596, ErrG = 0.8707784414291382, ErrA = 0.42960737440929125\n",
      "Epoch = 598, ErrG = 0.7842960357666016, ErrA = 0.4632687548485895\n",
      "Epoch = 600, ErrG = 0.9329968690872192, ErrA = 0.4357417522308727\n",
      "Epoch = 602, ErrG = 0.95200315117836, ErrA = 0.45157153745822143\n",
      "Epoch = 604, ErrG = 0.9577278196811676, ErrA = 0.44284421696405235\n",
      "Epoch = 606, ErrG = 0.9346960783004761, ErrA = 0.4603936683367162\n",
      "Epoch = 608, ErrG = 0.7769030928611755, ErrA = 0.3810359894899496\n",
      "Epoch = 610, ErrG = 0.88060462474823, ErrA = 0.43940106003234786\n",
      "Epoch = 612, ErrG = 0.8677367866039276, ErrA = 0.4526523627185573\n",
      "Epoch = 614, ErrG = 0.9013304710388184, ErrA = 0.36167651736953604\n",
      "Epoch = 616, ErrG = 0.7371206283569336, ErrA = 0.4445989108644426\n",
      "Epoch = 618, ErrG = 0.8018956780433655, ErrA = 0.4434614830291442\n",
      "Epoch = 620, ErrG = 0.8427288234233856, ErrA = 0.457490720039156\n",
      "Epoch = 622, ErrG = 0.7859868109226227, ErrA = 0.45554111277063686\n",
      "Epoch = 624, ErrG = 0.7657858729362488, ErrA = 0.4384137149997211\n",
      "Epoch = 626, ErrG = 0.8416046500205994, ErrA = 0.46249754706029006\n",
      "Epoch = 628, ErrG = 0.808212548494339, ErrA = 0.44745513755090843\n",
      "Epoch = 630, ErrG = 0.9369635581970215, ErrA = 0.4354431807102325\n",
      "Epoch = 632, ErrG = 0.7154632806777954, ErrA = 0.4581225221530379\n",
      "Epoch = 634, ErrG = 0.606325626373291, ErrA = 0.4850596214697968\n",
      "Epoch = 636, ErrG = 0.8837416470050812, ErrA = 0.4423328074044548\n",
      "Epoch = 638, ErrG = 0.7917526662349701, ErrA = 0.48346946769743226\n",
      "Epoch = 640, ErrG = 0.7945796549320221, ErrA = 0.38023441084078513\n",
      "Epoch = 642, ErrG = 0.7079169750213623, ErrA = 0.4272437875624746\n",
      "Epoch = 644, ErrG = 0.660423070192337, ErrA = 0.4451813306368422\n",
      "Epoch = 646, ErrG = 0.9886527061462402, ErrA = 0.442153788850798\n",
      "Epoch = 648, ErrG = 0.8284912109375, ErrA = 0.4620396056949782\n",
      "Epoch = 650, ErrG = 0.8183205723762512, ErrA = 0.444729687878862\n",
      "Epoch = 652, ErrG = 0.7405913174152374, ErrA = 0.5743055373119811\n",
      "Epoch = 654, ErrG = 0.7727427184581757, ErrA = 0.4488293433338792\n",
      "Epoch = 656, ErrG = 0.7133713364601135, ErrA = 0.45174254744051723\n",
      "Epoch = 658, ErrG = 0.7809738218784332, ErrA = 0.433811829405992\n",
      "Epoch = 660, ErrG = 0.8160635232925415, ErrA = 0.2799638506597451\n",
      "Epoch = 662, ErrG = 0.7281859219074249, ErrA = 0.4560444198092834\n",
      "Epoch = 664, ErrG = 0.7493390440940857, ErrA = 0.44800153886171756\n",
      "Epoch = 666, ErrG = 0.7392912805080414, ErrA = 0.43535868522788707\n",
      "Epoch = 668, ErrG = 0.7419269680976868, ErrA = 0.22672747036752602\n",
      "Epoch = 670, ErrG = 0.8792935609817505, ErrA = 0.4222841212370743\n",
      "Epoch = 672, ErrG = 0.7734657824039459, ErrA = 0.45101732482968754\n",
      "Epoch = 674, ErrG = 0.7109618186950684, ErrA = 0.43562647385988384\n",
      "Epoch = 676, ErrG = 0.7944141030311584, ErrA = 0.4435998768603895\n",
      "Epoch = 678, ErrG = 0.8381923735141754, ErrA = 0.24121217347177057\n",
      "Epoch = 680, ErrG = 0.8727018237113953, ErrA = 0.43619311765117647\n",
      "Epoch = 682, ErrG = 0.7841627299785614, ErrA = 0.43695590148369473\n",
      "Epoch = 684, ErrG = 0.8662834167480469, ErrA = 0.4431545090046711\n",
      "Epoch = 686, ErrG = 0.8495096564292908, ErrA = 0.5613587218928539\n",
      "Epoch = 688, ErrG = 0.8658651411533356, ErrA = 0.332293205584089\n",
      "Epoch = 690, ErrG = 0.8071056306362152, ErrA = 0.4609514574209849\n",
      "Epoch = 692, ErrG = 0.9246188402175903, ErrA = 0.2575916551165089\n",
      "Epoch = 694, ErrG = 0.7300475835800171, ErrA = 0.42913578130173846\n",
      "Epoch = 696, ErrG = 0.8312381505966187, ErrA = 0.4254535626678262\n",
      "Epoch = 698, ErrG = 0.9194859564304352, ErrA = 0.3576241774717346\n",
      "Epoch = 700, ErrG = 0.7556600272655487, ErrA = 0.3077318850458444\n"
     ]
    }
   ],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "g_k = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "# netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "# optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, g_k = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, g_k, target))\n",
    "\n",
    "low_loss = 10\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#     for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "#         noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "#         ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % g_k ==0:\n",
    "#             # update D\n",
    "#             lossD = 0\n",
    "#             optimD.zero_grad()\n",
    "#             output = netd(ass_label)\n",
    "#             label.fill_(real_label)\n",
    "#             lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "#             lossD += lossD_real1.item()\n",
    "#             lossD_real1.backward()\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             output1 = netd(noass_label)\n",
    "#             lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "#             lossD += lossD_real2.item()\n",
    "#             lossD_real2.backward()\n",
    "\n",
    "#             fake = netg(img).detach()\n",
    "#             label.fill_(fake_label)\n",
    "#             output2 = netd(fake)\n",
    "#             lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "#             lossD += lossD_fake.item()\n",
    "#             lossD_fake.backward()\n",
    "\n",
    "#             optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake = netg(img).detach()\n",
    "            faked = th.cat((img, fake), 1)\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "#         if i % k ==0: \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        ]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  ]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3,\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, \n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}\\n'.format(\n",
    "            epoch, lossG/2, lossA/3\n",
    "        ))    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-10T03:05:11.264440Z",
     "start_time": "2019-05-10T03:05:11.221502Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from model_siGAN import NetG, NetD, NetA\n",
    "from data_set import *\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "ass_label, noass_label, img = dataset.getbatch(1)\n",
    "# ass_label, noass_label, img = dataset.getbatch(1)\n",
    "\n",
    "# dataset_test = CASIABDatasetForTest(data_dir=Data_Dir)\n",
    "# ass_label_test, noass_label_test, img_test = dataset_test.getbatch(1)\n",
    "# ass_label_test, noass_label_test, img_test = dataset_test.getbatch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T22:52:44.360471Z",
     "start_time": "2019-05-06T16:38:09.779397Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from model_siGAN import NetG, NetD, NetA\n",
    "from data_set import *\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import make_grid\n",
    "import visdom\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "Model_Name = 'Model_Triplet'\n",
    "if not os.path.isdir(Model_Name):\n",
    "    os.mkdir(Model_Name)\n",
    "    \n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "#     list(netd.children())[0].children(),\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netg.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "dataset_test = CASIABDatasetForTest(data_dir=Data_Dir)\n",
    "ass_label_test, noass_label_test, img_test = dataset_test.getbatch(300)\n",
    "ass_label_test = ass_label_test.to(device).to(th.float32)\n",
    "noass_label_test = noass_label_test.to(device).to(th.float32)\n",
    "img_test = img_test.to(device).to(th.float32)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.0001\n",
    "batchSize = 128\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr)\n",
    "# optimG = optim.Adam(netg.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "while iteration < 30000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    __, A = netg(img)\n",
    "    __, P = netg(ass_label)\n",
    "    __, N = netg(noass_label)\n",
    "    lossTriplet = F.triplet_margin_loss(A, P, N, margin=5)\n",
    "    lossGT = lossTriplet.item()\n",
    "    lossTriplet.backward()\n",
    "    optimG.step()\n",
    "    \n",
    "    iteration+=1\n",
    "    if iteration % 500 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            __, A_test = netg(img_test)\n",
    "            __, P_test = netg(ass_label_test)\n",
    "            __, N_test = netg(noass_label_test)\n",
    "            loss_test = F.triplet_margin_loss(A_test, P_test, N_test, margin=5)\n",
    "            loss_test = loss_test.item()\n",
    "            netg.train() #切換回去\n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrGT = {}, Test_ErrGT = {}\\n'.format(\n",
    "            iteration, lossGT, loss_test\n",
    "        ))\n",
    "        print('iter = {}, ErrGT = {}, Test_ErrGT = {}'.format(\n",
    "            iteration, lossGT, loss_test\n",
    "        ))\n",
    "\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration,iteration]]),\n",
    "                           Y=np.array([[lossGT, loss_test]]),\n",
    "                           opts=dict(\n",
    "                               title= Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossGT', 'lossGT_test']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration]]),\n",
    "                     Y=np.array([[lossGT, loss_test]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "            \n",
    "    if iteration % 2500 == 0:\n",
    "        state = {\n",
    "#             'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "#             'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Siamese and GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-29T21:13:30.999315Z",
     "start_time": "2019-05-29T14:16:28.502269Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "margin = 5\n",
    "target = '036'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, margin = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, margin, target))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "        label.fill_(real_label)\n",
    "        lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "        lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake, _ = netg(img)\n",
    "        label.fill_(fake_label)\n",
    "        output2 = netd(fake.detach())\n",
    "        lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "\n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        fake,_ = netg(img)\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "        lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "        lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "        label.fill_(fake_label)\n",
    "        output = neta(faked.detach())\n",
    "        lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "        \n",
    "        \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake, A = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "        \n",
    "        # constrain on generator\n",
    "        fake_ass, P = netg(ass_label)\n",
    "        fake_noass, N = netg(noass_label)\n",
    "        lossTriplet = F.triplet_margin_loss(fake, fake_ass, fake_noass, margin = margin)\n",
    "        lossG += lossTriplet.item()\n",
    "        lossTriplet.backward()\n",
    "        \n",
    "        # constrain on encoder\n",
    "#         __, P = netg(ass_label)\n",
    "#         __, N = netg(noass_label)\n",
    "#         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "#         lossG += lossTriplet.item()\n",
    "#         lossTriplet.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Siamese and GAN k times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-18T17:27:36.724552Z",
     "start_time": "2019-06-18T06:30:54.000065Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "margin = 10\n",
    "g_k = 2\n",
    "k = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr/3)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, margin = {}, g_k ={}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, margin, g_k, target))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         com_img = th.cat((noass_img, img, ass_img), 0)\n",
    "#         com_label = th.cat(( label_neg, label_anc, label_pos), 0)\n",
    "#         com_img = com_img.to(device).to(th.float32)\n",
    "#         com_label = com_label.to(device).to(th.float32)\n",
    "        \n",
    "#         if(i ==0):\n",
    "#             print(label_neg,label_anc,label_pos)\n",
    "#             print(com_label)\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape,com_img.shape, com_label.shape)\n",
    "        \n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "        \n",
    "        if i % g_k ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            optimD.zero_grad()\n",
    "            output = netd(ass_label)\n",
    "            label.fill_(real_label)\n",
    "            lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "            lossD += lossD_real1.item()\n",
    "            lossD_real1.backward()\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = netd(noass_label)\n",
    "            lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "            lossD += lossD_real2.item()\n",
    "            lossD_real2.backward()\n",
    "\n",
    "            fake, _ = netg(img)\n",
    "            label.fill_(fake_label)\n",
    "            output2 = netd(fake.detach()) #需要 detach 因為不希望更新fake的參數\n",
    "            lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "            lossD += lossD_fake.item()\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            optimD.step()\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            fake,_ = netg(img)\n",
    "            faked = th.cat((img, fake.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "            label.fill_(real_label)\n",
    "            output1 = neta(assd)\n",
    "            lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "            lossA += lossA_real1.item()\n",
    "            lossA_real1.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(noassd)\n",
    "            lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_real2.item()\n",
    "            lossA_real2.backward()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            output = neta(faked)\n",
    "            lossA_fake = F.binary_cross_entropy(output, label)\n",
    "            lossA += lossA_fake.item()\n",
    "            lossA_fake.backward()\n",
    "\n",
    "            optimA.step()\n",
    "        \n",
    "#     if i % k ==0: \n",
    "        # update G\n",
    "        lossG = 0\n",
    "        optimG.zero_grad()\n",
    "        fake, A = netg(img)\n",
    "        output = netd(fake)\n",
    "\n",
    "        label.fill_(real_label)\n",
    "        lossGD = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGD.item()\n",
    "        lossGD.backward(retain_graph=True)  ##這裡需要retain graph 因為他之後有需要fake，因此需要retain\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        output = neta(faked)\n",
    "        label.fill_(real_label)\n",
    "        lossGA = F.binary_cross_entropy(output, label)\n",
    "        lossG += lossGA.item()\n",
    "        lossGA.backward()\n",
    "        \n",
    "        ## new tripletloss\n",
    "        _, P = netg(ass_img)\n",
    "        __, N = netg(noass_img)\n",
    "        lossf = TripletLoss(margin) #因為之前的A都沒被使用過所以不會遺失，如果是拿fake ，LossGA就需要再retain graph\n",
    "        lossTriplet =lossf(A, P, N)\n",
    "        lossG += lossTriplet.item()\n",
    "        lossTriplet.backward()\n",
    "        \n",
    "#         ## new onlinetripletloss\n",
    "#         __, com = netg(com_img)\n",
    "#         loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "#         lossTriplet,len_triplet = loss_fn(com, com_label)\n",
    "#         lossG += lossTriplet.item()\n",
    "#         lossTriplet.backward()\n",
    "# #         print(lossTriplet.item(),len_triplet)\n",
    "        \n",
    "#         ## triplet loss\n",
    "#         __, P = netg(ass_img)\n",
    "#         __, N = netg(noass_img)\n",
    "#         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin) #因為之前的A都沒被使用過所以不會遺失，如果是拿fake ，LossGA就需要再retain graph\n",
    "#         lossG += lossTriplet.item()\n",
    "#         lossTriplet.backward()\n",
    "# #         if i%10==0:\n",
    "# #             print(\"tripletloss \",lossTriplet.item())\n",
    "\n",
    "        ## tripletloss no negative\n",
    "#         N_plus = th.zeros((A.size()), requires_grad=False).to(device)\n",
    "#         lossTriplet_AP = F.triplet_margin_loss(A, P, N_plus, margin = margin)\n",
    "#         lossG += lossTriplet_AP.item()\n",
    "#         lossTriplet += lossTriplet_AP\n",
    "#         lossTriplet.backward()\n",
    "\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG  Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from PixelDT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-13T15:13:36.331308Z",
     "start_time": "2019-04-13T08:01:32.315792Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir)\n",
    "\n",
    "iteration = 0\n",
    "lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 128\n",
    "\n",
    "real_label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "fake_label = th.ones((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr)\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr)\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr)\n",
    "\n",
    "print('Training starts')\n",
    "while iteration < 40000:\n",
    "    ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "    ass_label = ass_label.to(device).to(th.float32)\n",
    "    noass_label = noass_label.to(device).to(th.float32)\n",
    "    img = img.to(device).to(th.float32)\n",
    "    \n",
    "    # update D\n",
    "    lossD = 0\n",
    "    optimD.zero_grad()\n",
    "    output = netd(ass_label)\n",
    "#     label.fill_(real_label)\n",
    "    lossD_real1 = F.binary_cross_entropy(output, real_label)\n",
    "#     lossD += lossD_real1.item()\n",
    "#     lossD_real1.backward()\n",
    "\n",
    "#     label.fill_(real_label)\n",
    "    output1 = netd(noass_label)\n",
    "    lossD_real2 = F.binary_cross_entropy(output1, real_label)\n",
    "#     lossD += lossD_real2.item()\n",
    "#     lossD_real2.backward()\n",
    "\n",
    "    fake = netg(img).detach()\n",
    "#     label.fill_(fake_label)\n",
    "    output2 = netd(fake)\n",
    "    lossD_fake = F.binary_cross_entropy(output2, fake_label)\n",
    "#     lossD += lossD_fake.item()\n",
    "#     lossD_fake.backward()\n",
    "    lossD = (lossD_real1+ lossD_real2+ lossD_fake)/3\n",
    "    lossD.backward()\n",
    "\n",
    "    lossD_item = lossD.item()\n",
    "    optimD.step()\n",
    "    \n",
    "    # update A\n",
    "    lossA = 0\n",
    "    optimA.zero_grad()\n",
    "    assd = th.cat((img, ass_label), 1)\n",
    "    noassd = th.cat((img, noass_label), 1)\n",
    "    fake = netg(img).detach()\n",
    "    faked = th.cat((img, fake), 1)\n",
    "\n",
    "#     label.fill_(real_label)\n",
    "    output = neta(assd)\n",
    "    lossA_real1 = F.binary_cross_entropy(output, real_label)\n",
    "#     lossA += lossA_real1.item()\n",
    "#     lossA_real1.backward()\n",
    "\n",
    "#     label.fill_(fake_label)\n",
    "    output1 = neta(noassd)\n",
    "    lossA_real2 = F.binary_cross_entropy(output1, fake_label)\n",
    "#     lossA += lossA_real2.item()\n",
    "#     lossA_real2.backward()\n",
    "\n",
    "#     label.fill_(fake_label)\n",
    "    output2 = neta(faked)\n",
    "    lossA_fake = F.binary_cross_entropy(output2, fake_label)\n",
    "#     lossA += lossA_fake.item()\n",
    "#     lossA_fake.backward()\n",
    "    lossA = (lossA_real1+ lossA_real2 +lossA_fake)/3\n",
    "    lossA.backward()\n",
    "    \n",
    "    lossA_item = lossA.item()\n",
    "    optimA.step()\n",
    "    \n",
    "    # update G\n",
    "    lossG = 0\n",
    "    optimG.zero_grad()\n",
    "    fake = netg(img)\n",
    "    output = netd(fake)\n",
    "#     label.fill_(real_label)\n",
    "    lossGD = F.binary_cross_entropy(output, real_label)\n",
    "#     lossG += lossGD.item()\n",
    "#     lossGD.backward(retain_graph=True)\n",
    "\n",
    "    faked = th.cat((img, fake), 1)\n",
    "    output = neta(faked)\n",
    "#     label.fill_(real_label)\n",
    "    lossGA = F.binary_cross_entropy(output, real_label)\n",
    "#     lossG += lossGA.item()\n",
    "#     lossGA.backward()\n",
    "    lossG = (lossGD + lossGA)/2\n",
    "    lossG.backward()\n",
    "    \n",
    "    lossG_item = lossG.item()\n",
    "    optimG.step()\n",
    "\n",
    "    iteration += 1\n",
    "    \n",
    "    if iteration % 20 == 0:\n",
    "        with th.no_grad():\n",
    "            netg.eval()  #切換\n",
    "            fake = netg(img) \n",
    "            netg.train() #切換回去\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 20).cpu().numpy()\n",
    "        if win1 is None:\n",
    "            win1 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train'))\n",
    "        else:\n",
    "            vis.image(display, win=win1)\n",
    "    if iteration % 5000 == 0 or iteration==500:\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_Name+'/snapshot'+ Model_Name +'_%d.t7' % iteration)\n",
    "        with open(Model_Name+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('iter = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            iteration, lossG_item, lossA_item, lossD_item\n",
    "        ))\n",
    "        print('iter = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            iteration, lossG_item, lossA_item, lossD_item\n",
    "        ))\n",
    "    if iteration % 5000==0 or iteration==10 or iteration==500:\n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[iteration, iteration,\n",
    "                                        iteration]]),\n",
    "                           Y=np.array([[lossG_item, lossA_item, lossD_item]]),\n",
    "                           opts=dict(\n",
    "                               title='GaitGAN',\n",
    "                               ylabel='loss',\n",
    "                               xlabel='iterations',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[iteration, iteration,\n",
    "                                  iteration]]),\n",
    "                     Y=np.array([[lossG_item, lossA_item, lossD_item]]),\n",
    "                     win=win,\n",
    "                     update='append')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN from gaitgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-19T11:24:25.000385Z",
     "start_time": "2019-05-19T06:44:16.638708Z"
    }
   },
   "outputs": [],
   "source": [
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 2\n",
    "target = '090'\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "label = th.zeros((batchSize, 1), requires_grad=False).to(device)\n",
    "optimG = optim.RMSprop(netg.parameters(), lr=lr/2)\n",
    "optimD = optim.RMSprop(netd.parameters(), lr=lr/3)\n",
    "optimA = optim.RMSprop(neta.parameters(), lr=lr/3)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, n_critic = {}, target={} \\n'.format(\n",
    "            epoches, lr, batchSize, n_critic, target))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "#         label.fill_(real_label)\n",
    "#         lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD_real1 = -th.mean(output)\n",
    "        lossD += lossD_real1.item()\n",
    "        lossD_real1.backward()\n",
    "\n",
    "#         label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "#         lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD_real2 = -th.mean(output1)\n",
    "        lossD += lossD_real2.item()\n",
    "        lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "#         label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "#         lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD_fake = th.mean(output2)\n",
    "        lossD += lossD_fake.item()\n",
    "        lossD_fake.backward()\n",
    "\n",
    "        optimD.step()\n",
    "        \n",
    "        for p in netd.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        fake = netg(img).detach()\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "#         label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "#         lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA_real1 = -th.mean(output1)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_real1.backward()\n",
    "\n",
    "#         label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "#         lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA_real2 = th.mean(output)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_real2.backward()\n",
    "\n",
    "#         label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "#         lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA_fake = th.mean(output)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_fake.backward()\n",
    "\n",
    "        optimA.step()\n",
    "    \n",
    "        for p in neta.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "        if i % n_critic == 0:\n",
    "            lossG = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossGD = -th.mean(output)\n",
    "            lossG += lossGD.item()\n",
    "            lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "#             label.fill_(real_label)\n",
    "#             lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossGA = -th.mean(output)\n",
    "            lossG += lossGA.item()\n",
    "            lossGA.backward()\n",
    "\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    \n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-02T17:54:50.674179Z",
     "start_time": "2019-06-02T12:25:08.423036Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "lr = 0.00002\n",
    "# lr = 0.0002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 5\n",
    "target = '090'\n",
    "lambda_gp = 10\n",
    "beta1 = 0\n",
    "beta2 = 0.999\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, lr = {}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, lr, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        lossD_ = 0\n",
    "        optimD.zero_grad()\n",
    "        output = netd(ass_label)\n",
    "#         label.fill_(real_label)\n",
    "#         lossD_real1 = F.binary_cross_entropy(output, label)\n",
    "        lossD_real1 = -th.mean(output)\n",
    "        lossD_ += lossD_real1\n",
    "        lossD += lossD_real1.item()\n",
    "#         lossD_real1.backward()\n",
    "\n",
    "#         label.fill_(real_label)\n",
    "        output1 = netd(noass_label)\n",
    "#         lossD_real2 = F.binary_cross_entropy(output1, label)\n",
    "        lossD_real2 = -th.mean(output1)\n",
    "        lossD_ += lossD_real2\n",
    "        lossD += lossD_real2.item()\n",
    "#         lossD_real2.backward()\n",
    "\n",
    "        fake = netg(img).detach()\n",
    "#         label.fill_(fake_label)\n",
    "        output2 = netd(fake)\n",
    "#         lossD_fake = F.binary_cross_entropy(output2, label)\n",
    "        lossD_fake = th.mean(output2)\n",
    "        lossD_ += lossD_fake\n",
    "        lossD += lossD_fake.item()\n",
    "        gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "#         lossD_fake.backward()\n",
    "        lossD_ = lossD_/3 + lambda_gp * gradient_penalty\n",
    "        lossD_.backward()\n",
    "\n",
    "        optimD.step()\n",
    "        \n",
    "#         for p in netd.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        lossA_ = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        fake = netg(img).detach()\n",
    "        faked = th.cat((img, fake), 1)\n",
    "\n",
    "#         label.fill_(real_label)\n",
    "        output1 = neta(assd)\n",
    "#         lossA_real1 = F.binary_cross_entropy(output1, label)\n",
    "        lossA_real1 = -th.mean(output1)\n",
    "        lossA += lossA_real1.item()\n",
    "        lossA_ += lossA_real1\n",
    "#         lossA_real1.backward()\n",
    "\n",
    "#         label.fill_(fake_label)\n",
    "        output = neta(noassd)\n",
    "#         lossA_real2 = F.binary_cross_entropy(output, label)\n",
    "        lossA_real2 = th.mean(output)\n",
    "        lossA += lossA_real2.item()\n",
    "        lossA_ += lossA_real2\n",
    "#         lossA_real2.backward()\n",
    "\n",
    "#         label.fill_(fake_label)\n",
    "        output = neta(faked)\n",
    "#         lossA_fake = F.binary_cross_entropy(output, label)\n",
    "        lossA_fake = th.mean(output)\n",
    "        lossA += lossA_fake.item()\n",
    "        lossA_ += lossA_fake\n",
    "#         lossA_fake.backward()\n",
    "        gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "        lossA_ = lossA_/3 + lambda_gp * gradient_penalty\n",
    "        \n",
    "        lossA_.backward()\n",
    "        optimA.step()\n",
    "    \n",
    "#         for p in neta.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "        if i % n_critic == 0:\n",
    "            lossG = 0\n",
    "            lossG_ = 0\n",
    "            optimG.zero_grad()\n",
    "            fake = netg(img)\n",
    "            output = netd(fake)\n",
    "\n",
    "#             label.fill_(real_label)\n",
    "#             lossGD = F.binary_cross_entropy(output, label)\n",
    "            lossGD = -th.mean(output)\n",
    "            lossG += lossGD.item()\n",
    "            lossG_ += lossGD\n",
    "#             lossGD.backward(retain_graph=True)\n",
    "\n",
    "            faked = th.cat((img, fake), 1)\n",
    "            output = neta(faked)\n",
    "#             label.fill_(real_label)\n",
    "#             lossGA = F.binary_cross_entropy(output, label)\n",
    "            lossGA = -th.mean(output)\n",
    "            lossG += lossGA.item()\n",
    "            lossG_ += lossGA\n",
    "#             lossGA.backward()\n",
    "            lossG_ = lossG_/2\n",
    "            lossG_.backward(retain_graph=True)\n",
    "            optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN (hing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T00:07:22.217162Z",
     "start_time": "2019-06-05T16:58:50.881140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "# lr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 0\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, dlr, glr, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        # update D\n",
    "        lossD = 0\n",
    "        lossD_ = 0\n",
    "        optimD.zero_grad()\n",
    "        d_out_assreal,dr1 = netd(ass_label)\n",
    "        d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "        lossD_ += d_loss_assreal\n",
    "        lossD += d_loss_assreal.item()\n",
    "\n",
    "        d_out_noassreal,dr2 = netd(noass_label)\n",
    "        d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "        lossD_ += d_loss_noassreal\n",
    "        lossD += d_loss_noassreal.item()\n",
    "\n",
    "        fake, gf1 = netg(img)\n",
    "        d_out_fake, df1 = netd(fake.detach())  #需要 detach 因為不希望更新fake的參數\n",
    "        d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "        lossD_ += d_loss_fake\n",
    "        lossD += d_loss_fake.item()\n",
    "#         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "        lossD_ = lossD_/3\n",
    "        lossD_.backward()\n",
    "        optimD.step()\n",
    "        \n",
    "#         for p in netd.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        lossA_ = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked, gf1 = netg(img)\n",
    "        faked = th.cat((img, faked.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "        d_out_assreal,dr1 = neta(assd)\n",
    "        d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "        lossA += d_loss_assreal.item()\n",
    "        lossA_ += d_loss_assreal\n",
    "\n",
    "        d_out_noassreal,dr2 = neta(noassd)\n",
    "        d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "        lossA_ += d_loss_noassreal\n",
    "        lossA += d_loss_noassreal.item()\n",
    "        \n",
    "        d_out_faked, df3 = neta(faked)\n",
    "        d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "        lossA_ += d_loss_faked\n",
    "        lossA += d_loss_faked.item()\n",
    "#         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "        lossA_ = lossA_/3\n",
    "        lossA_.backward()\n",
    "        optimA.step()\n",
    "    \n",
    "#         for p in neta.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "#         if i % n_critic == 0:\n",
    "        lossG = 0\n",
    "        lossG_ = 0\n",
    "        optimG.zero_grad()\n",
    "        fake,_= netg(img)\n",
    "        g_out_fake,_ = netd(fake)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "        lossG += g_loss_fake.item()\n",
    "        lossG_ += g_loss_fake\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        g_out_faked,_ = neta(faked)\n",
    "        g_loss_faked = - g_out_faked.mean()\n",
    "        lossG += g_loss_faked.item()\n",
    "        lossG_ += g_loss_faked\n",
    "        \n",
    "        lossG_ = lossG_/2\n",
    "        lossG_.backward(retain_graph=True) ##其實這裡也不需要retain graph 因為他只 backward 一次；\n",
    "        #如果爾後有要再backward，第一次就需要retain graph\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA GaitGAN (WGAN-GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T00:07:22.217162Z",
     "start_time": "2019-06-05T16:58:50.881140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "# lr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 0\n",
    "target = '090'\n",
    "lambda_gp = 10\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, dlr = {}, glr={}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, dlr, glr, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "    for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        \n",
    "        \n",
    "        # update D\n",
    "        lossD = 0\n",
    "        lossD_ = 0\n",
    "        optimD.zero_grad()\n",
    "        d_out_assreal,dr1 = netd(ass_label)\n",
    "        d_loss_assreal = -th.mean(d_out_assreal)\n",
    "\n",
    "        lossD_ += d_loss_assreal\n",
    "        lossD += d_loss_assreal.item()\n",
    "\n",
    "        d_out_noassreal,dr2 = netd(noass_label)\n",
    "        d_loss_noassreal = -th.mean(d_out_noassreal)\n",
    "\n",
    "        lossD_ += d_loss_noassreal\n",
    "        lossD += d_loss_noassreal.item()\n",
    "\n",
    "        fake, gf1 = netg(img)\n",
    "        d_out_fake, df1 = netd(fake.detach())  #需要 detach 因為不希望更新fake的參數\n",
    "        d_loss_fake = th.mean(d_out_fake)\n",
    "\n",
    "        lossD_ += d_loss_fake\n",
    "        lossD += d_loss_fake.item()\n",
    "        gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "        lossD_ = lossD_/3 + lambda_gp * gradient_penalty\n",
    "#         lossD_ = lossD_/3\n",
    "        lossD_.backward()\n",
    "        optimD.step()\n",
    "        \n",
    "            \n",
    "        # update A\n",
    "        lossA = 0\n",
    "        lossA_ = 0\n",
    "        optimA.zero_grad()\n",
    "        assd = th.cat((img, ass_label), 1)\n",
    "        noassd = th.cat((img, noass_label), 1)\n",
    "        faked, gf1 = netg(img)\n",
    "        faked = th.cat((img, faked.detach()), 1)  #需要 detach 因為不希望更新fake的參數\n",
    "\n",
    "        d_out_assreal,dr1 = neta(assd)\n",
    "        d_loss_assreal = -th.mean(d_out_assreal)\n",
    "        lossA += d_loss_assreal.item()\n",
    "        lossA_ += d_loss_assreal\n",
    "\n",
    "        d_out_noassreal,dr2 = neta(noassd)\n",
    "        d_loss_noassreal = th.mean(d_out_noassreal)\n",
    "\n",
    "        lossA_ += d_loss_noassreal\n",
    "        lossA += d_loss_noassreal.item()\n",
    "        \n",
    "        d_out_faked, df3 = neta(faked)\n",
    "        d_loss_faked = th.mean(d_out_faked)\n",
    "\n",
    "        lossA_ += d_loss_faked\n",
    "        lossA += d_loss_faked.item()\n",
    "        gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "        lossA_ = lossA_/3 + lambda_gp * gradient_penalty\n",
    "#         lossA_ = lossA_/3\n",
    "        lossA_.backward()\n",
    "        optimA.step()\n",
    "\n",
    "            \n",
    "        # update G\n",
    "#         if i % n_critic == 0:\n",
    "        lossG = 0\n",
    "        lossG_ = 0\n",
    "        optimG.zero_grad()\n",
    "        fake,_= netg(img)\n",
    "        g_out_fake,_ = netd(fake)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "        lossG += g_loss_fake.item()\n",
    "        lossG_ += g_loss_fake\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        g_out_faked,_ = neta(faked)\n",
    "        g_loss_faked = - g_out_faked.mean()\n",
    "        lossG += g_loss_faked.item()\n",
    "        lossG_ += g_loss_faked\n",
    "        \n",
    "        lossG_ = lossG_/2\n",
    "        lossG_.backward(retain_graph=True) ##其實這裡也不需要retain graph 因為他只 backward 一次；\n",
    "        #如果爾後有要再backward，第一次就需要retain graph\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/2, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/2)<low_loss:  \n",
    "        low_loss = lossG/2\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/2, lossA/3, lossD/3\n",
    "        ))           \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine siamese and SAGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-06T11:04:01.107626Z",
     "start_time": "2019-07-06T04:16:43.132497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n",
      "Epoch = 2, ErrG = 1.9260542591412861, ErrTri = 5.951812744140625, ErrA = 0.676393223926425, ErrD = 0.6965182224909464, Gattn=-0.003843697952106595, Dattn=0.0010151999304071069, Aattn=4.331633681431413e-05\n",
      "Epoch = 4, ErrG = 1.6584657430648804, ErrTri = 5.226146221160889, ErrA = 0.6802028510719538, ErrD = 0.6874451587597529, Gattn=-0.005840306170284748, Dattn=0.0007879249169491231, Aattn=5.519977639778517e-05\n",
      "Epoch = 6, ErrG = 1.7611311674118042, ErrTri = 5.390015125274658, ErrA = 0.6771195195615292, ErrD = 0.7037542636195818, Gattn=-0.0068143089301884174, Dattn=0.0010411073453724384, Aattn=2.1014287995058112e-05\n",
      "Epoch = 8, ErrG = 1.2754840453465779, ErrTri = 3.8532814979553223, ErrA = 0.6971508264541626, ErrD = 0.698284812271595, Gattn=-0.007755768019706011, Dattn=0.002113168127834797, Aattn=-3.813387593254447e-05\n",
      "Epoch = 10, ErrG = 1.2904465595881145, ErrTri = 3.841475486755371, ErrA = 0.6739893381794294, ErrD = 0.6956908404827118, Gattn=-0.00863258633762598, Dattn=0.0032977983355522156, Aattn=4.6106524678179994e-05\n",
      "Epoch = 12, ErrG = 1.2255411545435588, ErrTri = 3.6979048252105713, ErrA = 0.6867261603474617, ErrD = 0.6956596970558167, Gattn=-0.00929893646389246, Dattn=0.004571781028062105, Aattn=3.625575118348934e-05\n",
      "Epoch = 14, ErrG = 1.334749440352122, ErrTri = 4.094287872314453, ErrA = 0.6747587987532219, ErrD = 0.6940268576145172, Gattn=-0.009869836270809174, Dattn=0.005605579353868961, Aattn=1.7929838577401824e-05\n",
      "Epoch = 16, ErrG = 1.0572414795557659, ErrTri = 3.3477609157562256, ErrA = 0.6735853341718515, ErrD = 0.6770934648811817, Gattn=-0.010418910533189774, Dattn=0.006516698282212019, Aattn=-4.458274634089321e-05\n",
      "Epoch = 18, ErrG = 1.0154287815093994, ErrTri = 3.134014129638672, ErrA = 0.6721265837550163, ErrD = 0.6897746995091438, Gattn=-0.010951853357255459, Dattn=0.007311555091291666, Aattn=-3.1129927720030537e-06\n",
      "Epoch = 20, ErrG = 1.2476414442062378, ErrTri = 3.7936787605285645, ErrA = 0.6835663368304571, ErrD = 0.688090868294239, Gattn=-0.011381519958376884, Dattn=0.00803554430603981, Aattn=-2.9715089112869464e-05\n",
      "Epoch = 22, ErrG = 1.4563865065574646, ErrTri = 4.499532699584961, ErrA = 0.6761107457180818, ErrD = 0.6816523484885693, Gattn=-0.011771020479500294, Dattn=0.008676335215568542, Aattn=-2.4453431251458824e-05\n",
      "Epoch = 24, ErrG = 1.1144258578618367, ErrTri = 3.331228017807007, ErrA = 0.6704936871925989, ErrD = 0.6863577316204706, Gattn=-0.012126930989325047, Dattn=0.009353388100862503, Aattn=-7.313553214771673e-05\n",
      "Epoch = 26, ErrG = 1.1723878582318623, ErrTri = 3.5293376445770264, ErrA = 0.6690825950354338, ErrD = 0.6862414280573527, Gattn=-0.01247886661440134, Dattn=0.01019931212067604, Aattn=-6.86195126036182e-05\n",
      "Epoch = 28, ErrG = 1.1290996273358662, ErrTri = 3.407289743423462, ErrA = 0.6690228891869386, ErrD = 0.6851005032658577, Gattn=-0.012773197144269943, Dattn=0.011004753410816193, Aattn=-9.616614261176437e-05\n",
      "Epoch = 30, ErrG = 0.9182340701421102, ErrTri = 2.7664661407470703, ErrA = 0.6729279421269894, ErrD = 0.6855666736761729, Gattn=-0.013145522214472294, Dattn=0.01173508632928133, Aattn=-4.641944178729318e-05\n",
      "Epoch = 32, ErrG = 1.0509565273920696, ErrTri = 3.1514649391174316, ErrA = 0.6682249717414379, ErrD = 0.6848702244460583, Gattn=-0.013445206917822361, Dattn=0.012436565943062305, Aattn=-4.9439524445915595e-05\n",
      "Epoch = 34, ErrG = 0.8427616755167643, ErrTri = 2.6378841400146484, ErrA = 0.6758423857390881, ErrD = 0.6797804906964302, Gattn=-0.01373202446848154, Dattn=0.013158740475773811, Aattn=-9.640540520194918e-05\n",
      "Epoch = 36, ErrG = 1.2055169343948364, ErrTri = 3.671049118041992, ErrA = 0.6682358340670665, ErrD = 0.6801963200171789, Gattn=-0.014049236662685871, Dattn=0.013985245488584042, Aattn=-6.260797817958519e-05\n",
      "Epoch = 38, ErrG = 1.1581151088078816, ErrTri = 3.49638032913208, ErrA = 0.6692079299439987, ErrD = 0.6787622136374315, Gattn=-0.014307783916592598, Dattn=0.014839768409729004, Aattn=-5.579112621489912e-05\n",
      "Epoch = 40, ErrG = 1.2743364175160725, ErrTri = 3.860781669616699, ErrA = 0.6685429066419601, ErrD = 0.6804529974857966, Gattn=-0.014586989767849445, Dattn=0.015818607062101364, Aattn=-7.953539170557633e-05\n",
      "Epoch = 42, ErrG = 1.0076117118199666, ErrTri = 3.0390686988830566, ErrA = 0.6684224735945463, ErrD = 0.6803035500148932, Gattn=-0.014723346568644047, Dattn=0.016662703827023506, Aattn=-0.00022838858421891928\n",
      "Epoch = 44, ErrG = 0.8831380804379781, ErrTri = 2.701401710510254, ErrA = 0.66751795510451, ErrD = 0.6797837441166242, Gattn=-0.015009451657533646, Dattn=0.017728541046380997, Aattn=-0.0002256809821119532\n",
      "Epoch = 46, ErrG = 1.2168780167897542, ErrTri = 3.681468963623047, ErrA = 0.6683234771092733, ErrD = 0.6761999254425367, Gattn=-0.015251235105097294, Dattn=0.018886998295783997, Aattn=-0.0002411169116385281\n",
      "Epoch = 48, ErrG = 0.9338541626930237, ErrTri = 2.819143533706665, ErrA = 0.6693527655055126, ErrD = 0.6756704437235991, Gattn=-0.015463756397366524, Dattn=0.020056433975696564, Aattn=-0.0004640638071577996\n",
      "Epoch = 50, ErrG = 0.9426736036936442, ErrTri = 2.883419990539551, ErrA = 0.6680709732075533, ErrD = 0.6793802219132582, Gattn=-0.01571446843445301, Dattn=0.021642662584781647, Aattn=-0.0008884866256266832\n",
      "Epoch = 52, ErrG = 0.7246087789535522, ErrTri = 2.2041616439819336, ErrA = 0.6683542095124722, ErrD = 0.6788365120689074, Gattn=-0.015904627740383148, Dattn=0.023087160661816597, Aattn=-0.0010498928604647517\n",
      "Epoch = 54, ErrG = 0.8421016534169515, ErrTri = 2.5396499633789062, ErrA = 0.6716860663145781, ErrD = 0.6789504401385784, Gattn=-0.01609784923493862, Dattn=0.024885807186365128, Aattn=-0.0016608800506219268\n",
      "Epoch = 56, ErrG = 1.0780216256777446, ErrTri = 3.329263210296631, ErrA = 0.6707496158778667, ErrD = 0.6775878096620241, Gattn=-0.01618870347738266, Dattn=0.026673678308725357, Aattn=-0.0021279677748680115\n",
      "Epoch = 58, ErrG = 1.0080917874972026, ErrTri = 3.0570104122161865, ErrA = 0.6686854424575964, ErrD = 0.6781687947611014, Gattn=-0.016421815380454063, Dattn=0.028214726597070694, Aattn=-0.0026201149448752403\n",
      "Epoch = 60, ErrG = 0.9250070055325826, ErrTri = 2.8208601474761963, ErrA = 0.667320633927981, ErrD = 0.6767509380976359, Gattn=-0.016504328697919846, Dattn=0.02980138547718525, Aattn=-0.0030389002058655024\n",
      "Epoch = 62, ErrG = 0.6397353808085123, ErrTri = 1.9266688823699951, ErrA = 0.6733178477734327, ErrD = 0.6773461053768793, Gattn=-0.016723668202757835, Dattn=0.031075015664100647, Aattn=-0.00362873962149024\n",
      "Epoch = 64, ErrG = 0.8255672057469686, ErrTri = 2.559732437133789, ErrA = 0.6698942140986522, ErrD = 0.6765992057820162, Gattn=-0.016824306920170784, Dattn=0.032226476818323135, Aattn=-0.00378457666374743\n",
      "Epoch = 66, ErrG = 0.8855210145314535, ErrTri = 2.7251367568969727, ErrA = 0.6690749494979779, ErrD = 0.6755274583896002, Gattn=-0.01703896000981331, Dattn=0.033167764544487, Aattn=-0.004151143599301577\n",
      "Epoch = 68, ErrG = 1.0185762643814087, ErrTri = 3.090559482574463, ErrA = 0.6675433752437433, ErrD = 0.6775804633895556, Gattn=-0.017127512022852898, Dattn=0.034050531685352325, Aattn=-0.004440248478204012\n",
      "Epoch = 70, ErrG = 0.5801812807718912, ErrTri = 1.754931092262268, ErrA = 0.6672699848810831, ErrD = 0.676503191391627, Gattn=-0.017312414944171906, Dattn=0.034819912165403366, Aattn=-0.0048478445969522\n",
      "Epoch = 72, ErrG = 0.5045252243677775, ErrTri = 1.6200237274169922, ErrA = 0.6732368879020214, ErrD = 0.6744926882286867, Gattn=-0.017535967752337456, Dattn=0.03547695279121399, Aattn=-0.0051314630545675755\n",
      "Epoch = 74, ErrG = 0.6554102500279745, ErrTri = 2.0531558990478516, ErrA = 0.6676217336207628, ErrD = 0.6761255028347174, Gattn=-0.0176717396825552, Dattn=0.03602339327335358, Aattn=-0.00536109646782279\n",
      "Epoch = 76, ErrG = 0.725937287012736, ErrTri = 2.1983165740966797, ErrA = 0.6664580851793289, ErrD = 0.6750717777758837, Gattn=-0.017760679125785828, Dattn=0.036569103598594666, Aattn=-0.005736133083701134\n",
      "Epoch = 78, ErrG = 0.620105504989624, ErrTri = 1.9672112464904785, ErrA = 0.6692142939815918, ErrD = 0.6741798613220453, Gattn=-0.017924554646015167, Dattn=0.037040263414382935, Aattn=-0.005970319267362356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 80, ErrG = 0.35619552930196124, ErrTri = 1.1775492429733276, ErrA = 0.6695427081237236, ErrD = 0.6721634231507778, Gattn=-0.01801953837275505, Dattn=0.037466391921043396, Aattn=-0.006200551055371761\n",
      "Epoch = 82, ErrG = 0.6228386163711548, ErrTri = 1.893239974975586, ErrA = 0.6658571660518646, ErrD = 0.6740605961531401, Gattn=-0.018170703202486038, Dattn=0.0378650426864624, Aattn=-0.006782026030123234\n",
      "Epoch = 84, ErrG = 0.7426910797754923, ErrTri = 2.2517428398132324, ErrA = 0.66833905937771, ErrD = 0.6767601855099201, Gattn=-0.01821422390639782, Dattn=0.03823858126997948, Aattn=-0.007006083615124226\n",
      "Epoch = 86, ErrG = 0.6266598502794901, ErrTri = 1.9032856225967407, ErrA = 0.668173398822546, ErrD = 0.6745888255536556, Gattn=-0.018352419137954712, Dattn=0.03859074413776398, Aattn=-0.007284077815711498\n",
      "Epoch = 88, ErrG = 0.40512855847676593, ErrTri = 1.3287544250488281, ErrA = 0.6693551825980345, ErrD = 0.6740432791411877, Gattn=-0.01846087910234928, Dattn=0.03890705108642578, Aattn=-0.007550443522632122\n",
      "Epoch = 90, ErrG = 0.5314389864603678, ErrTri = 1.64070725440979, ErrA = 0.6792312252024809, ErrD = 0.6754652336239815, Gattn=-0.01851818896830082, Dattn=0.0391915999352932, Aattn=-0.008305433206260204\n",
      "Epoch = 92, ErrG = 0.7110600074132284, ErrTri = 2.1458144187927246, ErrA = 0.6664232977976402, ErrD = 0.6742663607001305, Gattn=-0.018673017621040344, Dattn=0.03947355970740318, Aattn=-0.008414304815232754\n",
      "Epoch = 94, ErrG = 0.5876603523890177, ErrTri = 1.857118844985962, ErrA = 0.6690191415448984, ErrD = 0.6750941313803196, Gattn=-0.0187363438308239, Dattn=0.039732832461595535, Aattn=-0.008620236068964005\n",
      "Epoch = 96, ErrG = 0.7544556458791097, ErrTri = 2.312340497970581, ErrA = 0.668733254695932, ErrD = 0.6739380906025568, Gattn=-0.018846550956368446, Dattn=0.03996583819389343, Aattn=-0.008969716727733612\n",
      "Epoch = 98, ErrG = 0.5051829020182291, ErrTri = 1.540670394897461, ErrA = 0.6787998974323273, ErrD = 0.6742590187738339, Gattn=-0.01900569163262844, Dattn=0.0402052104473114, Aattn=-0.009284124709665775\n",
      "Epoch = 100, ErrG = 0.5480361779530843, ErrTri = 1.7165415287017822, ErrA = 0.6670681616912285, ErrD = 0.6750413862367471, Gattn=-0.01910717412829399, Dattn=0.040430039167404175, Aattn=-0.010479440912604332\n",
      "Epoch = 102, ErrG = 0.5235535701115926, ErrTri = 1.5750665664672852, ErrA = 0.666901179899772, ErrD = 0.673810642833511, Gattn=-0.01924281008541584, Dattn=0.0406394861638546, Aattn=-0.011220568791031837\n",
      "Epoch = 104, ErrG = 0.5375109910964966, ErrTri = 1.644960880279541, ErrA = 0.6643084219346443, ErrD = 0.6693742014467716, Gattn=-0.01928783766925335, Dattn=0.0408334955573082, Aattn=-0.011842606589198112\n",
      "Epoch = 106, ErrG = 0.7321071028709412, ErrTri = 2.262845039367676, ErrA = 0.6838258604208628, ErrD = 0.6738602221012115, Gattn=-0.01936919242143631, Dattn=0.04103522002696991, Aattn=-0.012718702666461468\n",
      "Epoch = 108, ErrG = 0.6998740434646606, ErrTri = 2.078207492828369, ErrA = 0.6680553934226433, ErrD = 0.668057918548584, Gattn=-0.019492391496896744, Dattn=0.04126676544547081, Aattn=-0.013423332944512367\n",
      "Epoch = 110, ErrG = 0.48456962903340656, ErrTri = 1.4697178602218628, ErrA = 0.6689770724624395, ErrD = 0.6688177461425463, Gattn=-0.019568458199501038, Dattn=0.04144137352705002, Aattn=-0.014018789865076542\n",
      "Epoch = 112, ErrG = 0.4775697588920593, ErrTri = 1.4195032119750977, ErrA = 0.6682685265938441, ErrD = 0.6691489002356926, Gattn=-0.0196224357932806, Dattn=0.04161588475108147, Aattn=-0.015127611346542835\n",
      "Epoch = 114, ErrG = 0.2913772463798523, ErrTri = 0.9576073288917542, ErrA = 0.6621732711791992, ErrD = 0.6672721256812414, Gattn=-0.019778292626142502, Dattn=0.041786231100559235, Aattn=-0.015909884124994278\n",
      "Epoch = 116, ErrG = 0.47966180245081586, ErrTri = 1.4671251773834229, ErrA = 0.6680757962167263, ErrD = 0.6681126430630684, Gattn=-0.019816726446151733, Dattn=0.0419461652636528, Aattn=-0.01677435263991356\n",
      "Epoch = 118, ErrG = 0.4915836453437805, ErrTri = 1.441292405128479, ErrA = 0.671459366256992, ErrD = 0.6674807202070951, Gattn=-0.019993094727396965, Dattn=0.04211507365107536, Aattn=-0.01759858801960945\n",
      "Epoch = 120, ErrG = 0.5468358993530273, ErrTri = 1.6267327070236206, ErrA = 0.675721729795138, ErrD = 0.6668574350575606, Gattn=-0.01988942176103592, Dattn=0.04226453974843025, Aattn=-0.017944572493433952\n",
      "Epoch = 122, ErrG = 0.36617588996887207, ErrTri = 1.2537598609924316, ErrA = 0.6755373477935791, ErrD = 0.6687595049540201, Gattn=-0.01998356357216835, Dattn=0.042415399104356766, Aattn=-0.01898892968893051\n",
      "Epoch = 124, ErrG = 0.5357921123504639, ErrTri = 1.6027065515518188, ErrA = 0.6660729901244243, ErrD = 0.6677476558834314, Gattn=-0.02015487290918827, Dattn=0.042570650577545166, Aattn=-0.020177429541945457\n",
      "Epoch = 126, ErrG = 0.3920946915944417, ErrTri = 1.2495709657669067, ErrA = 0.6611802869786819, ErrD = 0.6672113059709469, Gattn=-0.020241420716047287, Dattn=0.0427115336060524, Aattn=-0.021653752774000168\n",
      "Epoch = 128, ErrG = 0.2916581630706787, ErrTri = 0.9053910970687866, ErrA = 0.6683123527715603, ErrD = 0.6694749848296245, Gattn=-0.020285503938794136, Dattn=0.04285603016614914, Aattn=-0.021944545209407806\n",
      "Epoch = 130, ErrG = 0.32581700881322223, ErrTri = 0.9765344858169556, ErrA = 0.6673877419282993, ErrD = 0.6695226828257242, Gattn=-0.020284799858927727, Dattn=0.04299919679760933, Aattn=-0.021962927654385567\n",
      "Epoch = 132, ErrG = 0.39043378829956055, ErrTri = 1.1768412590026855, ErrA = 0.6709759632746378, ErrD = 0.6677966912587484, Gattn=-0.02026853710412979, Dattn=0.04314000532031059, Aattn=-0.02203710563480854\n",
      "Epoch = 134, ErrG = 0.419508953889211, ErrTri = 1.3561478853225708, ErrA = 0.6687702729056278, ErrD = 0.6686731968075037, Gattn=-0.020274359732866287, Dattn=0.04326499626040459, Aattn=-0.02214382216334343\n",
      "Epoch = 136, ErrG = 0.46674489974975586, ErrTri = 1.4335217475891113, ErrA = 0.6798769210775694, ErrD = 0.6696499188741049, Gattn=-0.02030571736395359, Dattn=0.0434114970266819, Aattn=-0.02246645838022232\n",
      "Epoch = 138, ErrG = 0.5627157688140869, ErrTri = 1.636657476425171, ErrA = 0.6678413810829321, ErrD = 0.6671182047575712, Gattn=-0.02029932104051113, Dattn=0.04354273900389671, Aattn=-0.022846557199954987\n",
      "Epoch = 140, ErrG = 0.28510258595148724, ErrTri = 0.8977883458137512, ErrA = 0.6697547826915979, ErrD = 0.6684525807698568, Gattn=-0.02028898522257805, Dattn=0.04366767406463623, Aattn=-0.023371238261461258\n",
      "Epoch = 142, ErrG = 0.3343923091888428, ErrTri = 1.0178279876708984, ErrA = 0.6675548925995827, ErrD = 0.6687630750238895, Gattn=-0.020349957048892975, Dattn=0.04380575940012932, Aattn=-0.0236392542719841\n",
      "Epoch = 144, ErrG = 0.42092446486155194, ErrTri = 1.272562861442566, ErrA = 0.6689754041532675, ErrD = 0.6702130635579427, Gattn=-0.02035713568329811, Dattn=0.043920453637838364, Aattn=-0.023886986076831818\n",
      "Epoch = 146, ErrG = 0.25998520851135254, ErrTri = 0.8650025129318237, ErrA = 0.6687675851086775, ErrD = 0.6665218857427438, Gattn=-0.02031266689300537, Dattn=0.04404696449637413, Aattn=-0.024079149588942528\n",
      "Epoch = 148, ErrG = 0.4599473476409912, ErrTri = 1.3543503284454346, ErrA = 0.667548630386591, ErrD = 0.66916808920602, Gattn=-0.02031928487122059, Dattn=0.04414985328912735, Aattn=-0.024225030094385147\n",
      "Epoch = 150, ErrG = 0.476387898127238, ErrTri = 1.533178687095642, ErrA = 0.6731838037570318, ErrD = 0.6681033801287413, Gattn=-0.020366543903946877, Dattn=0.044265128672122955, Aattn=-0.024324214085936546\n",
      "Epoch = 152, ErrG = 0.3167215983072917, ErrTri = 0.9702095985412598, ErrA = 0.6676839906722307, ErrD = 0.6667737755924463, Gattn=-0.02039797231554985, Dattn=0.0443694107234478, Aattn=-0.024624623358249664\n",
      "Epoch = 154, ErrG = 0.2166098952293396, ErrTri = 0.7562128305435181, ErrA = 0.6558080756415924, ErrD = 0.6673423449198405, Gattn=-0.020409466698765755, Dattn=0.04447507858276367, Aattn=-0.024871734902262688\n",
      "Epoch = 156, ErrG = 0.46653153498967487, ErrTri = 1.4275832176208496, ErrA = 0.6727000375588735, ErrD = 0.6695947647094727, Gattn=-0.020450105890631676, Dattn=0.044575102627277374, Aattn=-0.0252523235976696\n",
      "Epoch = 158, ErrG = 0.4497832457224528, ErrTri = 1.3406944274902344, ErrA = 0.6695239680508772, ErrD = 0.6690306775271893, Gattn=-0.020422104746103287, Dattn=0.04468541592359543, Aattn=-0.025571951642632484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 160, ErrG = 0.26708030700683594, ErrTri = 0.8404383659362793, ErrA = 0.6729234041025242, ErrD = 0.6662080648044745, Gattn=-0.02051149122416973, Dattn=0.04478449001908302, Aattn=-0.025810878723859787\n",
      "Epoch = 162, ErrG = 0.2933942874272664, ErrTri = 0.8757205009460449, ErrA = 0.6733941199878851, ErrD = 0.6670015857865413, Gattn=-0.020526675507426262, Dattn=0.04490313678979874, Aattn=-0.026120126247406006\n",
      "Epoch = 164, ErrG = 0.5324180126190186, ErrTri = 1.6377794742584229, ErrA = 0.6684541472544273, ErrD = 0.6698337029665709, Gattn=-0.020552387461066246, Dattn=0.04499809816479683, Aattn=-0.026392705738544464\n",
      "Epoch = 166, ErrG = 0.3370840549468994, ErrTri = 1.0034589767456055, ErrA = 0.6620852078000704, ErrD = 0.6629095959166685, Gattn=-0.020608749240636826, Dattn=0.04509630799293518, Aattn=-0.026749679818749428\n",
      "Epoch = 168, ErrG = 0.3410554528236389, ErrTri = 1.0329116582870483, ErrA = 0.6664159862945477, ErrD = 0.6682561058551073, Gattn=-0.020655827596783638, Dattn=0.04517382010817528, Aattn=-0.027035370469093323\n",
      "Epoch = 170, ErrG = 0.3701831102371216, ErrTri = 1.1617627143859863, ErrA = 0.6658036733667055, ErrD = 0.6691230448583761, Gattn=-0.02077045664191246, Dattn=0.04529968276619911, Aattn=-0.02724197506904602\n",
      "Epoch = 172, ErrG = 0.34992776314417523, ErrTri = 1.0172947645187378, ErrA = 0.6662284812579552, ErrD = 0.6668398467202982, Gattn=-0.020869499072432518, Dattn=0.04538001865148544, Aattn=-0.027491094544529915\n",
      "Epoch = 174, ErrG = 0.4633506139119466, ErrTri = 1.4036624431610107, ErrA = 0.6680228890230259, ErrD = 0.6642859807858864, Gattn=-0.020883066579699516, Dattn=0.04545820131897926, Aattn=-0.027800537645816803\n",
      "Epoch = 176, ErrG = 0.24030246337254843, ErrTri = 0.7756334543228149, ErrA = 0.6694248430430889, ErrD = 0.6679840199649334, Gattn=-0.020915990695357323, Dattn=0.0455537848174572, Aattn=-0.028103632852435112\n",
      "Epoch = 178, ErrG = 0.24571535984675089, ErrTri = 0.7210649847984314, ErrA = 0.6741202392925819, ErrD = 0.6653369354705015, Gattn=-0.02092585898935795, Dattn=0.045665863901376724, Aattn=-0.028431713581085205\n",
      "Epoch = 180, ErrG = 0.24558667341868082, ErrTri = 0.6883207559585571, ErrA = 0.6707453150302172, ErrD = 0.6654260214418173, Gattn=-0.02100244350731373, Dattn=0.04578222334384918, Aattn=-0.02889813669025898\n",
      "Epoch = 182, ErrG = 0.3447893460591634, ErrTri = 0.9816832542419434, ErrA = 0.6602364704012871, ErrD = 0.6642603998382887, Gattn=-0.02105901762843132, Dattn=0.045873917639255524, Aattn=-0.029175350442528725\n",
      "Epoch = 184, ErrG = 0.36613668998082477, ErrTri = 1.066213607788086, ErrA = 0.666500256707271, ErrD = 0.6692148844401041, Gattn=-0.021099310368299484, Dattn=0.046008553355932236, Aattn=-0.02946729026734829\n",
      "Epoch = 186, ErrG = 0.31648627916971844, ErrTri = 0.9755494594573975, ErrA = 0.667992498104771, ErrD = 0.6713309288024902, Gattn=-0.02118845470249653, Dattn=0.046150993555784225, Aattn=-0.02977648936212063\n",
      "Epoch = 188, ErrG = 0.14458628495534262, ErrTri = 0.5059398412704468, ErrA = 0.6743098714699348, ErrD = 0.6693157963454723, Gattn=-0.021235140040516853, Dattn=0.046356312930583954, Aattn=-0.03012201376259327\n",
      "Epoch = 190, ErrG = 0.25133609771728516, ErrTri = 0.7528387904167175, ErrA = 0.6661985628306866, ErrD = 0.670547383526961, Gattn=-0.02131810039281845, Dattn=0.046508144587278366, Aattn=-0.03062528744339943\n",
      "Epoch = 192, ErrG = 0.21584310134251913, ErrTri = 0.7947688102722168, ErrA = 0.6679538109650215, ErrD = 0.6655320624510447, Gattn=-0.021357759833335876, Dattn=0.04671598970890045, Aattn=-0.030969059094786644\n",
      "Epoch = 194, ErrG = 0.38469745715459186, ErrTri = 1.1925325393676758, ErrA = 0.6521416697651148, ErrD = 0.6652871059874693, Gattn=-0.02147522196173668, Dattn=0.046895187348127365, Aattn=-0.031470656394958496\n",
      "Epoch = 196, ErrG = 0.28111133972803753, ErrTri = 0.8085454106330872, ErrA = 0.6661121733486652, ErrD = 0.6666797418147326, Gattn=-0.021555738523602486, Dattn=0.0471133328974247, Aattn=-0.031991858035326004\n",
      "Epoch = 198, ErrG = 0.2389256159464518, ErrTri = 0.7571188807487488, ErrA = 0.6701272086550792, ErrD = 0.669927871475617, Gattn=-0.021544618532061577, Dattn=0.04735531657934189, Aattn=-0.032606665045022964\n",
      "Epoch = 200, ErrG = 0.2862580418586731, ErrTri = 0.8885956406593323, ErrA = 0.6666532208522161, ErrD = 0.6710459205011526, Gattn=-0.02160363644361496, Dattn=0.04770510271191597, Aattn=-0.033028777688741684\n",
      "Epoch = 202, ErrG = 0.25727442900339764, ErrTri = 0.7660829424858093, ErrA = 0.6528938723107179, ErrD = 0.6637502647936344, Gattn=-0.021675264462828636, Dattn=0.04803767800331116, Aattn=-0.03355878219008446\n",
      "Epoch = 204, ErrG = 0.27759937445322674, ErrTri = 0.8385896682739258, ErrA = 0.66713164995114, ErrD = 0.6664069847514232, Gattn=-0.021588949486613274, Dattn=0.0486452579498291, Aattn=-0.03407696262001991\n",
      "Epoch = 206, ErrG = 0.14358429114023843, ErrTri = 0.4832265377044678, ErrA = 0.6703575402498245, ErrD = 0.6676110159605742, Gattn=-0.02167282998561859, Dattn=0.04914803057909012, Aattn=-0.03472389653325081\n",
      "Epoch = 208, ErrG = 0.29456984996795654, ErrTri = 0.8781675100326538, ErrA = 0.6667840400089821, ErrD = 0.6577482695380846, Gattn=-0.021732069551944733, Dattn=0.04971855506300926, Aattn=-0.03527091071009636\n",
      "Epoch = 210, ErrG = 0.21783639987309775, ErrTri = 0.6409735679626465, ErrA = 0.6488551758229733, ErrD = 0.6686178122957548, Gattn=-0.021645519882440567, Dattn=0.05025916174054146, Aattn=-0.035535745322704315\n",
      "Epoch = 212, ErrG = 0.27738223473231, ErrTri = 0.8920358419418335, ErrA = 0.667042151093483, ErrD = 0.6672964549312989, Gattn=-0.02180580422282219, Dattn=0.050547003746032715, Aattn=-0.035883836448192596\n",
      "Epoch = 214, ErrG = 0.16732142368952432, ErrTri = 0.5005686283111572, ErrA = 0.6668483130633831, ErrD = 0.668831596771876, Gattn=-0.021871406584978104, Dattn=0.05093371868133545, Aattn=-0.036335840821266174\n",
      "Epoch = 216, ErrG = 0.17159096399943033, ErrTri = 0.5484535694122314, ErrA = 0.6555872485041618, ErrD = 0.6498408491412798, Gattn=-0.021887708455324173, Dattn=0.05094292014837265, Aattn=-0.037207651883363724\n",
      "Epoch = 218, ErrG = 0.18499356508255005, ErrTri = 0.587992787361145, ErrA = 0.6648466742287079, ErrD = 0.6677470803260803, Gattn=-0.02196916751563549, Dattn=0.051284562796354294, Aattn=-0.0382913313806057\n",
      "Epoch = 220, ErrG = 0.17938150962193808, ErrTri = 0.54985511302948, ErrA = 0.6464623274902502, ErrD = 0.6622951291501522, Gattn=-0.021883288398385048, Dattn=0.05135989189147949, Aattn=-0.03907417878508568\n",
      "Epoch = 222, ErrG = 0.37335360050201416, ErrTri = 1.0786879062652588, ErrA = 0.6650012681881586, ErrD = 0.6661918958028158, Gattn=-0.021833986043930054, Dattn=0.05141708254814148, Aattn=-0.040543921291828156\n",
      "Epoch = 224, ErrG = 0.11851423978805542, ErrTri = 0.33474165201187134, ErrA = 0.6714980223526558, ErrD = 0.6638776063919067, Gattn=-0.021855851635336876, Dattn=0.05142104625701904, Aattn=-0.0418524444103241\n",
      "Epoch = 226, ErrG = 0.17515379190444946, ErrTri = 0.5482765436172485, ErrA = 0.6643807794898748, ErrD = 0.664076084891955, Gattn=-0.021941067650914192, Dattn=0.05164828523993492, Aattn=-0.04213590919971466\n",
      "Epoch = 228, ErrG = 0.26212940613428753, ErrTri = 0.8592718839645386, ErrA = 0.66686050593853, ErrD = 0.6673115510493517, Gattn=-0.021900339052081108, Dattn=0.05171103775501251, Aattn=-0.04334140568971634\n",
      "Epoch = 230, ErrG = 0.22482446829477945, ErrTri = 0.734471321105957, ErrA = 0.6578102180113395, ErrD = 0.6550129167735577, Gattn=-0.021966520696878433, Dattn=0.05181083455681801, Aattn=-0.043312445282936096\n",
      "Epoch = 232, ErrG = 0.1784204045931498, ErrTri = 0.5121927857398987, ErrA = 0.666459201524655, ErrD = 0.6622417283554872, Gattn=-0.02216353639960289, Dattn=0.05192740261554718, Aattn=-0.04510319605469704\n",
      "Epoch = 234, ErrG = 0.22738826274871826, ErrTri = 0.700581431388855, ErrA = 0.6682165308545033, ErrD = 0.662683847049872, Gattn=-0.022197077050805092, Dattn=0.05190637707710266, Aattn=-0.0454847477376461\n",
      "Epoch = 236, ErrG = 0.22972116867701212, ErrTri = 0.7113823294639587, ErrA = 0.6662365036706129, ErrD = 0.6734479193886121, Gattn=-0.022269560024142265, Dattn=0.05210777372121811, Aattn=-0.0466565378010273\n",
      "Epoch = 238, ErrG = 0.213372011979421, ErrTri = 0.6462136507034302, ErrA = 0.6654344331473112, ErrD = 0.6642171293497086, Gattn=-0.022280724719166756, Dattn=0.052213992923498154, Aattn=-0.04687362164258957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 240, ErrG = 0.21528776486714682, ErrTri = 0.6162649393081665, ErrA = 0.6447196900844574, ErrD = 0.6581355830033621, Gattn=-0.02223062328994274, Dattn=0.0522821806371212, Aattn=-0.048486292362213135\n",
      "Epoch = 242, ErrG = 0.20778397719065347, ErrTri = 0.5268774628639221, ErrA = 0.6685782615095377, ErrD = 0.6646854567031065, Gattn=-0.022338805720210075, Dattn=0.05235536769032478, Aattn=-0.04984793812036514\n",
      "Epoch = 244, ErrG = 0.22306394577026367, ErrTri = 0.60271817445755, ErrA = 0.6618240413566431, ErrD = 0.6601707606265942, Gattn=-0.022450676187872887, Dattn=0.052425190806388855, Aattn=-0.04975678026676178\n",
      "Epoch = 246, ErrG = 0.23902557293574014, ErrTri = 0.6476641297340393, ErrA = 0.6654705386608839, ErrD = 0.6563515824576219, Gattn=-0.022485367953777313, Dattn=0.0525280199944973, Aattn=-0.05056845396757126\n",
      "Epoch = 248, ErrG = 0.1009166141351064, ErrTri = 0.2766213119029999, ErrA = 0.6410699114203453, ErrD = 0.6393701086441675, Gattn=-0.022413745522499084, Dattn=0.05264514312148094, Aattn=-0.05069830268621445\n",
      "Epoch = 250, ErrG = 0.08035804828008015, ErrTri = 0.21931475400924683, ErrA = 0.6402352824807167, ErrD = 0.6471030612786611, Gattn=-0.022511761635541916, Dattn=0.052788205444812775, Aattn=-0.052520107477903366\n",
      "Epoch = 252, ErrG = 0.2879257798194885, ErrTri = 0.8198960423469543, ErrA = 0.6475218410293261, ErrD = 0.6504925979922215, Gattn=-0.022505324333906174, Dattn=0.05281045660376549, Aattn=-0.052812833338975906\n",
      "Epoch = 254, ErrG = 0.09162694215774536, ErrTri = 0.29991722106933594, ErrA = 0.6684517705192169, ErrD = 0.6546892896294594, Gattn=-0.022520001977682114, Dattn=0.05289755389094353, Aattn=-0.05332820490002632\n",
      "Epoch = 256, ErrG = 0.2160541613896688, ErrTri = 0.5681678056716919, ErrA = 0.6750619262456894, ErrD = 0.6648096771289905, Gattn=-0.022543203085660934, Dattn=0.05286804586648941, Aattn=-0.05307793244719505\n",
      "Epoch = 258, ErrG = 0.1463411053021749, ErrTri = 0.4727252721786499, ErrA = 0.6609634986768166, ErrD = 0.6549543173362812, Gattn=-0.022582141682505608, Dattn=0.05279236286878586, Aattn=-0.054713450372219086\n",
      "Epoch = 260, ErrG = 0.20663891235987344, ErrTri = 0.6908658742904663, ErrA = 0.6582583039999008, ErrD = 0.6589019844929377, Gattn=-0.022650117054581642, Dattn=0.052870508283376694, Aattn=-0.055357012897729874\n",
      "Epoch = 262, ErrG = 0.17339354753494263, ErrTri = 0.5546793937683105, ErrA = 0.6708975496391455, ErrD = 0.6574694837133089, Gattn=-0.022719237953424454, Dattn=0.0528004989027977, Aattn=-0.05533864349126816\n",
      "Epoch = 264, ErrG = 0.16537290811538696, ErrTri = 0.4499938488006592, ErrA = 0.6615790768216053, ErrD = 0.6608450238903364, Gattn=-0.02271627075970173, Dattn=0.05279766023159027, Aattn=-0.056094735860824585\n",
      "Epoch = 266, ErrG = 0.2400389313697815, ErrTri = 0.6367161870002747, ErrA = 0.6631927868972222, ErrD = 0.6518890876322985, Gattn=-0.022862331941723824, Dattn=0.05282821133732796, Aattn=-0.05751227214932442\n",
      "Epoch = 268, ErrG = 0.1704418659210205, ErrTri = 0.5679638385772705, ErrA = 0.6442849611242613, ErrD = 0.6602868760625521, Gattn=-0.022714441642165184, Dattn=0.052752505987882614, Aattn=-0.058317795395851135\n",
      "Epoch = 270, ErrG = 0.17214022080103555, ErrTri = 0.627875804901123, ErrA = 0.6634017322212458, ErrD = 0.6617775907119116, Gattn=-0.022808747366070747, Dattn=0.052601296454668045, Aattn=-0.0590217262506485\n",
      "Epoch = 272, ErrG = 0.17632339398066202, ErrTri = 0.3987463116645813, ErrA = 0.6433094895134369, ErrD = 0.6407994814217091, Gattn=-0.022835079580545425, Dattn=0.05237744376063347, Aattn=-0.05988550931215286\n",
      "Epoch = 274, ErrG = 0.24950602650642395, ErrTri = 0.45766934752464294, ErrA = 0.6584786487122377, ErrD = 0.6463163973142704, Gattn=-0.02285471372306347, Dattn=0.05207041651010513, Aattn=-0.060309864580631256\n",
      "Epoch = 276, ErrG = 0.29531705379486084, ErrTri = 0.7449362874031067, ErrA = 0.6547382355978092, ErrD = 0.6700082365423441, Gattn=-0.0230066180229187, Dattn=0.05166485905647278, Aattn=-0.060960426926612854\n",
      "Epoch = 278, ErrG = 0.19459225734074911, ErrTri = 0.5097682476043701, ErrA = 0.6512298285961151, ErrD = 0.6579438149929047, Gattn=-0.023108674213290215, Dattn=0.050964437425136566, Aattn=-0.061851661652326584\n",
      "Epoch = 280, ErrG = 0.13116208712259927, ErrTri = 0.36224365234375, ErrA = 0.6486750543117523, ErrD = 0.6071600491801897, Gattn=-0.02314550057053566, Dattn=0.05004417523741722, Aattn=-0.06254592537879944\n",
      "Epoch = 282, ErrG = 0.2746986548105876, ErrTri = 0.4454912543296814, ErrA = 0.6553712400297323, ErrD = 0.6161176587144533, Gattn=-0.02302531711757183, Dattn=0.048757635056972504, Aattn=-0.06343293935060501\n",
      "Epoch = 284, ErrG = 0.15983086824417114, ErrTri = 0.3771202564239502, ErrA = 0.6293568760156631, ErrD = 0.6449487370749315, Gattn=-0.023051531985402107, Dattn=0.047636255621910095, Aattn=-0.06425808370113373\n",
      "Epoch = 286, ErrG = 0.2172806759675344, ErrTri = 0.43653544783592224, ErrA = 0.6435874936481317, ErrD = 0.6250460346539816, Gattn=-0.023128250613808632, Dattn=0.04619348421692848, Aattn=-0.06546714901924133\n",
      "Epoch = 288, ErrG = 0.23288341363271078, ErrTri = 0.3831198215484619, ErrA = 0.6535180093099674, ErrD = 0.6188096385449171, Gattn=-0.02323729172348976, Dattn=0.04537852481007576, Aattn=-0.06604554504156113\n",
      "Epoch = 290, ErrG = 0.015601575374603271, ErrTri = 0.19075322151184082, ErrA = 0.6614993363618851, ErrD = 0.6714021066824595, Gattn=-0.023185595870018005, Dattn=0.04499102383852005, Aattn=-0.06682420521974564\n",
      "Epoch = 292, ErrG = 0.30274369319279987, ErrTri = 0.3453209102153778, ErrA = 0.7132762422164282, ErrD = 0.5623412579298019, Gattn=-0.023241877555847168, Dattn=0.04487309232354164, Aattn=-0.06747036427259445\n",
      "Epoch = 294, ErrG = 0.18936235706011453, ErrTri = 0.4649113416671753, ErrA = 0.6619484101732572, ErrD = 0.6680389232933521, Gattn=-0.023321736603975296, Dattn=0.04472891986370087, Aattn=-0.0678815096616745\n",
      "Epoch = 296, ErrG = 0.2566734155019124, ErrTri = 0.6089975833892822, ErrA = 0.6091938788692156, ErrD = 0.4774918307860692, Gattn=-0.02338257059454918, Dattn=0.044598259031772614, Aattn=-0.06811878085136414\n",
      "Epoch = 298, ErrG = 0.5803204377492269, ErrTri = 0.2870769500732422, ErrA = 0.6120992228388786, ErrD = 0.6022522201140722, Gattn=-0.02338593266904354, Dattn=0.04463515803217888, Aattn=-0.0686255693435669\n",
      "Epoch = 300, ErrG = 0.5589967295527458, ErrTri = 0.6573936343193054, ErrA = 0.6565959608803192, ErrD = 0.6199544866879781, Gattn=-0.023398641496896744, Dattn=0.04468104988336563, Aattn=-0.0688309371471405\n",
      "Epoch = 302, ErrG = 0.5941088795661926, ErrTri = 0.4545696973800659, ErrA = 0.5544256567955017, ErrD = 0.45621630549430847, Gattn=-0.023543179035186768, Dattn=0.04477394372224808, Aattn=-0.06907588243484497\n",
      "Epoch = 304, ErrG = 0.8110891679922739, ErrTri = 0.30014100670814514, ErrA = 0.7939057846864065, ErrD = 0.5085519446680943, Gattn=-0.023550506681203842, Dattn=0.044871728867292404, Aattn=-0.06949371844530106\n",
      "Epoch = 306, ErrG = 0.7328657309214274, ErrTri = 0.7638945579528809, ErrA = 0.6490524324278036, ErrD = 0.5811545997858047, Gattn=-0.02360663376748562, Dattn=0.044917989522218704, Aattn=-0.06942801177501678\n",
      "Epoch = 308, ErrG = 0.16888393958409628, ErrTri = 0.4294416308403015, ErrA = 0.6520229360709587, ErrD = 0.516231894493103, Gattn=-0.023655619472265244, Dattn=0.04494277387857437, Aattn=-0.06986095756292343\n",
      "Epoch = 310, ErrG = 0.45813828706741333, ErrTri = 0.3664838671684265, ErrA = 0.6582102278868357, ErrD = 0.592657725016276, Gattn=-0.02362881228327751, Dattn=0.04497400298714638, Aattn=-0.07028289139270782\n",
      "Epoch = 312, ErrG = 0.2813478509585063, ErrTri = 0.41075485944747925, ErrA = 0.6102009216944376, ErrD = 0.5374424854914347, Gattn=-0.023675205186009407, Dattn=0.045098770409822464, Aattn=-0.07065019011497498\n",
      "Epoch = 314, ErrG = 0.437720646460851, ErrTri = 0.25947728753089905, ErrA = 0.5950233352681001, ErrD = 0.5087131361166636, Gattn=-0.02385552227497101, Dattn=0.045153357088565826, Aattn=-0.071126788854599\n",
      "Epoch = 316, ErrG = 0.034900655349095665, ErrTri = 0.3988710343837738, ErrA = 0.6020141659925381, ErrD = 0.7136892477671305, Gattn=-0.023873943835496902, Dattn=0.045218344777822495, Aattn=-0.07092025130987167\n",
      "Epoch = 318, ErrG = 0.4497073292732239, ErrTri = 0.6982197761535645, ErrA = 0.6513045063863198, ErrD = 0.6280244588851929, Gattn=-0.02393624186515808, Dattn=0.0452294796705246, Aattn=-0.07117779552936554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 320, ErrG = 0.3705063462257385, ErrTri = 0.6936146020889282, ErrA = 0.592785914738973, ErrD = 0.7291649350275596, Gattn=-0.02384408749639988, Dattn=0.04530612751841545, Aattn=-0.07142718881368637\n",
      "Epoch = 322, ErrG = 0.36221540967623395, ErrTri = 0.41553181409835815, ErrA = 0.6385101415216923, ErrD = 0.6386140187581381, Gattn=-0.023841699585318565, Dattn=0.04530642554163933, Aattn=-0.07174340635538101\n",
      "Epoch = 324, ErrG = 0.4301662743091583, ErrTri = 0.5181174874305725, ErrA = 0.5364030400911967, ErrD = 0.6731035814930996, Gattn=-0.023899540305137634, Dattn=0.04536827281117439, Aattn=-0.07195452600717545\n",
      "Epoch = 326, ErrG = 0.7021071414152781, ErrTri = 0.4537392556667328, ErrA = 0.5342137515544891, ErrD = 0.4386960168679555, Gattn=-0.023977473378181458, Dattn=0.04535771906375885, Aattn=-0.07231582701206207\n",
      "Epoch = 328, ErrG = 0.14137120048205057, ErrTri = 0.3223157823085785, ErrA = 0.6430610101670027, ErrD = 0.5159811973571777, Gattn=-0.02394130639731884, Dattn=0.045378174632787704, Aattn=-0.07243303954601288\n",
      "Epoch = 330, ErrG = 0.4166601151227951, ErrTri = 0.3697730600833893, ErrA = 0.7010432779788971, ErrD = 0.5726688330372175, Gattn=-0.023972095921635628, Dattn=0.0453902967274189, Aattn=-0.07258931547403336\n",
      "Epoch = 332, ErrG = 0.671213964621226, ErrTri = 0.45468997955322266, ErrA = 0.5595200185974439, ErrD = 0.5362655992309252, Gattn=-0.024032991379499435, Dattn=0.04544419050216675, Aattn=-0.07291365414857864\n",
      "Epoch = 334, ErrG = 0.20117314656575522, ErrTri = 0.28896403312683105, ErrA = 0.6325369303425153, ErrD = 0.589442789554596, Gattn=-0.024147609248757362, Dattn=0.045510243624448776, Aattn=-0.07276872545480728\n",
      "Epoch = 336, ErrG = 0.31891189018885296, ErrTri = 0.7173669338226318, ErrA = 0.6417554020881653, ErrD = 0.5296538273493449, Gattn=-0.024460013955831528, Dattn=0.045577630400657654, Aattn=-0.07290027290582657\n",
      "Epoch = 338, ErrG = 0.524650459488233, ErrTri = 0.6370041370391846, ErrA = 0.62437987079223, ErrD = 0.6390020549297333, Gattn=-0.024474726989865303, Dattn=0.045608989894390106, Aattn=-0.07319927215576172\n",
      "Epoch = 340, ErrG = 0.647453765074412, ErrTri = 0.8064984083175659, ErrA = 0.5530299233893553, ErrD = 0.46579967935880023, Gattn=-0.024604786187410355, Dattn=0.045512448996305466, Aattn=-0.07357139140367508\n",
      "Epoch = 342, ErrG = 0.7370316982269287, ErrTri = 0.5510377883911133, ErrA = 0.6150117218494415, ErrD = 0.6689584931979576, Gattn=-0.024557534605264664, Dattn=0.04554235562682152, Aattn=-0.07362159341573715\n",
      "Epoch = 344, ErrG = 0.5621889034907023, ErrTri = 0.415316641330719, ErrA = 0.6559123943249384, ErrD = 0.6008013567576805, Gattn=-0.024654731154441833, Dattn=0.04550357535481453, Aattn=-0.07373973727226257\n",
      "Epoch = 346, ErrG = 0.2878704021374385, ErrTri = 0.2891455888748169, ErrA = 0.5333884209394455, ErrD = 0.6513617038726807, Gattn=-0.02475164271891117, Dattn=0.04548979550600052, Aattn=-0.07376155257225037\n",
      "Epoch = 348, ErrG = 0.32523538668950397, ErrTri = 0.44290784001350403, ErrA = 0.4909774779031674, ErrD = 0.6457768380641937, Gattn=-0.024870876222848892, Dattn=0.045515671372413635, Aattn=-0.07404205203056335\n",
      "Epoch = 350, ErrG = 0.1948396364847819, ErrTri = 0.2933189868927002, ErrA = 0.5590201454857985, ErrD = 0.6525416374206543, Gattn=-0.024839112535119057, Dattn=0.04552342742681503, Aattn=-0.07408712804317474\n",
      "Epoch = 352, ErrG = 0.4685571293036143, ErrTri = 0.7143495082855225, ErrA = 0.5365548531214396, ErrD = 0.8040909767150879, Gattn=-0.024823978543281555, Dattn=0.045576732605695724, Aattn=-0.07436959445476532\n",
      "Epoch = 354, ErrG = 0.21451792617638907, ErrTri = 0.41950249671936035, ErrA = 0.46023196913301945, ErrD = 0.42945589621861774, Gattn=-0.024986108765006065, Dattn=0.04554733261466026, Aattn=-0.07440653443336487\n",
      "Epoch = 356, ErrG = 0.05229006210962931, ErrTri = 0.4923366904258728, ErrA = 0.48822663972775143, ErrD = 0.3875209589799245, Gattn=-0.025002799928188324, Dattn=0.045465510338544846, Aattn=-0.07472830265760422\n",
      "Epoch = 358, ErrG = 0.7937986453374227, ErrTri = 0.6457834243774414, ErrA = 0.5488867610692978, ErrD = 0.42542580763498944, Gattn=-0.024920491501688957, Dattn=0.045534782111644745, Aattn=-0.07503766566514969\n",
      "Epoch = 360, ErrG = 0.6820218165715536, ErrTri = 0.7413784265518188, ErrA = 0.5386720423897108, ErrD = 0.49760012825330097, Gattn=-0.02489371970295906, Dattn=0.04554923623800278, Aattn=-0.07533743232488632\n",
      "Epoch = 362, ErrG = 0.5914031068483988, ErrTri = 0.8157906532287598, ErrA = 0.43823245478173095, ErrD = 0.5637178706626097, Gattn=-0.025127314031124115, Dattn=0.04560871422290802, Aattn=-0.07573988288640976\n",
      "Epoch = 364, ErrG = 0.3753332297007243, ErrTri = 0.6516733169555664, ErrA = 0.5167537008722624, ErrD = 0.36607474088668823, Gattn=-0.025224100798368454, Dattn=0.04556687921285629, Aattn=-0.07619171589612961\n",
      "Epoch = 366, ErrG = 0.7639023462931315, ErrTri = 0.7337325811386108, ErrA = 0.5638713190952936, ErrD = 0.6202225337425867, Gattn=-0.02533472515642643, Dattn=0.04551061987876892, Aattn=-0.07658086717128754\n",
      "Epoch = 368, ErrG = 0.45410458246866864, ErrTri = 0.5311478972434998, ErrA = 0.47056028867761296, ErrD = 0.365834445382158, Gattn=-0.02534891478717327, Dattn=0.04553381726145744, Aattn=-0.07674308121204376\n",
      "Epoch = 370, ErrG = 0.724291721979777, ErrTri = 0.3696898818016052, ErrA = 0.5690020894010862, ErrD = 0.5937725367645422, Gattn=-0.025337835773825645, Dattn=0.04555424675345421, Aattn=-0.07704512774944305\n",
      "Epoch = 372, ErrG = 0.6626196404298147, ErrTri = 0.4735603630542755, ErrA = 0.6706255457053582, ErrD = 0.43736623724301654, Gattn=-0.02534816414117813, Dattn=0.04554241523146629, Aattn=-0.07728425413370132\n",
      "Epoch = 374, ErrG = 0.9027113715807596, ErrTri = 0.2825869917869568, ErrA = 0.46820402207473916, ErrD = 0.5198835786432028, Gattn=-0.02538936585187912, Dattn=0.04546224698424339, Aattn=-0.07773663103580475\n",
      "Epoch = 376, ErrG = 0.07276152571042378, ErrTri = 0.18961070477962494, ErrA = 0.4958684630692005, ErrD = 0.45718076825141907, Gattn=-0.025434380397200584, Dattn=0.045534897595644, Aattn=-0.07791084051132202\n",
      "Epoch = 378, ErrG = 0.10177439451217651, ErrTri = 0.3840617537498474, ErrA = 0.6079479766388735, ErrD = 0.4092242916425069, Gattn=-0.025424480438232422, Dattn=0.04548393189907074, Aattn=-0.07839327305555344\n",
      "Epoch = 380, ErrG = 0.4249109923839569, ErrTri = 0.26054397225379944, ErrA = 0.4864132155974706, ErrD = 0.38523035248120624, Gattn=-0.025288494303822517, Dattn=0.045403383672237396, Aattn=-0.07862967252731323\n",
      "Epoch = 382, ErrG = 0.6744974255561829, ErrTri = 0.16435295343399048, ErrA = 0.5067802220582962, ErrD = 0.42981133858362836, Gattn=-0.02539641037583351, Dattn=0.045414283871650696, Aattn=-0.07886441051959991\n",
      "Epoch = 384, ErrG = 0.6712081034978231, ErrTri = 0.40399080514907837, ErrA = 0.48097104641298455, ErrD = 0.553549995024999, Gattn=-0.02541082352399826, Dattn=0.04546505585312843, Aattn=-0.07912369817495346\n",
      "Epoch = 386, ErrG = 0.8654651393493017, ErrTri = 0.2098541110754013, ErrA = 0.4562009988973538, ErrD = 0.4813771452754736, Gattn=-0.02550533600151539, Dattn=0.04538901522755623, Aattn=-0.0793677419424057\n",
      "Epoch = 388, ErrG = 0.17416393756866455, ErrTri = 0.3605564832687378, ErrA = 0.4130112479130427, ErrD = 0.47448959946632385, Gattn=-0.025496670976281166, Dattn=0.04543895646929741, Aattn=-0.07969716191291809\n",
      "Epoch = 390, ErrG = 0.6651974519093832, ErrTri = 0.3902508616447449, ErrA = 0.45080270369847614, ErrD = 0.41579534610112506, Gattn=-0.025576753541827202, Dattn=0.04541212320327759, Aattn=-0.0797949880361557\n",
      "Epoch = 392, ErrG = 0.44365520278612774, ErrTri = 0.4144544005393982, ErrA = 0.48101270757615566, ErrD = 0.44433361291885376, Gattn=-0.02558840624988079, Dattn=0.04538525640964508, Aattn=-0.07986634224653244\n",
      "Epoch = 394, ErrG = 0.7819548646608988, ErrTri = 0.35179024934768677, ErrA = 0.4929825887084007, ErrD = 0.6391553152352571, Gattn=-0.025599004700779915, Dattn=0.04540746659040451, Aattn=-0.07999633252620697\n",
      "Epoch = 396, ErrG = 0.2752348482608795, ErrTri = 0.5145337581634521, ErrA = 0.45013655722141266, ErrD = 0.38344813386599225, Gattn=-0.02560163289308548, Dattn=0.04538894444704056, Aattn=-0.08021891862154007\n",
      "Epoch = 398, ErrG = 0.4064731262624264, ErrTri = 0.5587105751037598, ErrA = 0.5639735379566749, ErrD = 0.47455522418022156, Gattn=-0.025620218366384506, Dattn=0.045392461121082306, Aattn=-0.08034956455230713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 400, ErrG = 0.9914257526397705, ErrTri = 0.451373815536499, ErrA = 0.4774714633822441, ErrD = 0.5560151661435763, Gattn=-0.025720078498125076, Dattn=0.04532025381922722, Aattn=-0.08039143681526184\n",
      "Epoch = 402, ErrG = 0.9281780322392782, ErrTri = 0.49386441707611084, ErrA = 0.575357586145401, ErrD = 0.4404910746961832, Gattn=-0.025699876248836517, Dattn=0.04528258368372917, Aattn=-0.0808243378996849\n",
      "Epoch = 404, ErrG = 0.5898028910160065, ErrTri = 0.5013291239738464, ErrA = 0.5079388494292895, ErrD = 0.5758944184829792, Gattn=-0.0258130244910717, Dattn=0.04514315724372864, Aattn=-0.08118374645709991\n",
      "Epoch = 406, ErrG = 0.956541121006012, ErrTri = 0.28301918506622314, ErrA = 0.4219586451848348, ErrD = 0.4264504512151082, Gattn=-0.025800831615924835, Dattn=0.04506335034966469, Aattn=-0.08156149834394455\n",
      "Epoch = 408, ErrG = 0.5613180100917816, ErrTri = 0.3418649137020111, ErrA = 0.38512905811270076, ErrD = 0.5154022177060446, Gattn=-0.025920584797859192, Dattn=0.04513439163565636, Aattn=-0.08182615786790848\n",
      "Epoch = 410, ErrG = 0.36552401383717853, ErrTri = 0.42548373341560364, ErrA = 0.3184870562205712, ErrD = 0.33343955874443054, Gattn=-0.026042381301522255, Dattn=0.04508441314101219, Aattn=-0.08190463483333588\n",
      "Epoch = 412, ErrG = 0.6059087514877319, ErrTri = 0.3138663172721863, ErrA = 0.491189431399107, ErrD = 0.2852228581905365, Gattn=-0.02598543092608452, Dattn=0.04499721899628639, Aattn=-0.08202877640724182\n",
      "Epoch = 414, ErrG = 0.9901876846949259, ErrTri = 0.43744492530822754, ErrA = 0.4234513094027837, ErrD = 0.3764881876607736, Gattn=-0.026025308296084404, Dattn=0.04492747783660889, Aattn=-0.08233635127544403\n",
      "Epoch = 416, ErrG = 0.7844278514385223, ErrTri = 0.42915859818458557, ErrA = 0.4311855187018712, ErrD = 0.25990410645802814, Gattn=-0.026054024696350098, Dattn=0.04484894126653671, Aattn=-0.0826549381017685\n",
      "Epoch = 418, ErrG = 1.0769215822219849, ErrTri = 0.9786146879196167, ErrA = 0.31634783558547497, ErrD = 0.4187144773701827, Gattn=-0.026169830933213234, Dattn=0.044818151742219925, Aattn=-0.0831647738814354\n",
      "Epoch = 420, ErrG = 0.7809439698855082, ErrTri = 0.4370080828666687, ErrA = 0.4024997850259145, ErrD = 0.5844616486380497, Gattn=-0.026159167289733887, Dattn=0.0448339618742466, Aattn=-0.08335170149803162\n",
      "Epoch = 422, ErrG = 0.3186516761779785, ErrTri = 0.5470055341720581, ErrA = 0.3936064038425684, ErrD = 0.5288275380929311, Gattn=-0.026251409202814102, Dattn=0.044762082397937775, Aattn=-0.08362030982971191\n",
      "Epoch = 424, ErrG = 0.6457831660906473, ErrTri = 0.3226509690284729, ErrA = 0.4419690997650226, ErrD = 0.3539481945335865, Gattn=-0.026235245168209076, Dattn=0.044698137789964676, Aattn=-0.08377757668495178\n",
      "Epoch = 426, ErrG = 0.6675433814525604, ErrTri = 0.2665945589542389, ErrA = 0.4378273331870635, ErrD = 0.4667213646074136, Gattn=-0.026299288496375084, Dattn=0.04455197602510452, Aattn=-0.08395805954933167\n",
      "Epoch = 428, ErrG = 0.7625702917575836, ErrTri = 0.23630496859550476, ErrA = 0.4070917268594106, ErrD = 0.22939278682072958, Gattn=-0.02628195472061634, Dattn=0.0445394329726696, Aattn=-0.08414758741855621\n",
      "Epoch = 430, ErrG = 0.20720637838045755, ErrTri = 0.3043973743915558, ErrA = 0.37076628766953945, ErrD = 0.41148290534814197, Gattn=-0.02633589319884777, Dattn=0.0445077158510685, Aattn=-0.08418082445859909\n",
      "Epoch = 432, ErrG = 0.40845468640327454, ErrTri = 0.20794931054115295, ErrA = 0.35724733397364616, ErrD = 0.42295057078202564, Gattn=-0.026360614225268364, Dattn=0.04446198418736458, Aattn=-0.08455482125282288\n",
      "Epoch = 434, ErrG = 0.8043852845827738, ErrTri = 0.6172742247581482, ErrA = 0.3325617214043935, ErrD = 0.6365739504496256, Gattn=-0.0263340063393116, Dattn=0.044388893991708755, Aattn=-0.08484874665737152\n",
      "Epoch = 436, ErrG = 0.5376134216785431, ErrTri = 0.5349079370498657, ErrA = 0.3623515913883845, ErrD = 0.5313657323519388, Gattn=-0.026386268436908722, Dattn=0.044432274997234344, Aattn=-0.08503422886133194\n",
      "Epoch = 438, ErrG = 0.7401312788327535, ErrTri = 0.36398881673812866, ErrA = 0.5710951760411263, ErrD = 0.47204012672106427, Gattn=-0.02651272527873516, Dattn=0.044321294873952866, Aattn=-0.08540352433919907\n",
      "Epoch = 440, ErrG = 0.5772889455159506, ErrTri = 0.5385021567344666, ErrA = 0.2581694008161624, ErrD = 0.2361635367075602, Gattn=-0.02657822147011757, Dattn=0.044301845133304596, Aattn=-0.08555539697408676\n",
      "Epoch = 442, ErrG = 0.6477879186471304, ErrTri = 0.5803683996200562, ErrA = 0.38882650434970856, ErrD = 0.35232922931512195, Gattn=-0.02663181535899639, Dattn=0.04422338679432869, Aattn=-0.08573431521654129\n",
      "Epoch = 444, ErrG = 1.0528931319713593, ErrTri = 0.4699564278125763, ErrA = 0.43262667829791707, ErrD = 0.4125353489071131, Gattn=-0.02667962945997715, Dattn=0.044158484786748886, Aattn=-0.08572717756032944\n",
      "Epoch = 446, ErrG = 1.0286105573177338, ErrTri = 0.25114694237709045, ErrA = 0.4207657277584076, ErrD = 0.4247387231638034, Gattn=-0.026740089058876038, Dattn=0.044036075472831726, Aattn=-0.08603611588478088\n",
      "Epoch = 448, ErrG = 0.7491039435068766, ErrTri = 0.4034329056739807, ErrA = 0.4096578328559796, ErrD = 0.6846025933821996, Gattn=-0.026695603504776955, Dattn=0.044002871960401535, Aattn=-0.08626754581928253\n",
      "Epoch = 450, ErrG = 0.9158469637235006, ErrTri = 0.5654630661010742, ErrA = 0.17352372718354067, ErrD = 0.4465522840619087, Gattn=-0.02663818560540676, Dattn=0.043993715196847916, Aattn=-0.0863695740699768\n",
      "Epoch = 452, ErrG = 0.295638603468736, ErrTri = 0.215828537940979, ErrA = 0.3857690791289012, ErrD = 0.42841655015945435, Gattn=-0.02667825110256672, Dattn=0.04390821233391762, Aattn=-0.08673550933599472\n",
      "Epoch = 454, ErrG = 0.2950897812843323, ErrTri = 0.45230549573898315, ErrA = 0.4937048461288214, ErrD = 0.4754144052664439, Gattn=-0.0266555305570364, Dattn=0.04386426880955696, Aattn=-0.08693668991327286\n",
      "Epoch = 456, ErrG = 0.19695329666137695, ErrTri = 0.2794974446296692, ErrA = 0.4601813157399495, ErrD = 0.357669934630394, Gattn=-0.02675306238234043, Dattn=0.04387107864022255, Aattn=-0.0872838944196701\n",
      "Epoch = 458, ErrG = 0.7821020682652792, ErrTri = 0.3073219060897827, ErrA = 0.36401428282260895, ErrD = 0.4174711952606837, Gattn=-0.026812370866537094, Dattn=0.04383484274148941, Aattn=-0.08745720237493515\n",
      "Epoch = 460, ErrG = 1.0055708090464275, ErrTri = 0.3095434904098511, ErrA = 0.4292696565389633, ErrD = 0.36209107500811416, Gattn=-0.02684512920677662, Dattn=0.04385073110461235, Aattn=-0.08759698271751404\n",
      "Epoch = 462, ErrG = 0.9088794986406962, ErrTri = 0.46174824237823486, ErrA = 0.33154925517737865, ErrD = 0.3017897792160511, Gattn=-0.026812352240085602, Dattn=0.04368840530514717, Aattn=-0.08774889260530472\n",
      "Epoch = 464, ErrG = 0.6027973691622416, ErrTri = 0.3385835886001587, ErrA = 0.3517746950189273, ErrD = 0.525433287024498, Gattn=-0.02689255215227604, Dattn=0.043685805052518845, Aattn=-0.08794907480478287\n",
      "Epoch = 466, ErrG = 0.7234287212292353, ErrTri = 0.18545971810817719, ErrA = 0.360730638106664, ErrD = 0.46481915314992267, Gattn=-0.026930831372737885, Dattn=0.04356987029314041, Aattn=-0.08823525160551071\n",
      "Epoch = 468, ErrG = 0.5902670919895172, ErrTri = 0.30854785442352295, ErrA = 0.2911285211642583, ErrD = 0.4787928859392802, Gattn=-0.027014199644327164, Dattn=0.04354814440011978, Aattn=-0.08826259523630142\n",
      "Epoch = 470, ErrG = 0.3673408105969429, ErrTri = 0.39609915018081665, ErrA = 0.3497891078392665, ErrD = 0.2940373470385869, Gattn=-0.02699928544461727, Dattn=0.043566878885030746, Aattn=-0.0885821208357811\n",
      "Epoch = 472, ErrG = 0.333882416288058, ErrTri = 0.4355204105377197, ErrA = 0.34669365112980205, ErrD = 0.4384656697511673, Gattn=-0.026988033205270767, Dattn=0.043591152876615524, Aattn=-0.08863500505685806\n",
      "Epoch = 474, ErrG = 0.9435238242149353, ErrTri = 0.22112220525741577, ErrA = 0.4385452965895335, ErrD = 0.5158126465976238, Gattn=-0.027050213888287544, Dattn=0.043497227132320404, Aattn=-0.08881362527608871\n",
      "Epoch = 476, ErrG = 0.7750325798988342, ErrTri = 0.4776419997215271, ErrA = 0.3403461053967476, ErrD = 0.3672320892413457, Gattn=-0.027018984779715538, Dattn=0.04346394166350365, Aattn=-0.08889371156692505\n",
      "Epoch = 478, ErrG = 1.2834441860516865, ErrTri = 0.5662618279457092, ErrA = 0.34486370782057446, ErrD = 0.24913656090696654, Gattn=-0.027162769809365273, Dattn=0.04336192086338997, Aattn=-0.08908497542142868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 480, ErrG = 0.7129133393367132, ErrTri = 1.0005292892456055, ErrA = 0.31649766365687054, ErrD = 0.3707296848297119, Gattn=-0.027231695130467415, Dattn=0.04338693991303444, Aattn=-0.08908867835998535\n",
      "Epoch = 482, ErrG = 0.7922591716051102, ErrTri = 0.23373650014400482, ErrA = 0.33417196571826935, ErrD = 0.3600047454237938, Gattn=-0.027247117832303047, Dattn=0.04333580657839775, Aattn=-0.08913403749465942\n",
      "Epoch = 484, ErrG = 0.8346841633319855, ErrTri = 0.38902977108955383, ErrA = 0.30527279898524284, ErrD = 0.36581435054540634, Gattn=-0.027277855202555656, Dattn=0.043313074856996536, Aattn=-0.08927620202302933\n",
      "Epoch = 486, ErrG = 0.5601225395997366, ErrTri = 0.32630059123039246, ErrA = 0.3070090711116791, ErrD = 0.24749239285786948, Gattn=-0.027351893484592438, Dattn=0.043239135295152664, Aattn=-0.08956865966320038\n",
      "Epoch = 488, ErrG = 0.2496929963429769, ErrTri = 0.26613765954971313, ErrA = 0.38843360481162864, ErrD = 0.48542119065920514, Gattn=-0.027309393510222435, Dattn=0.04320181533694267, Aattn=-0.08991093933582306\n",
      "Epoch = 490, ErrG = 0.21577479938666025, ErrTri = 0.28961628675460815, ErrA = 0.4753047203024228, ErrD = 0.42490232984224957, Gattn=-0.027342358604073524, Dattn=0.04313294589519501, Aattn=-0.09014515578746796\n",
      "Epoch = 492, ErrG = 0.767396608988444, ErrTri = 0.7135317325592041, ErrA = 0.21403121513624987, ErrD = 0.41948358217875165, Gattn=-0.027374401688575745, Dattn=0.04310807213187218, Aattn=-0.0901859775185585\n",
      "Epoch = 494, ErrG = 0.8867282072703043, ErrTri = 0.2845689058303833, ErrA = 0.22005436569452286, ErrD = 0.5631769734124342, Gattn=-0.02737988531589508, Dattn=0.04311256855726242, Aattn=-0.0903358906507492\n",
      "Epoch = 496, ErrG = 0.8337116539478302, ErrTri = 0.2597658336162567, ErrA = 0.25633260421454906, ErrD = 0.3731856693824132, Gattn=-0.02743714302778244, Dattn=0.04297821223735809, Aattn=-0.09044161438941956\n",
      "Epoch = 498, ErrG = 0.7224838534990946, ErrTri = 0.36711400747299194, ErrA = 0.24463925634821257, ErrD = 0.383532593647639, Gattn=-0.027471965178847313, Dattn=0.04287220537662506, Aattn=-0.09070409834384918\n",
      "Epoch = 500, ErrG = 0.9950589934984843, ErrTri = 0.6856713891029358, ErrA = 0.4589474598566691, ErrD = 0.3664618482192357, Gattn=-0.027512364089488983, Dattn=0.042761486023664474, Aattn=-0.09084022790193558\n",
      "Epoch = 502, ErrG = 0.46922845641771954, ErrTri = 0.1828921139240265, ErrA = 0.2756171226501465, ErrD = 0.32923829555511475, Gattn=-0.02754540927708149, Dattn=0.04272346943616867, Aattn=-0.09100034832954407\n",
      "Epoch = 504, ErrG = 0.49077791596452397, ErrTri = 0.41528084874153137, ErrA = 0.3073323282102744, ErrD = 0.459736963113149, Gattn=-0.02766810543835163, Dattn=0.04268268123269081, Aattn=-0.09105528146028519\n",
      "Epoch = 506, ErrG = 0.8351269066333771, ErrTri = 0.4667370617389679, ErrA = 0.19537761186559996, ErrD = 0.27704792221387226, Gattn=-0.02770448662340641, Dattn=0.04257020726799965, Aattn=-0.09131625294685364\n",
      "Epoch = 508, ErrG = 1.087051272392273, ErrTri = 0.5011193752288818, ErrA = 0.2712466816107432, ErrD = 0.34101755172014236, Gattn=-0.02770616114139557, Dattn=0.04258694872260094, Aattn=-0.09153337776660919\n",
      "Epoch = 510, ErrG = 0.7656484718124071, ErrTri = 0.08532639592885971, ErrA = 0.26749980449676514, ErrD = 0.40048561493555707, Gattn=-0.02775309421122074, Dattn=0.04248010367155075, Aattn=-0.09178916364908218\n",
      "Epoch = 512, ErrG = 0.46219980468352634, ErrTri = 0.4324702024459839, ErrA = 0.26279190244774026, ErrD = 0.3549932390451431, Gattn=-0.027802113443613052, Dattn=0.04246633127331734, Aattn=-0.09202495217323303\n",
      "Epoch = 514, ErrG = 0.9147197802861532, ErrTri = 0.5550057888031006, ErrA = 0.27206457902987796, ErrD = 0.3579770090679328, Gattn=-0.027834279462695122, Dattn=0.04233164340257645, Aattn=-0.09200774133205414\n",
      "Epoch = 516, ErrG = 0.5958359986543655, ErrTri = 0.7337960004806519, ErrA = 0.1780515710512797, ErrD = 0.47666919976472855, Gattn=-0.027929149568080902, Dattn=0.04228891059756279, Aattn=-0.09235115349292755\n",
      "Epoch = 518, ErrG = 0.489286333322525, ErrTri = 0.4011189043521881, ErrA = 0.3248471220334371, ErrD = 0.5118024150530497, Gattn=-0.027916857972741127, Dattn=0.04216887429356575, Aattn=-0.09245607256889343\n",
      "Epoch = 520, ErrG = 0.5954661866029104, ErrTri = 0.44744980335235596, ErrA = 0.25353943308194477, ErrD = 0.27200721700986225, Gattn=-0.028019577264785767, Dattn=0.04213842749595642, Aattn=-0.09271884709596634\n",
      "Epoch = 522, ErrG = 0.8825364510218302, ErrTri = 0.40135252475738525, ErrA = 0.2583083162705104, ErrD = 0.28459902045627433, Gattn=-0.02806188352406025, Dattn=0.04208746552467346, Aattn=-0.09299436956644058\n",
      "Epoch = 524, ErrG = 0.8536666433016459, ErrTri = 0.43725287914276123, ErrA = 0.17249877750873566, ErrD = 0.45978706143796444, Gattn=-0.028104763478040695, Dattn=0.0420353002846241, Aattn=-0.09306860715150833\n",
      "Epoch = 526, ErrG = 0.2770976424217224, ErrTri = 0.520280122756958, ErrA = 0.357122282187144, ErrD = 0.7418436606725057, Gattn=-0.028246108442544937, Dattn=0.0420132651925087, Aattn=-0.09302953630685806\n",
      "Epoch = 528, ErrG = 0.8139339884122213, ErrTri = 0.27193278074264526, ErrA = 0.358295996983846, ErrD = 0.4686787575483322, Gattn=-0.028224583715200424, Dattn=0.04185454174876213, Aattn=-0.09336855262517929\n",
      "Epoch = 530, ErrG = 0.4971691817045212, ErrTri = 0.22173339128494263, ErrA = 0.3138426293929418, ErrD = 0.3928184111913045, Gattn=-0.028277909383177757, Dattn=0.041825391352176666, Aattn=-0.09370360523462296\n",
      "Epoch = 532, ErrG = 0.4726981272300084, ErrTri = 0.22081194818019867, ErrA = 0.2936701426903407, ErrD = 0.2760285586118698, Gattn=-0.02831243723630905, Dattn=0.04172227159142494, Aattn=-0.09402797371149063\n",
      "Epoch = 534, ErrG = 1.0057669480641682, ErrTri = 0.3491123914718628, ErrA = 0.3068939397732417, ErrD = 0.41421084105968475, Gattn=-0.0283725056797266, Dattn=0.041586171835660934, Aattn=-0.0942368283867836\n",
      "Epoch = 536, ErrG = 0.4529836376508077, ErrTri = 0.33843639492988586, ErrA = 0.34021184345086414, ErrD = 0.5648862719535828, Gattn=-0.0284042377024889, Dattn=0.041641950607299805, Aattn=-0.09429405629634857\n",
      "Epoch = 538, ErrG = 0.7229608198006948, ErrTri = 0.39993688464164734, ErrA = 0.25293819854656857, ErrD = 0.4788902997970581, Gattn=-0.028468970209360123, Dattn=0.04161170870065689, Aattn=-0.09437692165374756\n",
      "Epoch = 540, ErrG = 1.0536635319391887, ErrTri = 0.5091021060943604, ErrA = 0.23128767808278403, ErrD = 0.3797226343303919, Gattn=-0.028540965169668198, Dattn=0.04148216173052788, Aattn=-0.0945800170302391\n",
      "Epoch = 542, ErrG = 0.5942216515541077, ErrTri = 0.3666955530643463, ErrA = 0.24196661015351614, ErrD = 0.48248837391535443, Gattn=-0.02851054072380066, Dattn=0.04141934588551521, Aattn=-0.09477443993091583\n",
      "Epoch = 544, ErrG = 0.7948950628439585, ErrTri = 0.3925555646419525, ErrA = 0.29621850575009984, ErrD = 0.5850504599511623, Gattn=-0.028549298644065857, Dattn=0.041442111134529114, Aattn=-0.09494142979383469\n",
      "Epoch = 546, ErrG = 0.880403091510137, ErrTri = 0.35938718914985657, ErrA = 0.20569166541099548, ErrD = 0.2197498381137848, Gattn=-0.028577540069818497, Dattn=0.04135632887482643, Aattn=-0.09501533210277557\n",
      "Epoch = 548, ErrG = 0.23760685324668884, ErrTri = 0.4520590305328369, ErrA = 0.26159809281428653, ErrD = 0.5855004961291949, Gattn=-0.02862154133617878, Dattn=0.041257478296756744, Aattn=-0.09527645260095596\n",
      "Epoch = 550, ErrG = 0.5066330333550771, ErrTri = 0.2687828838825226, ErrA = 0.24432490766048431, ErrD = 0.42228832840919495, Gattn=-0.028694795444607735, Dattn=0.0411934033036232, Aattn=-0.09544644504785538\n",
      "Epoch = 552, ErrG = 1.0602762301762898, ErrTri = 0.40897607803344727, ErrA = 0.24824676165978113, ErrD = 0.38255525814990204, Gattn=-0.028715867549180984, Dattn=0.04120602831244469, Aattn=-0.09558131545782089\n",
      "Epoch = 554, ErrG = 0.8734214355548223, ErrTri = 0.137461319565773, ErrA = 0.19914484148224196, ErrD = 0.46389206250508624, Gattn=-0.028743812814354897, Dattn=0.04108111932873726, Aattn=-0.09557771682739258\n",
      "Epoch = 556, ErrG = 0.28624092042446136, ErrTri = 0.3776737451553345, ErrA = 0.262184785058101, ErrD = 0.32400402426719666, Gattn=-0.028797168284654617, Dattn=0.041013337671756744, Aattn=-0.0959119200706482\n",
      "Epoch = 558, ErrG = 0.7512124876181284, ErrTri = 0.25622811913490295, ErrA = 0.26537154118220013, ErrD = 0.4985071290284395, Gattn=-0.028849752619862556, Dattn=0.0409889742732048, Aattn=-0.0960814580321312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 560, ErrG = 0.6118245323499044, ErrTri = 0.4160063564777374, ErrA = 0.25557664781808853, ErrD = 0.39010149488846463, Gattn=-0.028949540108442307, Dattn=0.04092749208211899, Aattn=-0.0962422788143158\n",
      "Epoch = 562, ErrG = 0.46231236557165784, ErrTri = 0.3709062337875366, ErrA = 0.1954436351855596, ErrD = 0.4338449239730835, Gattn=-0.0289840679615736, Dattn=0.040781352669000626, Aattn=-0.0964789167046547\n",
      "Epoch = 564, ErrG = 0.6003871162732443, ErrTri = 0.5088762044906616, ErrA = 0.23497148354848227, ErrD = 0.403876930475235, Gattn=-0.02902291715145111, Dattn=0.04073943942785263, Aattn=-0.09673493355512619\n",
      "Epoch = 566, ErrG = 0.38870836421847343, ErrTri = 0.2965693473815918, ErrA = 0.13640687863032022, ErrD = 0.4274595081806183, Gattn=-0.029039878398180008, Dattn=0.04067516326904297, Aattn=-0.09677167236804962\n",
      "Epoch = 568, ErrG = 0.8463039000829061, ErrTri = 0.40488290786743164, ErrA = 0.20413067440191904, ErrD = 0.28954119980335236, Gattn=-0.02909497357904911, Dattn=0.04059945419430733, Aattn=-0.09672211855649948\n",
      "Epoch = 570, ErrG = 0.5577995181083679, ErrTri = 0.35180991888046265, ErrA = 0.3265240167578061, ErrD = 0.41940657297770184, Gattn=-0.029118187725543976, Dattn=0.04052557423710823, Aattn=-0.09722544997930527\n",
      "Epoch = 572, ErrG = 0.5400824546813965, ErrTri = 0.0851803869009018, ErrA = 0.13166624742249647, ErrD = 0.27123311161994934, Gattn=-0.029160091653466225, Dattn=0.04049412161111832, Aattn=-0.0972716212272644\n",
      "Epoch = 574, ErrG = 0.9368388255437216, ErrTri = 0.5326262712478638, ErrA = 0.24478822946548462, ErrD = 0.41454562544822693, Gattn=-0.029180387035012245, Dattn=0.04035479947924614, Aattn=-0.09750549495220184\n",
      "Epoch = 576, ErrG = 1.056570033232371, ErrTri = 0.3274868130683899, ErrA = 0.25166718661785126, ErrD = 0.429313230017821, Gattn=-0.02920392155647278, Dattn=0.04032247141003609, Aattn=-0.09755261987447739\n",
      "Epoch = 578, ErrG = 0.9726997017860413, ErrTri = 0.1551455855369568, ErrA = 0.16632749699056149, ErrD = 0.3671776627500852, Gattn=-0.029267610982060432, Dattn=0.04016916826367378, Aattn=-0.09773287177085876\n",
      "Epoch = 580, ErrG = 0.9612602194150289, ErrTri = 0.2642597556114197, ErrA = 0.28349508841832477, ErrD = 0.41089948018391925, Gattn=-0.029270384460687637, Dattn=0.0401410274207592, Aattn=-0.0979536846280098\n",
      "Epoch = 582, ErrG = 0.826252688964208, ErrTri = 0.2016286551952362, ErrA = 0.19884860888123512, ErrD = 0.4964216562608878, Gattn=-0.02931387536227703, Dattn=0.0400543250143528, Aattn=-0.09818074107170105\n",
      "Epoch = 584, ErrG = 0.3592239134013653, ErrTri = 0.24249741435050964, ErrA = 0.30171048765381175, ErrD = 0.41989751656850177, Gattn=-0.029334884136915207, Dattn=0.039983201771974564, Aattn=-0.09867589920759201\n",
      "Epoch = 586, ErrG = 0.3678840398788452, ErrTri = 0.24962902069091797, ErrA = 0.23292280981938043, ErrD = 0.5795652170976003, Gattn=-0.029356887564063072, Dattn=0.03989049792289734, Aattn=-0.09872493147850037\n",
      "Epoch = 588, ErrG = 0.9305321375528971, ErrTri = 0.383745014667511, ErrA = 0.2823345934351285, ErrD = 0.2943250983953476, Gattn=-0.029462704434990883, Dattn=0.0397690087556839, Aattn=-0.09887497872114182\n",
      "Epoch = 590, ErrG = 0.8751700123151144, ErrTri = 0.36820417642593384, ErrA = 0.4028328365335862, ErrD = 0.2846163312594096, Gattn=-0.029497740790247917, Dattn=0.03973317891359329, Aattn=-0.09910784661769867\n",
      "Epoch = 592, ErrG = 0.46596121539672214, ErrTri = 0.1550280898809433, ErrA = 0.24246603498856226, ErrD = 0.45391934116681415, Gattn=-0.02954167127609253, Dattn=0.0397237129509449, Aattn=-0.09921586513519287\n",
      "Epoch = 594, ErrG = 0.8879604637622833, ErrTri = 0.18909761309623718, ErrA = 0.21587203443050385, ErrD = 0.5069690744082133, Gattn=-0.02954026497900486, Dattn=0.039630237966775894, Aattn=-0.09939868003129959\n",
      "Epoch = 596, ErrG = 0.39066267510255176, ErrTri = 0.12602941691875458, ErrA = 0.3717423329750697, ErrD = 0.6856027742226919, Gattn=-0.029531754553318024, Dattn=0.0395953543484211, Aattn=-0.09956788271665573\n",
      "Epoch = 598, ErrG = 0.9417172968387604, ErrTri = 0.31266042590141296, ErrA = 0.30724723637104034, ErrD = 0.6085366290062666, Gattn=-0.02958867698907852, Dattn=0.03950611129403114, Aattn=-0.0995340347290039\n",
      "Epoch = 600, ErrG = 1.2331900596618652, ErrTri = 0.3526960611343384, ErrA = 0.35942381620407104, ErrD = 0.4310232351223628, Gattn=-0.029636595398187637, Dattn=0.03934035822749138, Aattn=-0.09983707219362259\n",
      "Epoch = 602, ErrG = 0.7547067205111185, ErrTri = 0.2311611771583557, ErrA = 0.2010404902199904, ErrD = 0.3357006063063939, Gattn=-0.029641183093190193, Dattn=0.039317768067121506, Aattn=-0.10014130920171738\n",
      "Epoch = 604, ErrG = 0.5858509888251623, ErrTri = 0.13020794093608856, ErrA = 0.24772959078351656, ErrD = 0.3514615421493848, Gattn=-0.029673805460333824, Dattn=0.039258923381567, Aattn=-0.10029197484254837\n",
      "Epoch = 606, ErrG = 0.5535382628440857, ErrTri = 0.3095211386680603, ErrA = 0.2225902477900187, ErrD = 0.4937851627667745, Gattn=-0.02967202104628086, Dattn=0.0392499677836895, Aattn=-0.10027734935283661\n",
      "Epoch = 608, ErrG = 0.9879675706227621, ErrTri = 0.35024094581604004, ErrA = 0.17354367735485235, ErrD = 0.371746468047301, Gattn=-0.029734741896390915, Dattn=0.03907104581594467, Aattn=-0.10052953660488129\n",
      "Epoch = 610, ErrG = 0.5277672906716665, ErrTri = 0.3088635504245758, ErrA = 0.3611538366725047, ErrD = 0.4362981120745341, Gattn=-0.029789019376039505, Dattn=0.03905344381928444, Aattn=-0.10070306807756424\n",
      "Epoch = 612, ErrG = 1.0999244054158528, ErrTri = 0.22298204898834229, ErrA = 0.15264058113098145, ErrD = 0.3736037289102872, Gattn=-0.029788263142108917, Dattn=0.0388503223657608, Aattn=-0.10069771856069565\n",
      "Epoch = 614, ErrG = 0.6922911008199056, ErrTri = 0.5428786873817444, ErrA = 0.24420001606146494, ErrD = 0.4615161729355653, Gattn=-0.029839087277650833, Dattn=0.038885608315467834, Aattn=-0.10079552233219147\n",
      "Epoch = 616, ErrG = 0.42087655266125995, ErrTri = 0.16460290551185608, ErrA = 0.17026681328813234, ErrD = 0.5133446455001831, Gattn=-0.029837224632501602, Dattn=0.03875236585736275, Aattn=-0.10098859667778015\n",
      "Epoch = 618, ErrG = 0.8146224816640218, ErrTri = 0.2849605083465576, ErrA = 0.29819009453058243, ErrD = 0.36473412811756134, Gattn=-0.029856810346245766, Dattn=0.03863277658820152, Aattn=-0.10116083920001984\n",
      "Epoch = 620, ErrG = 0.9002880950768789, ErrTri = 0.17664286494255066, ErrA = 0.2921400840083758, ErrD = 0.4940320998430252, Gattn=-0.02991713397204876, Dattn=0.038540519773960114, Aattn=-0.10123170167207718\n",
      "Epoch = 622, ErrG = 0.5919928203026453, ErrTri = 0.20626051723957062, ErrA = 0.15404584196706614, ErrD = 0.37823713819185895, Gattn=-0.029988901689648628, Dattn=0.03848806768655777, Aattn=-0.10154712945222855\n",
      "Epoch = 624, ErrG = 0.8152309358119965, ErrTri = 0.45753660798072815, ErrA = 0.2972487894197305, ErrD = 0.303370734055837, Gattn=-0.030003441497683525, Dattn=0.038437843322753906, Aattn=-0.10173048079013824\n",
      "Epoch = 626, ErrG = 0.8506084879239401, ErrTri = 0.4115642309188843, ErrA = 0.28635744005441666, ErrD = 0.48698372145493823, Gattn=-0.030069243162870407, Dattn=0.03840357065200806, Aattn=-0.10173430293798447\n",
      "Epoch = 628, ErrG = 0.8649313052495321, ErrTri = 0.31121838092803955, ErrA = 0.1604981521765391, ErrD = 0.25446704030036926, Gattn=-0.030080081894993782, Dattn=0.03830296918749809, Aattn=-0.10188060998916626\n",
      "Epoch = 630, ErrG = 0.9552693764368693, ErrTri = 0.5576990842819214, ErrA = 0.20878432070215544, ErrD = 0.48768201284110546, Gattn=-0.030108259990811348, Dattn=0.03816978260874748, Aattn=-0.10226444900035858\n",
      "Epoch = 632, ErrG = 0.8322095274925232, ErrTri = 0.4310314655303955, ErrA = 0.17788150223592916, ErrD = 0.3512873748938243, Gattn=-0.030214257538318634, Dattn=0.03812599554657936, Aattn=-0.10239814966917038\n",
      "Epoch = 634, ErrG = 0.9357609450817108, ErrTri = 0.25628843903541565, ErrA = 0.16421747207641602, ErrD = 0.3315996378660202, Gattn=-0.030269119888544083, Dattn=0.038050327450037, Aattn=-0.10233243554830551\n",
      "Epoch = 636, ErrG = 0.5347885886828104, ErrTri = 0.1946590542793274, ErrA = 0.15217190980911255, ErrD = 0.37319884200890857, Gattn=-0.030304228886961937, Dattn=0.03796970844268799, Aattn=-0.10252301394939423\n",
      "Epoch = 638, ErrG = 0.05826425552368164, ErrTri = 0.35838425159454346, ErrA = 0.2999389171600342, ErrD = 0.3996818612019221, Gattn=-0.03035016916692257, Dattn=0.037971630692481995, Aattn=-0.10271336883306503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 640, ErrG = 0.5660357077916464, ErrTri = 0.2698623538017273, ErrA = 0.2882832909623782, ErrD = 0.4440277914206187, Gattn=-0.03037169761955738, Dattn=0.037870854139328, Aattn=-0.10285911709070206\n",
      "Epoch = 642, ErrG = 1.012982447942098, ErrTri = 0.4905036687850952, ErrA = 0.19511589407920837, ErrD = 0.3192889454464118, Gattn=-0.030424263328313828, Dattn=0.03771147131919861, Aattn=-0.10301701724529266\n",
      "Epoch = 644, ErrG = 0.44807885338862735, ErrTri = 0.3806682825088501, ErrA = 0.1994085634748141, ErrD = 0.2497753451267878, Gattn=-0.03044893778860569, Dattn=0.03765394166111946, Aattn=-0.10325406491756439\n",
      "Epoch = 646, ErrG = 0.5317885875701904, ErrTri = 0.4957934021949768, ErrA = 0.13783507173260054, ErrD = 0.5832590957482656, Gattn=-0.03045841120183468, Dattn=0.03764573484659195, Aattn=-0.10344134271144867\n",
      "Epoch = 648, ErrG = 0.274221807718277, ErrTri = 0.3355322480201721, ErrA = 0.2705098930746317, ErrD = 0.4238609845439593, Gattn=-0.03050369955599308, Dattn=0.0375526137650013, Aattn=-0.10364782810211182\n",
      "Epoch = 650, ErrG = 0.7623624006907145, ErrTri = 0.4275752305984497, ErrA = 0.20682089030742645, ErrD = 0.30948824683825177, Gattn=-0.030537763610482216, Dattn=0.03740248084068298, Aattn=-0.10369037091732025\n",
      "Epoch = 652, ErrG = 0.992818017800649, ErrTri = 0.33365875482559204, ErrA = 0.2104323407014211, ErrD = 0.2743462473154068, Gattn=-0.03057950921356678, Dattn=0.03737535700201988, Aattn=-0.1038321703672409\n",
      "Epoch = 654, ErrG = 1.0207351446151733, ErrTri = 0.4658561944961548, ErrA = 0.13359390447537103, ErrD = 0.46439256767431897, Gattn=-0.030612420290708542, Dattn=0.03729280084371567, Aattn=-0.10407491028308868\n",
      "Epoch = 656, ErrG = 0.30918989578882855, ErrTri = 0.4706115126609802, ErrA = 0.30253008256355923, ErrD = 0.3361692229906718, Gattn=-0.030643310397863388, Dattn=0.03722609207034111, Aattn=-0.10424671322107315\n",
      "Epoch = 658, ErrG = 0.4464843322833379, ErrTri = 0.1544913798570633, ErrA = 0.14251854829490185, ErrD = 0.422631432612737, Gattn=-0.030687352642416954, Dattn=0.037185151129961014, Aattn=-0.104473777115345\n",
      "Epoch = 660, ErrG = 0.4512444883584976, ErrTri = 0.2631504535675049, ErrA = 0.18661330454051495, ErrD = 0.2892523805300395, Gattn=-0.030709130689501762, Dattn=0.03714577853679657, Aattn=-0.10460927337408066\n",
      "Epoch = 662, ErrG = 0.9620754818121592, ErrTri = 0.4012216627597809, ErrA = 0.2474663034081459, ErrD = 0.46419481312235195, Gattn=-0.030749598518013954, Dattn=0.0370311439037323, Aattn=-0.10466461628675461\n",
      "Epoch = 664, ErrG = 1.3011019229888916, ErrTri = 0.3612661361694336, ErrA = 0.19302777449289957, ErrD = 0.26008987861375016, Gattn=-0.0307991374284029, Dattn=0.036916907876729965, Aattn=-0.10495495796203613\n",
      "Epoch = 666, ErrG = 0.7873833378156027, ErrTri = 0.3913854956626892, ErrA = 0.19590255245566368, ErrD = 0.392744114001592, Gattn=-0.03081611357629299, Dattn=0.036867231130599976, Aattn=-0.10503099113702774\n",
      "Epoch = 668, ErrG = 0.6328084170818329, ErrTri = 0.3930906653404236, ErrA = 0.14360162615776062, ErrD = 0.21946154038111368, Gattn=-0.03083895333111286, Dattn=0.03681638464331627, Aattn=-0.10523147881031036\n",
      "Epoch = 670, ErrG = 1.0071186820665996, ErrTri = 0.26062196493148804, ErrA = 0.28902017573515576, ErrD = 0.2815021649003029, Gattn=-0.030905332416296005, Dattn=0.036670953035354614, Aattn=-0.10542531311511993\n",
      "Epoch = 672, ErrG = 0.9566710293292999, ErrTri = 0.4096345603466034, ErrA = 0.1644289425263802, ErrD = 0.33540386085708934, Gattn=-0.030921971425414085, Dattn=0.036668479442596436, Aattn=-0.10556887835264206\n",
      "Epoch = 674, ErrG = 0.771831805507342, ErrTri = 0.09461073577404022, ErrA = 0.29712223758300144, ErrD = 0.37250140743951005, Gattn=-0.030960282310843468, Dattn=0.03658237308263779, Aattn=-0.10584904253482819\n",
      "Epoch = 676, ErrG = 0.7849380373954773, ErrTri = 0.4995313286781311, ErrA = 0.11951783423622449, ErrD = 0.22486068805058798, Gattn=-0.03103027120232582, Dattn=0.03649710863828659, Aattn=-0.10591664165258408\n",
      "Epoch = 678, ErrG = 0.8381169438362122, ErrTri = 0.2920309901237488, ErrA = 0.24595792839924494, ErrD = 0.3387754112482071, Gattn=-0.031057288870215416, Dattn=0.03644567355513573, Aattn=-0.1063535138964653\n",
      "Epoch = 680, ErrG = 0.5695595641930898, ErrTri = 0.31818288564682007, ErrA = 0.13943767547607422, ErrD = 0.2967478334903717, Gattn=-0.031155260279774666, Dattn=0.03633180260658264, Aattn=-0.10641095787286758\n",
      "Epoch = 682, ErrG = 1.0203984876473744, ErrTri = 0.38854822516441345, ErrA = 0.17786670724550882, ErrD = 0.2862189585963885, Gattn=-0.03114977851510048, Dattn=0.03624313324689865, Aattn=-0.10634457319974899\n",
      "Epoch = 684, ErrG = 1.1096654136975606, ErrTri = 0.5012381672859192, ErrA = 0.23504305506745973, ErrD = 0.19155807544787726, Gattn=-0.031208045780658722, Dattn=0.03620097041130066, Aattn=-0.10669597238302231\n",
      "Epoch = 686, ErrG = 1.1263536761204402, ErrTri = 0.2089732140302658, ErrA = 0.1467021865149339, ErrD = 0.4649525967737039, Gattn=-0.031209103763103485, Dattn=0.036028068512678146, Aattn=-0.10677489638328552\n",
      "Epoch = 688, ErrG = 1.0120706856250763, ErrTri = 0.2608085572719574, ErrA = 0.1361869474252065, ErrD = 0.3376636356115341, Gattn=-0.031247179955244064, Dattn=0.036028530448675156, Aattn=-0.1069779023528099\n",
      "Epoch = 690, ErrG = 0.9430566827456156, ErrTri = 0.29607802629470825, ErrA = 0.17796107133229574, ErrD = 0.33501853545506793, Gattn=-0.0312807634472847, Dattn=0.035935185849666595, Aattn=-0.10684491693973541\n",
      "Epoch = 692, ErrG = 0.8534926076730093, ErrTri = 0.4352984130382538, ErrA = 0.21333287159601846, ErrD = 0.25150688489278156, Gattn=-0.03130587562918663, Dattn=0.0358031690120697, Aattn=-0.10706496983766556\n",
      "Epoch = 694, ErrG = 0.952970822652181, ErrTri = 0.38788461685180664, ErrA = 0.21755946365495524, ErrD = 0.28226231038570404, Gattn=-0.03132380545139313, Dattn=0.035761475563049316, Aattn=-0.1075650304555893\n",
      "Epoch = 696, ErrG = 1.0269312858581543, ErrTri = 0.6490412950515747, ErrA = 0.12048464020093282, ErrD = 0.2442206492026647, Gattn=-0.031364310532808304, Dattn=0.03567104786634445, Aattn=-0.10758363455533981\n",
      "Epoch = 698, ErrG = 1.0924638509750366, ErrTri = 0.524989128112793, ErrA = 0.10698976988593738, ErrD = 0.3952483261624972, Gattn=-0.03140038996934891, Dattn=0.035653822124004364, Aattn=-0.10775459557771683\n",
      "Epoch = 700, ErrG = 1.05971097946167, ErrTri = 0.3737097978591919, ErrA = 0.22088736730317274, ErrD = 0.2977099282046159, Gattn=-0.03143588826060295, Dattn=0.03559216856956482, Aattn=-0.107915498316288\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "# lr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 0\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 10\n",
    "g_k = 2\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, g_k={}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, g_k, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img) in enumerate(train_loader):\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "    # while epoch < 30000:\n",
    "    #     ass_label, noass_label, img = dataset.getbatch(batchSize)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "\n",
    "        if i % g_k ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            d_out_assreal,dr1 = netd(ass_label)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_assreal\n",
    "            lossD += d_loss_assreal.item()\n",
    "\n",
    "            d_out_noassreal,dr2 = netd(noass_label)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_noassreal\n",
    "            lossD += d_loss_noassreal.item()\n",
    "\n",
    "            fake, code = netg(img)\n",
    "            d_out_fake, df1 = netd(fake.detach())\n",
    "            d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "            lossD_ += d_loss_fake\n",
    "            lossD += d_loss_fake.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "            lossD_ = lossD_/3\n",
    "            lossD_.backward()\n",
    "            optimD.step()\n",
    "\n",
    "    #         for p in netd.parameters():\n",
    "    #             p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked, code = netg(img)\n",
    "            faked = th.cat((img, faked.detach()), 1)\n",
    "\n",
    "            d_out_assreal,dr1 = neta(assd)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "            lossA += d_loss_assreal.item()\n",
    "            lossA_ += d_loss_assreal\n",
    "\n",
    "            d_out_noassreal,dr2 = neta(noassd)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "            lossA_ += d_loss_noassreal\n",
    "            lossA += d_loss_noassreal.item()\n",
    "\n",
    "            d_out_faked, df3 = neta(faked)\n",
    "            d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "            lossA_ += d_loss_faked\n",
    "            lossA += d_loss_faked.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "\n",
    "#         for p in neta.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "#         if i % n_critic == 0:\n",
    "        lossG = 0\n",
    "        lossG_ = 0\n",
    "        optimG.zero_grad()\n",
    "        fake, A= netg(img)\n",
    "        g_out_fake,_ = netd(fake)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "        lossG += g_loss_fake.item()\n",
    "        lossG_ += g_loss_fake\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        g_out_faked,_ = neta(faked)\n",
    "        g_loss_faked = - g_out_faked.mean()\n",
    "        lossG += g_loss_faked.item()\n",
    "        lossG_ += g_loss_faked\n",
    "        \n",
    "        # constrain on generator\n",
    "        fake_ass, P = netg(ass_img)\n",
    "        fake_noass, N = netg(noass_img)\n",
    "        lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "        lossG_ += lossTriplet\n",
    "        lossG += lossTriplet.item()\n",
    "#         lossTriplet.backward()\n",
    "        \n",
    "        lossG_ = lossG_/3\n",
    "        lossG_.backward(retain_graph=True)\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrTri = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/3,lossTriplet.item(), lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/3)<low_loss:  \n",
    "        low_loss = lossG/3\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA and triplet (onlineloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-06T16:40:54.767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "n_con= 10 ,n_ang= 11\n",
      "target =  090\n",
      "write parameter log...\n",
      "Training starts\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.autograd import grad, Variable\n",
    "\n",
    "#python -m visdom.server\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win = None\n",
    "win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "\n",
    "# weights init\n",
    "all_mods = itertools.chain()\n",
    "all_mods = itertools.chain(all_mods, [\n",
    "    list(netg.children())[0].children(),\n",
    "    list(netd.children())[0].children(),\n",
    "    list(neta.children())[0].children()\n",
    "])\n",
    "for mod in all_mods:\n",
    "    if isinstance(mod, nn.Conv2d) or isinstance(mod, nn.ConvTranspose2d):\n",
    "#         init.xavier_normal_(tensor, gain=1.)\n",
    "        init.normal_(mod.weight, 0.0, 0.02)\n",
    "    elif isinstance(mod, nn.BatchNorm2d):\n",
    "        init.normal_(mod.weight, 1.0, 0.02)\n",
    "        init.constant_(mod.bias, 0.0)\n",
    "        \n",
    "epoches = 700\n",
    "glr = 0.00001\n",
    "dlr = 0.00004\n",
    "# lr = 0.00002\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "batchSize = 32\n",
    "n_critic = 0\n",
    "target = '090'\n",
    "lambda_gp = 0\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "margin = 10\n",
    "g_k = 2\n",
    "\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "netg.train()\n",
    "netd.train()\n",
    "neta.train()\n",
    "dataset = CASIABDataset(data_dir=Data_Dir,target=target)\n",
    "train_loader = th.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=True, num_workers=2, pin_memory=False)\n",
    "\n",
    "\n",
    "optimG = optim.Adam(netg.parameters(), lr=glr, betas=(beta1, beta2))\n",
    "optimD = optim.Adam(netd.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "optimA = optim.Adam(neta.parameters(), lr=dlr, betas=(beta1, beta2))\n",
    "# optimG = optim.RMSprop(netg.parameters(), lr=lr)\n",
    "# optimD = optim.RMSprop(netd.parameters(), lr=lr)\n",
    "# optimA = optim.RMSprop(neta.parameters(), lr=lr)\n",
    "\n",
    "print(\"write parameter log...\")\n",
    "with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, margin = {}, dlr = {}, glr={}, g_k={}, batchsize = {}, beta1={}, beta2={}, n_critic = {}, target={},lambda_gp={} \\n'.format(\n",
    "            epoches, margin, dlr, glr, g_k, batchSize, beta1, beta2, n_critic, target, lambda_gp))\n",
    "\n",
    "low_loss = 10\n",
    "\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "#     alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    alpha = th.rand((batchSize, 1, 1, 1)).to(device).to(th.float32)\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "#     fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    gradients = grad(outputs=d_interpolates, \n",
    "                     inputs=interpolates, \n",
    "                     grad_outputs=th.ones([real_samples.shape[0],1]).to(device).requires_grad_(False),\n",
    "#                      grad_outputs = fake,\n",
    "                     create_graph=True, \n",
    "                     retain_graph=True, \n",
    "                     only_inputs=True)[0]\n",
    "#     fake = Variable((real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "#     # Get gradient w.r.t. interpolates\n",
    "#     gradients = autograd.grad(\n",
    "#         outputs=d_interpolates,\n",
    "#         inputs=interpolates,\n",
    "#         grad_outputs=fake,\n",
    "#         create_graph=True,\n",
    "#         retain_graph=True,\n",
    "#         only_inputs=True,\n",
    "#     )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "print('Training starts')\n",
    "for epoch in range(1,epoches+1):\n",
    "#     for i, (ass_label, noass_label, img) in enumerate(train_loader):\n",
    "    for i, (ass_label, noass_label, noass_img, img, ass_img, label_neg, label_anc, label_pos) in enumerate(train_loader):\n",
    "        \n",
    "        com_img = th.cat((noass_img, img, ass_img), 0)\n",
    "        com_label = th.cat(( label_neg, label_anc, label_pos), 0)\n",
    "        com_img = com_img.to(device).to(th.float32)\n",
    "        com_label = com_label.to(device).to(th.float32)\n",
    "#         print(\"shape\",ass_label.shape,noass_label.shape,img.shape)\n",
    "        \n",
    "\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        noass_label = noass_label.to(device).to(th.float32)\n",
    "        noass_img = noass_img.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "        ass_img = ass_img.to(device).to(th.float32)\n",
    "\n",
    "        if i % g_k ==0:\n",
    "            # update D\n",
    "            lossD = 0\n",
    "            lossD_ = 0\n",
    "            optimD.zero_grad()\n",
    "            d_out_assreal,dr1 = netd(ass_label)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_assreal\n",
    "            lossD += d_loss_assreal.item()\n",
    "\n",
    "            d_out_noassreal,dr2 = netd(noass_label)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 - d_out_noassreal).mean()\n",
    "\n",
    "            lossD_ += d_loss_noassreal\n",
    "            lossD += d_loss_noassreal.item()\n",
    "\n",
    "            fake, code = netg(img)\n",
    "            d_out_fake, df1 = netd(fake.detach())\n",
    "            d_loss_fake = nn.ReLU()(1.0 + d_out_fake).mean()\n",
    "\n",
    "            lossD_ += d_loss_fake\n",
    "            lossD += d_loss_fake.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(netd, ass_label.data, fake.data)\n",
    "            lossD_ = lossD_/3\n",
    "            lossD_.backward()\n",
    "            optimD.step()\n",
    "\n",
    "    #         for p in netd.parameters():\n",
    "    #             p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            # update A\n",
    "            lossA = 0\n",
    "            lossA_ = 0\n",
    "            optimA.zero_grad()\n",
    "            assd = th.cat((img, ass_label), 1)\n",
    "            noassd = th.cat((img, noass_label), 1)\n",
    "            faked, code = netg(img)\n",
    "            faked = th.cat((img, faked.detach()), 1)\n",
    "\n",
    "            d_out_assreal,dr1 = neta(assd)\n",
    "            d_loss_assreal = nn.ReLU()(1.0 - d_out_assreal).mean()\n",
    "            lossA += d_loss_assreal.item()\n",
    "            lossA_ += d_loss_assreal\n",
    "\n",
    "            d_out_noassreal,dr2 = neta(noassd)\n",
    "            d_loss_noassreal = nn.ReLU()(1.0 + d_out_noassreal).mean()\n",
    "\n",
    "            lossA_ += d_loss_noassreal\n",
    "            lossA += d_loss_noassreal.item()\n",
    "\n",
    "            d_out_faked, df3 = neta(faked)\n",
    "            d_loss_faked = nn.ReLU()(1.0 + d_out_faked).mean()\n",
    "\n",
    "            lossA_ += d_loss_faked\n",
    "            lossA += d_loss_faked.item()\n",
    "    #         gradient_penalty = compute_gradient_penalty(neta, assd.data, faked.data)\n",
    "            lossA_ = lossA_/3\n",
    "            lossA_.backward()\n",
    "            optimA.step()\n",
    "\n",
    "#         for p in neta.parameters():\n",
    "#             p.data.clamp_(-0.01, 0.01)\n",
    "            \n",
    "        # update G\n",
    "#         if i % n_critic == 0:\n",
    "        lossG = 0\n",
    "        lossG_ = 0\n",
    "        optimG.zero_grad()\n",
    "        fake, A= netg(img)\n",
    "        g_out_fake,_ = netd(fake)\n",
    "        g_loss_fake = - g_out_fake.mean()\n",
    "\n",
    "        lossG += g_loss_fake.item()\n",
    "        lossG_ += g_loss_fake\n",
    "\n",
    "        faked = th.cat((img, fake), 1)\n",
    "        g_out_faked,_ = neta(faked)\n",
    "        g_loss_faked = - g_out_faked.mean()\n",
    "        lossG += g_loss_faked.item()\n",
    "        lossG_ += g_loss_faked\n",
    "        \n",
    "#         # constrain on encoder\n",
    "#         fake_ass, P = netg(ass_img)\n",
    "#         fake_noass, N = netg(noass_img)\n",
    "#         lossTriplet = F.triplet_margin_loss(A, P, N, margin = margin)\n",
    "#         lossG_ += lossTriplet\n",
    "#         lossG += lossTriplet.item()\n",
    "# #         lossTriplet.backward()\n",
    "\n",
    "        ## new onlinetripletloss\n",
    "        __, com = netg(com_img)\n",
    "        loss_fn = OnlineTripletLoss(margin, SemihardNegativeTripletSelector(margin))\n",
    "        lossTriplet,len_triplet = loss_fn(com, com_label)\n",
    "        lossG += lossTriplet.item()\n",
    "        lossG_ += lossTriplet\n",
    "#         lossTriplet.backward()\n",
    "        \n",
    "        \n",
    "        lossG_ = lossG_/3\n",
    "        lossG_.backward(retain_graph=True)\n",
    "        optimG.step()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            with th.no_grad():\n",
    "                netg.eval()  #切換\n",
    "                fake,_ = netg(img) \n",
    "                netg.train() #切換回去\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            real = (ass_label + 1) / 2 * 255\n",
    "            ori = (img + 1) / 2 * 255\n",
    "            al = th.cat((fake, real, ori), 2)\n",
    "            display = make_grid(al, 20).cpu().numpy()\n",
    "            if win1 is None:\n",
    "                win1 = vis.image(display,\n",
    "                                 opts=dict(title=\"train\", caption='train'))\n",
    "            else:\n",
    "                vis.image(display, win=win1)\n",
    "\n",
    "    if epoch % 2==0:   #2   \n",
    "        if win is None:\n",
    "            win = vis.line(X=np.array([[epoch, epoch,\n",
    "                                        epoch]]),\n",
    "                           Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                           opts=dict(\n",
    "                               title=Model_Name,\n",
    "                               ylabel='loss',\n",
    "                               xlabel='epochs',\n",
    "                               legend=['lossG', 'lossA', 'lossD']\n",
    "                           ))\n",
    "        else:\n",
    "            vis.line(X=np.array([[epoch, epoch,\n",
    "                                  epoch]]),\n",
    "                     Y=np.array([[lossG/3, lossA/3, lossD/3]]),\n",
    "                     win=win,\n",
    "                     update='append')\n",
    "\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))\n",
    "        print('Epoch = {}, ErrG = {}, ErrTri = {}, ErrA = {}, ErrD = {}, Gattn={}, Dattn={}, Aattn={}'.format(\n",
    "            epoch, lossG/3,lossTriplet.item(), lossA/3, lossD/3, netg.attn.gamma.item(), netd.attn.gamma.item(), neta.attn.gamma.item()\n",
    "        ))\n",
    "            \n",
    "    if (epoch>= 300) and epoch%20==0:      \n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        \n",
    "    if (epoch>= 550) and (lossG/3)<low_loss:  \n",
    "        low_loss = lossG/3\n",
    "        state = {\n",
    "            'netA': neta.state_dict(),\n",
    "            'netG': netg.state_dict(),\n",
    "            'netD': netd.state_dict()\n",
    "        }\n",
    "        th.save(state, Model_dir+'/lowest_snapshot'+ Model_Name +'_%d.t7' % epoch)\n",
    "        with open(Model_dir+\"/snapshot_log.txt\", \"a\") as myfile:\n",
    "            myfile.write('lower_lossG Epoch = {}, ErrG = {}, ErrA = {}, ErrD = {} \\n'.format(\n",
    "            epoch, lossG/3, lossA/3, lossD/3\n",
    "        ))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_ting_cv]",
   "language": "python",
   "name": "conda-env-py36_ting_cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
