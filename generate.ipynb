{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate image(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T13:08:06.536006Z",
     "start_time": "2019-04-15T13:07:25.373655Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load generate.py\n",
    "# speed up the loading of the training data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import os\n",
    "import torch as th\n",
    "from model import NetG, NetD, NetA\n",
    "from data_set import CASIABDatasetGenerate\n",
    "import visdom\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "# checkpoint = './Model_64x64_allseqs_pixelDTcode/snapshotModel_64x64_allseqs_pixelDTcode_30000.t7'\n",
    "checkpoint = './Model_64x64_allseqs_newdata/snapshotModel_64x64_allseqs_newdata_25000.t7'\n",
    "\n",
    "# vis = visdom.Visdom(port=5274)\n",
    "# win1 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "neta = neta.to(device)\n",
    "fineSize = 64\n",
    "\n",
    "# checkpoint = './snapshot64_20000.t7'\n",
    "checkpoint = th.load(checkpoint)\n",
    "neta.load_state_dict(checkpoint['netA'])\n",
    "netg.load_state_dict(checkpoint['netG'])\n",
    "netd.load_state_dict(checkpoint['netD'])\n",
    "neta.eval()\n",
    "netg.eval()\n",
    "netd.eval()\n",
    "angles = ['000', '018', '036', '054', '072', '090',\n",
    "          '108', '126', '144', '162', '180']\n",
    "if not os.path.isdir('./Transform'+Data_Name):\n",
    "    os.mkdir('./Transform'+Data_Name)\n",
    "    \n",
    "for cond in ['nm-01', 'nm-02', 'nm-03', 'nm-04', 'nm-05',\n",
    "             'nm-06']:\n",
    "    dataset = CASIABDatasetGenerate(data_dir=Data_Dir,cond=cond)\n",
    "    print('cond',cond)\n",
    "    for i in range(1, 125):\n",
    "        ass_label, img = dataset.getbatch(i, 11)\n",
    "#         img = dataset.getbatch(i, 10)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        with th.no_grad():\n",
    "            fake = netg(img)\n",
    "            fake = (fake + 1) / 2 * 255\n",
    "            for j in range(11):\n",
    "                fake_ = fake[j].squeeze().cpu().numpy()\n",
    "                ang = angles[j]\n",
    "                cv2.imwrite('./Transform'+Data_Name+'/%03d-%s-%s.png' % (i, cond, ang), fake_)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T14:23:22.446351Z",
     "start_time": "2019-08-14T14:20:51.912912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 068/nm-01/068-nm-01-054.png\n",
      "None 068/nm-01/068-nm-01-126.png\n",
      "None 068/nm-01/068-nm-01-144.png\n",
      "None 068/nm-01/068-nm-01-162.png\n",
      "None 109/nm-01/109-nm-01-126.png\n",
      "None 109/nm-01/109-nm-01-144.png\n",
      "None 109/nm-01/109-nm-01-162.png\n",
      "None 109/nm-01/109-nm-01-180.png\n",
      "None 068/nm-02/068-nm-02-126.png\n",
      "None 068/nm-02/068-nm-02-162.png\n",
      "None 068/nm-03/068-nm-03-126.png\n",
      "None 068/nm-03/068-nm-03-144.png\n",
      "None 068/nm-03/068-nm-03-180.png\n",
      "None 088/nm-03/088-nm-03-054.png\n",
      "None 088/nm-03/088-nm-03-126.png\n",
      "None 088/nm-03/088-nm-03-162.png\n",
      "None 088/nm-03/088-nm-03-180.png\n",
      "None 068/nm-04/068-nm-04-126.png\n",
      "None 068/nm-04/068-nm-04-144.png\n",
      "None 088/nm-04/088-nm-04-054.png\n",
      "None 088/nm-04/088-nm-04-126.png\n",
      "None 088/nm-04/088-nm-04-144.png\n",
      "None 088/nm-04/088-nm-04-162.png\n",
      "None 088/nm-04/088-nm-04-180.png\n",
      "None 079/bg-02/079-bg-02-054.png\n",
      "None 079/bg-02/079-bg-02-162.png\n"
     ]
    }
   ],
   "source": [
    "# %load generate.py\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import torch as th\n",
    "# from model import NetG, NetD, NetA\n",
    "# from model_siGAN_dropout import NetG, NetD, NetA\n",
    "# from model_WGAN import NetG, NetD, NetA\n",
    "# from model_SAGAN1_1 import NetG, NetD, NetA\n",
    "# from model_SAGAN import NetG, NetD, NetA\n",
    "from model import NetG, NetD, NetA\n",
    "from dataset2Loader import loadImage\n",
    "import visdom\n",
    "\n",
    "checkpoint = './Transform_Model/Model_64x64_GaitGAN_90/snapshotModel_64x64_GaitGAN_90_600.t7'\n",
    "# checkpoint = './Transform_Model/Model_64x64_TripletSAGAN_90_trial3/snapshotModel_64x64_TripletSAGAN_90_trial3_600.t7'\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "save_datadir = './Transform_64x64_gaitgan'\n",
    "\n",
    "netg = NetG(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "netg = netg.to(device)\n",
    "\n",
    "checkpoint = th.load(checkpoint)\n",
    "netg.load_state_dict(checkpoint['netG'])\n",
    "netg.eval()\n",
    "angles = ['000', '018', '036', '054', '072', '090',\n",
    "          '108', '126', '144', '162', '180']\n",
    "if not os.path.isdir(save_datadir):\n",
    "    os.mkdir(save_datadir)\n",
    "\n",
    "\n",
    "for cond in ['nm-01', 'nm-02', 'nm-03', 'nm-04', 'nm-05','nm-06','bg-01','bg-02','cl-01','cl-02']:\n",
    "    for i in range(63, 125): \n",
    "        id1 = '%03d' % i\n",
    "        for ang in angles:\n",
    "            r3 = id1 + '/' + cond + '/'  + id1 + '-' + cond + '-' + ang + '.png'\n",
    "            if os.path.exists(Data_Dir + r3):\n",
    "                img3 = loadImage(Data_Dir + r3) #(1,64,64) 且歸一化\n",
    "                img3 = img3.unsqueeze(0)  #(1,1,64,64)\n",
    "                img3 = img3.to(device).to(th.float32)\n",
    "                with th.no_grad():\n",
    "#                     fake,_ = netg(img3)\n",
    "                    fake = netg(img3)\n",
    "                    fake = (fake + 1) / 2 * 255\n",
    "                    fake_ = fake.squeeze().cpu().numpy()\n",
    "                    cv2.imwrite(save_datadir+'/%03d-%s-%s.png' % (i, cond, ang), fake_)\n",
    "            else:\n",
    "                print('None', r3)\n",
    "                continue\n",
    "\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate image by multi-view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T01:53:30.913680Z",
     "start_time": "2019-05-31T01:46:12.724524Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7e6bba730b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#                     print(r3,'in 2 ang')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0mnetg\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mchoice_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                         \u001b[0mfake90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'144'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'162'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'180'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7e6bba730b81>\u001b[0m in \u001b[0;36mchoice_model\u001b[0;34m(checkpoint, netG)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchoice_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'netG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_ting_cv/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36_ting_cv/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load generate.py\n",
    "# speed up the loading of the training data\n",
    "import cv2\n",
    "import os\n",
    "import torch as th\n",
    "# from model_dropout import NetG, NetD, NetA\n",
    "# from model_siGAN_dropout import NetG, NetD, NetA\n",
    "# from model_WGAN import NetG, NetD, NetA\n",
    "from model_siGAN import NetG, NetD, NetA\n",
    "# from model import NetG, NetD, NetA\n",
    "from dataset2Loader import loadImage\n",
    "import visdom\n",
    "\n",
    "checkpoint36 = './Transform_Model/Model_64x64_TripletGAN_36_trial1/lowest_snapshotModel_64x64_TripletGAN_36_trial1_598.t7'\n",
    "checkpoint90 = './Transform_Model/Model_64x64_SAGAN_90_trial1/lowest_snapshotModel_64x64_TripletGAN_90_trial1_613.t7'\n",
    "checkpoint144 = './Transform_Model/Model_64x64_TripletGAN_144_trial1/lowest_snapshotModel_64x64_TripletGAN_144_trial1_613.t7'\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "save_datadir = './Transform_64x64_allseq'\n",
    "\n",
    "netg = NetG(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "netg = netg.to(device)\n",
    "\n",
    "def choice_model(checkpoint,netG):\n",
    "    checkpoint = th.load(checkpoint)\n",
    "    netG.load_state_dict(checkpoint['netG'])\n",
    "    netG.eval()\n",
    "    return netG\n",
    "\n",
    "angles = ['000', '018', '036', '054', '072', '090',\n",
    "          '108', '126', '144', '162', '180']\n",
    "if not os.path.isdir(save_datadir):\n",
    "    os.mkdir(save_datadir)\n",
    "\n",
    "count = 0\n",
    "for cond in ['nm-01', 'nm-02', 'nm-03', 'nm-04', 'nm-05','nm-06','bg-01','bg-02','cl-01','cl-02']:\n",
    "    for i in range(63, 125): \n",
    "        id1 = '%03d' % i\n",
    "        for ang in angles: \n",
    "            r3 = id1 + '/' + cond + '/'  + id1 + '-' + cond + '-' + ang + '.png'\n",
    "            if os.path.exists(Data_Dir + r3):\n",
    "                img3 = loadImage(Data_Dir + r3) \n",
    "                img3 = img3.unsqueeze(0)  #(1,1,64,64)\n",
    "                img3 = img3.to(device).to(th.float32)\n",
    "                if ang in ['000', '018', '036']:  \n",
    "#                     print(r3,'in 1 ang')\n",
    "                    with th.no_grad():\n",
    "                        netg= choice_model(checkpoint36,netg)\n",
    "                        fake36,_ = netg(img3)\n",
    "                        netg= choice_model(checkpoint90,netg)\n",
    "#                         fake36 = (fake36 + 1) / 2 * 255\n",
    "                        fake90,_ = netg(fake36)\n",
    "                elif ang in ['054', '072', '090', '108', '126']:\n",
    "#                     print(r3,'in 2 ang')\n",
    "                    with th.no_grad():\n",
    "                        netg= choice_model(checkpoint90,netg)\n",
    "                        fake90,_ = netg(img3)\n",
    "                elif ang in ['144', '162', '180']:\n",
    "#                     print(r3,'in 3 ang')\n",
    "                    with th.no_grad():\n",
    "                        netg= choice_model(checkpoint144,netg)\n",
    "                        fake144,_ = netg(img3)\n",
    "                        netg= choice_model(checkpoint90,netg)\n",
    "#                         fake144 = (fake144 + 1) / 2 * 255\n",
    "                        fake90,_ = netg(fake144)\n",
    "                fake90 = (fake90 + 1) / 2 * 255\n",
    "                fake90 = fake90.squeeze().cpu().numpy()\n",
    "                cv2.imwrite(save_datadir+'/%03d-%s-%s.png' % (i, cond, ang), fake90)\n",
    "\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# show generated images of some people on vistom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:05:24.457288Z",
     "start_time": "2019-06-03T02:05:23.725365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "cond nm-06\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import torch as th\n",
    "from model_SAGAN import NetG, NetD, NetA\n",
    "from data_set import CASIABDatasetGenerate,loadImage\n",
    "import visdom\n",
    "checkpoint = './Transform_Model/Model_64x64_SAGAN_90_trial1/lowest_snapshotModel_64x64_SAGAN_90_trial1_697.t7'\n",
    "Data_Dir = '../GaitRecognition/GEI_CASIA_B/gei/'\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "vis = visdom.Visdom(port=8097)\n",
    "win2 = None\n",
    "win3 = None\n",
    "win5 = None\n",
    "netg = NetG(nc=1)\n",
    "netd = NetD(nc=1)\n",
    "# neta = NetA(nc=1)\n",
    "device = th.device(\"cuda:1\")\n",
    "netg = netg.to(device)\n",
    "netd = netd.to(device)\n",
    "# neta = neta.to(device)\n",
    "fineSize = 64\n",
    "\n",
    "checkpoint = th.load(checkpoint)\n",
    "# neta.load_state_dict(checkpoint['netA'])\n",
    "netg.load_state_dict(checkpoint['netG'])\n",
    "netd.load_state_dict(checkpoint['netD'])\n",
    "# neta.eval()\n",
    "netg.eval()\n",
    "netd.eval()\n",
    "angles = ['000', '018', '036', '054', '072', '090',\n",
    "          '108', '126', '144', '162', '180']\n",
    "for cond in [\n",
    "#     'nm-01', 'nm-02', 'nm-03', 'nm-04', 'nm-05',\n",
    "             'nm-06']:\n",
    "    dataset = CASIABDatasetGenerate(data_dir=Data_Dir ,cond=cond)\n",
    "    print('cond',cond)\n",
    "    for i in range(100, 105):\n",
    "        ass_label, img = dataset.getbatch(i, 11)\n",
    "#         img = dataset.getbatch(i, 11)\n",
    "#         print(img.shape)\n",
    "        ass_label = ass_label.to(device).to(th.float32)\n",
    "        img = img.to(device).to(th.float32)\n",
    "\n",
    "        with th.no_grad():\n",
    "            fake,_= netg(img)\n",
    "#             fake = (fake + 1) / 2 * 255\n",
    "#             for j in range(11):\n",
    "#                 fake_ = fake[j].squeeze().cpu().numpy()\n",
    "#                 ang = angles[j]\n",
    "#                 cv2.imwrite('./Transform64/%03d-%s-%s.png' % (i, cond, ang), fake_)\n",
    "        fake = (fake + 1) / 2 * 255\n",
    "        real = (ass_label + 1) / 2 * 255\n",
    "        ori = (img + 1) / 2 * 255\n",
    "        al = th.cat((fake, real, ori), 2)\n",
    "        display = make_grid(al, 11).cpu().numpy()\n",
    "        \n",
    "        if win5 is None:\n",
    "            win5 = vis.image(display,\n",
    "                             opts=dict(title=\"train\", caption='train')) #最後會印出最後一個狀態 NM06\n",
    "        else:\n",
    "            vis.image(display, win=win5)\n",
    "        win5 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline \n",
    "colors = ['red','green','blue','purple','yellow','black','brown','pink','orange','gray']\n",
    "plt.scatter(X_embedded[:1000,0],X_embedded[:1000,1], c=label, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "cb = plt.colorbar()\n",
    "loc = np.arange(0,max(label),max(label)/float(len(colors)))\n",
    "cb.set_ticks(loc)\n",
    "cb.set_ticklabels([a for a in range(10)])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_ting_cv]",
   "language": "python",
   "name": "conda-env-py36_ting_cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
